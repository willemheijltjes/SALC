
\documentclass[a4paper,UKenglish,cleveref, autoref]{lipics-v2019}

\usepackage{opendeduction}
\usepackage{tikz}
\usetikzlibrary{decorations.pathmorphing}
\usepackage{amsmath, amssymb}
\usepackage{stmaryrd}
\usepackage{mathtools}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{MnSymbol}

\newtheorem{notation}[definition]{Notation}

\newcommand\defn{\textbf}

\newcommand{\FALC}{\Lambda^{S}_{a}}
\newcommand{\SLC}{\Lambda^{S}}
\newcommand{\WEAK}{\Lambda_{\weaksymbol}}
\newcommand{\fv}[1]{(#1)_{fv}}
\newcommand{\bv}[1]{(#1)_{bv}}
\newcommand{\fp}[1]{(#1)_{fp}}
\newcommand{\bp}[1]{(#1)_{bp}}
\newcommand{\fc}[1]{(#1)_{fc}}
\newcommand{\bc}[1]{(#1)_{bc}}
\newcommand{\set}[1]{ \{ #1 \} }
\newcommand{\abs}[2]{\lambda #1 . #2}
\newcommand{\app}[2]{#1 \, #2}
\newcommand{\fake}[3]{#1 \langle \, #2 \, \rangle . #3}
\newcommand{\share}[3]{#1 [#2 \leftarrow #3]}
\newcommand{\dist}[5]{#1 [ #2 \, \vert \, \fakedist{#4}{#5} \, #3 ]}
\newcommand{\olddist}[5]{#1 [ #2 \twoheadleftarrow \lambda #3 \langle #4 \rangle #5]}
\newcommand{\fakedist}[2]{#1 \langle \, #2 \, \rangle}
\newcommand{\barr}[2]{#1 \, \vert \, #2}
\newcommand{\size}[1]{\vert \, #1 \, \vert}
\newcommand{\vecdist}[2]{\overrightarrow{\fakedist{#1}{#2} \,}}
\newcommand{\sub}[3]{#1 \{ #2 / #3 \}}
\newcommand{\lamsub}[2]{\{ \lambda #1 / \lambda #2 \}}
\newcommand{\psub}[3]{#1 \{ #2 / #3 \}_{b}}
\newcommand{\exor}[3]{#1 \{ \fakedist{#2}{#3} \}_{e}}
\newcommand{\readback}[2]{\llbracket \, #1 \, \rrbracket}
\newcommand{\compile}[1]{\llparenthesis \, #1 \, \rrparenthesis}
\newcommand{\weaksymbol}{\mbox{\tiny $\mathcal{W}$}}
\newcommand{\trans}[1]{\llbracket \, #1 \, \rrbracket}
\newcommand{\tranclos}[1]{\| #1 \|}
\newcommand{\readbackclose}[1]{\llbracket \, #1 \, \rrbracket }
\newcommand{\readbackwmap}[3]{\llbracket \, #1 \, \vert \, #2 \, \vert \, #3  \, \rrbracket }
\newcommand{\readweakwmap}[3]{\llbracket \, #1 \, \vert \, #2 \, \vert \, #3  \, \rrbracket_{\weaksymbol} }
\newcommand{\bindvars}[1]{\parallel#1\parallel}
\newcommand{\compweak}[1]{\llparenthesis \, #1 \, \rrparenthesis^{\weaksymbol}}
\newcommand{\readbackweak}[1]{\lfloor \, #1 \, \rfloor}
\newcommand{\composeweak}[1]{\llbracket \, #1 \, \rrbracket^{\weaksymbol}}
\newcommand{\height}[2]{\mathcal{H}^{#1}(#2)}
\newcommand{\weight}[2]{\mathcal{W}^{#1}(#2)}
\newcommand{\weightvar}[2]{\mathcal{V}^{#1}(#2)}
\newcommand{\weightvarshare}[2]{\mathcal{F}^{#1}(#2)}

\newcommand{\distrule}{d}
\newcommand{\switchrule}{s}
\newcommand{\sharerule}{\triangle}
\newcommand{\weakrule}{\triangle_{0}}
\newcommand{\apprule}{@}
\newcommand{\lamrule}{\lambda}

\newcommand{\byprop}[1]{\stackrel{\hbox{\tiny #1}}{\hbox{=}}}

\newcommand{\IH}{\stackrel{\hbox{\tiny I.H.}}{\hbox{=}}}

\colorlet{myGreen}{green!40!gray}

\newcommand{\lambdabar}{\mbox{\textipa{\textcrlambda}}}

\def\infinity{\rotatebox{90}{8}}

\newdimen\arrowsize
\pgfarrowsdeclare{delta}{delta}{
        \arrowsize=0.8pt
        \advance\arrowsize by .5\pgflinewidth
        \pgfarrowsleftextend{-.5\pgflinewidth}
        \pgfarrowsrightextend{2\arrowsize-.5\pgflinewidth}
}{
        \arrowsize=.8pt
        \advance\arrowsize by .5\pgflinewidth
        \pgfsetdash{}{0pt} % do not dash
        \pgfsetmiterjoin        % fix join
        \pgfsetbuttcap  % fix cap
        \pgfpathmoveto{\pgfpoint{2\arrowsize}{0pt}}
        \pgfpathlineto{\pgfpoint{0pt}{\arrowsize}}
        \pgfpathlineto{\pgfpoint{0pt}{-\arrowsize}}
        \pgfpathclose
        \pgfusepathqstroke
}

\pgfarrowsdeclare{triangle}{triangle}{
        \arrowsize=1pt
        \advance\arrowsize by .5\pgflinewidth
        \pgfarrowsleftextend{-\arrowsize-.5\pgflinewidth}
        \pgfarrowsrightextend{-.5\pgflinewidth}
}{
        \arrowsize=1pt
        \advance\arrowsize by .5\pgflinewidth
        \pgfsetdash{}{0pt} % do not dash
        \pgfsetmiterjoin        % fix join
        \pgfsetrectcap  % fix cap
        \pgfpathmoveto{\pgfpointorigin}
        \pgfpathlineto{\pgfpointpolar{150}{\arrowsize}}
        \pgfpathlineto{\pgfpointpolar{210}{\arrowsize}}
        \pgfpathclose
        \pgfusepathqfillstroke
}


% PICTURE PRESETS

\tikzstyle{AL}=[>=triangle,x=5mm,y=5mm]
\tikzstyle{dot}=[circle,fill,inner sep=0pt,minimum size=1pt]


% PICTURE COMPONENTS

% triple dots
\newcommand\ALdots[1]{
        \path (#1) node[dot]{} -- +(-3pt,0) node[dot] {} -- +(3pt,0) node[dot]{};
}

        % diagonal bar (for bundles)
\newcommand\ALbar[1]{
        \draw #1 +(2pt,1pt) -- +(-2pt,-1pt);
}
        % general term box
\newcommand\ALnodeT[4][.4]{
        \node [inner sep=4pt, minimum height=.6cm, minimum width=#1cm, shape=rectangle, style=draw, rounded corners] (#4) at (#3) {$#2$};
        \coordinate (#4_top) at ([above=1pt] #4.north);
        \coordinate (#4_bot) at (#4.south);
        \coordinate (#4_lbot) at ([left=3pt] #4.south);
        \coordinate (#4_rbot) at ([right=3pt] #4.south);
}
        % lambda node
\newcommand\ALnodeL[2]{
        \node [inner sep=2pt] (#2) at (#1) {$\lambda$};
        \coordinate (#2_1) at (#2.north);
        \coordinate (#2_2) at (#2.south);
        \coordinate (#2_3) at (#2.east)
}
        % fake lambda node
\newcommand\ALnodeP[2]{
        \node [inner sep=2pt] (#2) at (#1) {$\lambda$};
        \coordinate (#2_1) at (#2.north);
        \coordinate (#2_2) at (#2.south);
        \coordinate (#2_3) at (#2.east)
}
        % application node
\newcommand\ALnodeA[2]{
        \node [inner sep=2pt] (#2) at (#1) {$@$};
        \coordinate (#2_1) at (#2.north);
        \coordinate (#2_2) at (#2.south);
        \coordinate (#2_3) at (#2.east)
}
        % sharing node
\newcommand\ALnodeS[3][.5]{
        \path (#2) -- +(-#1,0.3) coordinate (#3_left) -- +(0,0.3) coordinate (#3_mid) -- +(#1,0.3) coordinate (#3_right) -- +(0,-0.3) coordinate (#3_tip);
        \draw ([above=1pt] #3_tip) -- ([below=1pt] #3_left) -- ([below=1pt] #3_right) -- cycle
}
        % co-sharing node
\newcommand\ALnodeC[3][.5]{
        \path (#2) -- +(-#1,0.3) coordinate (#3_left) -- +(0,0.3) coordinate (#3_mid) -- +(#1,0.3) coordinate (#3_right) -- +(0,-0.3) coordinate (#3_tip);
        \draw [fill=gray] ([above=1pt] #3_tip) -- ([below=1pt] #3_left) -- ([below=1pt] #3_right) -- cycle
}
        % upside-down co-sharing node
\newcommand\ALnodeCup[3][.5]{
        \path (#2) -- +(-#1,-0.3) coordinate (#3_left) -- +(0,-0.3) coordinate (#3_mid) -- +(#1,-0.3) coordinate (#3_right) -- +(0,0.3) coordinate (#3_tip);
        \draw [fill=gray] ([below=1pt] #3_tip) -- (#3_left) -- (#3_right) -- cycle
}
        % nullary sharing node
\newcommand\ALnodeSnull[2]{
        \path (#1) -- +(-.2,.1) coordinate (#2_left) -- +(.2,.1) coordinate (#2_right) -- +(0,-0.1) coordinate (#2_tip);
        \draw (#2_tip) -- (#2_left) -- (#2_right) -- cycle
}

\newcommand\BA{{\scriptstyle B\!\raisebox{.5ex}{$\scriptstyle A$}}}
\newcommand\imp{\mathbin\rightarrow}
\newcommand\con{\mathbin\wedge}
\newcommand\adbmal{\reflectbox{$\lambda$}}
\newcommand\red{\color{red}}
\newcommand\blue{\color{blue}}
\newcommand\black{\color{black}}
\newcommand\dirL{{\scriptscriptstyle\shortleftarrow}}
\newcommand\dirR{{\scriptscriptstyle\shortrightarrow}}
\newcommand\dirRL{{\scriptscriptstyle\leftrightarrow}}
\newcommand\dirSTOP{{\scriptscriptstyle\bot}}
\newcommand\var{{\scriptstyle\square}}

% ================================================== FRONTMATTER

\bibliographystyle{plainurl}

\title{Spinal Atomic Lambda-Calculus}

\author
{Tom Gundersen}
{Red Hat, Inc.}
{teg@jklm.no}
{}
{}

\author
{Willem Heijltjes}
{University of Bath, UK \and \url{http://www.cs.bath.ac.uk/~wbh22/}}{w.b.heijltjes@bath.ac.uk}
{}
{Supported by EPSRC Project EP/R029121/1 \emph{Typed lambda-calculi with sharing and unsharing}}


\author
{Michel Parigot}
{Institut de Recherche en Informatique Fondamentale, CNRS \&\ Universit\'e de Paris, France} 
{michel.parigot@gmail.com}
{}
{Supported by ANR project 15-CE25-0014 FISP}

\author
{David Rhys Sherratt}
{Friedrich-Schiller University Jena, Germany}
{david.rhys.sherratt@uni-jena.de}
{}
{}

\authorrunning{T.E.\ Gundersen, W.B.\ Heijltjes, M.\ Parigot, and D.R.\ Sherratt}

\Copyright{Tom E.\ Gundersen, Willem B.\ Heijltjes, Michel Parigot, and David R.\ Sherratt}

\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10002950.10003714.10003732.10003733</concept_id>
<concept_desc>Mathematics of computing~Lambda calculus</concept_desc>
<concept_significance>500</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Mathematics of computing~Lambda calculus}

\keywords{Lambda-Calculus, Full laziness, Deep inference, Curry--Howard}

%\acknowledgements{}

%\nolinenumbers


% ================================================== PAPER

\begin{document}

\maketitle

\begin{abstract}
We present the spinal atomic $\lambda$-calculus, a typed $\lambda$-calculus with explicit sharing and atomic duplication that achieves spinal full laziness: duplicating only the direct paths between a binder and bound variables is enough for beta reduction to proceed. We show how this calculus is the result of a Curry--Howard style interpretation of a deep inference proof system, and prove that it has natural properties with respect to the $\lambda$-calculus: confluence and preservation of strong normalization.

\end{abstract}

\section{Introduction}

In the $\lambda$-calculus, a main source of efficiency is \emph{sharing}: multiple use of a single subterm, commonly expressed through graph reduction~\cite{Wadsworth-1971} or explicit substitution~\cite{Abadi-Cardelli-Curien-Levy-1991}. This work, and the \emph{atomic $\lambda$-calculus}~\cite{Gundersen-Heijltjes-Parigot-2013-LICS} on which it builds, is an investigation into sharing as it occurs naturally in intuitionistic \emph{deep-inference} proof theory~\cite{Tiu-2006}.

The atomic $\lambda$-calculus arose as a Curry--Howard interpretation of a deep-inference proof system, in particular of the \emph{distribution} rule below left, a variant of the characteristic \emph{medial} rule~\cite{Brunnler-Tiu-2001,Tiu-2006}. In the term calculus, the corresponding \emph{distributor} construct enables duplication to proceed \emph{atomically}, on individual constructors, in the style of sharing graphs \cite{Lamping-1990}. As a consequence, the natural reduction strategy in the atomic $\lambda$-calculus is \emph{fully lazy}~\cite{Wadsworth-1971,Balabonski-2012}: it duplicates only the minimal part of a term, the \emph{skeleton}, that can be obtained by lifting out subterms as explicit substitutions.%
\footnote{While duplication is atomic \emph{locally}, a duplicated abstraction does not form a redex until also its bound variables have been duplicated; hence duplication becomes fully lazy \emph{globally}.}
\[
	\text{\small Distribution:}
\quad
	\drv{A\rightarrow (B\wedge C);-[d];(A\rightarrow B)\wedge(A\rightarrow C)}
\qquad\qquad
	\text{\small Switch:}
\quad
	\drv{(A\rightarrow B)\wedge C;-[s];A\rightarrow(B\wedge C)}
\]
In this work, we investigate the computational interpretation of another characteristic deep-inference proof rule: the \emph{switch} rule above right~\cite{Tiu-2006}.%
\footnote{The switch rule is an intuitionistic variant of \emph{weak} or \emph{linear distributivity}~\cite{Cockett-Seely-1997} for multiplicative linear logic.}
Our result is the \emph{spinal atomic $\lambda$-calculus}, a term calculus in which the natural strategy is a refined form of full laziness, \emph{spine duplication}. This strategy duplicates only the \emph{spine} of an abstraction: the paths to its bound variables in the syntax tree of the term.

We illustrate these notions below, for the example term $\lambda x.\lambda y.((\lambda z.z)y)x$. The \emph{scope} of the abstraction $\lambda x$ is the entire subterm, $\lambda y.((\lambda z.z)y)x$ (which may or may not be taken to include $\lambda x$ itself). Note that with explicit substitution, the scope may grow or shrink by lifting explicit substitutions in or out. The \emph{skeleton}, indicated in blue below, is the term $\lambda x.\lambda y.(wy)x$ where the subterm $\lambda z.z$ is lifted out as an (explicit) substitution $[\lambda z.z/w]$. The \emph{spine} of a term, indicated in red in the second image, cannot naturally be expressed with explicit substitution, though one can get an impression with \emph{capturing} substitutions: it would be $\lambda x.\lambda y.wx$, with the subterm $(\lambda z.z)y$ extracted by a capturing substitution $[(\lambda z.z)y/w]$. Observe further that the skeleton can be described as the \emph{iterated spine}: it is the smallest subgraph of the syntax tree closed under taking the spine of each abstraction, i.e.\ that contains the spine of every abstraction it contains.
%

{\small \centering   
	\raisebox{0.25cm}{
	\begin{tikzpicture}[auto, scale = 0.75]
		\filldraw[fill = orange!20, draw = orange!70, rounded corners] (-0.3, -2.75) rectangle (0.3, -4);
		%%%%%%%%%%%%%
		\node (a) at (0, 0) {$\lambda x$};
		\node (b) at (0, -0.75) {$\lambda y$};
		\node (c) at (0, -1.5) {$@$};
		\node (d) at (0, -2.25) {$@$};
		\node (e) at (0, -3) {$\lambda z$};
		\node (f) at (0, -3.75) {$z$};
		\node (g) at (0.75, -3) {$y$};
		\node (h) at (1.5, -2.25) {$x$};
		%%%%%%%%%%%%%
		\draw [very thick, blue] (a) to (b);
		\draw [very thick, blue] (b) to (c);
		\draw [very thick, blue] (c) to (d);
		\draw [very thick, blue, rounded corners] (d) -| (g);
		\draw [very thick, blue, rounded corners] (c) -| (h);
		\draw (d) to (e);
		\draw (e) to (f);
	\end{tikzpicture}}
	}
	\hspace{1cm}
{\small   \begin{tikzpicture}[auto, scale = 0.75]
		\filldraw[fill = yellow!20, draw = yellow!70, rounded corners] (-0.55, -2) rectangle (1.125, -4.25);
		\filldraw[fill = orange!20, draw = orange!70, rounded corners] (-0.3, -2.75) rectangle (0.3, -4);
		%%%%%%%%%%%%%
		\node (a) at (0, 0) {$\lambda x$};
		\node (b) at (0, -0.75) {$\lambda y$};
		\node (c) at (0, -1.5) {$@$};
		\node (d) at (0, -2.25) {$@$};
		\node (e) at (0, -3) {$\lambda z$};
		\node (f) at (0, -3.75) {$z$};
		\node (g) at (0.75, -3) {$y$};
		\node (h) at (1.5, -2.25) {$x$};
		%%%%%%%%%%%%%
		\draw [very thick, red] (a) to (b);
		\draw [very thick, red] (b) to (c);
		\draw (c) to (d);
		\draw [rounded corners] (d) -| (g);
		\draw [very thick, red, rounded corners] (c) -| (h);
		\draw (d) to (e);
		\draw (e) to (f);
	\end{tikzpicture}}
	\hspace{1cm}
	\raisebox{1.5cm}{
	\begin{tabular}{l c}
		{\small Skeleton} &
		 \raisebox{0.5ex}{\begin{tikzpicture}[auto]
			\draw [blue, very thick] (0, 0) to (1, 0);
		\end{tikzpicture}}  \\[0.2cm]
		{\small Spine} & \raisebox{0.5ex}{{\begin{tikzpicture}[auto]
			\draw [red, very thick] (0, 0) to (1, 0);
		\end{tikzpicture}}} \\[0.2cm]
		{\small Subterms} &
		 \raisebox{-1ex}{\begin{tikzpicture}[auto]
			\filldraw[fill = yellow!20, draw = yellow!70, rounded corners] (0, 0) rectangle (0.5, 0.5);
			\filldraw[fill = orange!20, draw = orange!70, rounded corners] (0+0.75, 0) rectangle (0.5+0.75, 0.5);
		\end{tikzpicture}}
	\end{tabular}}


The above notions give rise to four natural duplication regimes. For a shared abstraction to become available as the function in a $\beta$-redex: \emph{laziness} duplicates its \emph{scope} \cite{Launchbury-1993}; \emph{Full laziness} duplicates its \emph{skeleton} \cite{Wadsworth-1971}; \emph{Spinal full laziness} duplicates its \emph{spine}; \emph{Optimal reduction} duplicates only the abstraction $\lambda x$ and its bound variables $x$ \cite{Lamping-1990,Asperti-Guerrini-1998}.%
\footnote{Interestingly, Balabonski~\cite{Balabonski-2012} shows that for \emph{weak} reduction (where one does not reduce under an abstraction) full laziness and spinal full laziness are both optimal (in the number of beta-steps required to reach a normal form).}

While each of these duplication strategies has been expressed in graphs and labelled calculi, the atomic $\lambda$-calculus is the first term calculus with Curry--Howard corresponding proof system to naturally describe full laziness. Likewise, the spinal atomic $\lambda$-calculus presented here is the first term calculus with Curry--Howard corresponding proof system to naturally describe spinal full laziness.

%\begin{description}
%\item[Laziness] duplicates its \emph{scope} \cite{Launchbury1993, ariolafelleisen1997};
%\item[Full laziness] duplicates its \emph{skeleton} \cite{wadsworth1971semantics, Balabonski12, gundersen2013atomic};
%\item[Spinal full laziness] duplicates its \emph{spine} \cite{Blanc2005, blanc2007sharing};
%\item[Optimal reduction] duplicates only the abstraction $\lambda x$ and its bound variables $x$ \cite{lamping1989algorithm, van2004lambdascope}.%
%\footnote{Interestingly, Balabonski \cite{Balabonski12} shows that for \emph{weak} reduction (where one does not reduce under an abstraction) full laziness and spinal full laziness are both optimal (in the number of beta-steps required to reach a normal form).}
%\end{description}

\paragraph*{Switch and Spine}

One way to describe the skeleton or the spine of an abstraction within a $\lambda$-term is through explicit end-of-scope markers, as explored by Berkling and Fehr~\cite{Berkling-Fehr-1982}, and more recently by Hendriks and Van Oostrom \cite{Hendriks-VanOostrom-2003}. We use their \emph{adbmal} ($\adbmal$) to illustrate the idea: the constructor $\adbmal x.N$ indicates that the subterm $N$ does not contain occurrences of $x$ (or that any that do occur are not available to a binder $\lambda x$ outside $\adbmal x.N$). The scope of an abstraction thus becomes explicitly indicated in the term. This opens up a distinction between \emph{balanced} and \emph{unbalanced} scopes: whether scopes must be properly nested, or not; for example, in $\lambda x.\lambda y.N$, a subterm $\adbmal y.\adbmal x.M$ is balanced, but $\adbmal x.\adbmal y.M$ is not. With balanced scope, one can indicate the skeleton of an abstraction; with unbalanced scope (which Hendriks and Van Oostrom dismiss) one can indicate the spine. We do so for our example term $\lambda x.\lambda y.((\lambda z.z)y)x$ below. 
%
\[
\text{\small Balanced:}
~~{\blue\lambda x. \lambda y. ((\adbmal y.({\black\adbmal x.\lambda z.z})y)(\adbmal y.x)}
\qquad
\text{\small Unbalanced:}
~~{\red\lambda x. \lambda y. ({\black\adbmal x. (\adbmal y.\lambda z.z)y})(\adbmal y.x)}
\]
%
A closely related approach is \emph{director strings}, introduced by Kennaway and Sleep \cite{Kennaway-Sleep-1988} for combinator reduction and generalized to any reduction strategy by Fern\'{a}ndez, Mackie, and Sinot in \cite{Fernandez-Mackie-Sinot-2005}. The idea is to use nameless abstractions identified by their nesting (as with De Bruijn indices), and make the paths to bound variables explicit by annotating each constructor with a string of \emph{directors}, one for each binder: \emph{left} $(^\dirL)$, \emph{right} $(^\dirR)$, \emph{both} $(^\dirRL)$, \emph{none} $(^\dirSTOP)$. Using $\lambda$ for nameless abstraction and $\var$ for nameless variable, our example becomes as follows (where the red directors are those for $x$).
\[
\text{\small Director strings:}~~\red\lambda.(\lambda.({\black((\lambda.\var)\var)^\dirR}\var)^{\dirR\black\dirL})^\dirR
\]
The primary aim of these approaches is to eliminate $\alpha$-conversion and to streamline substitution. Consequently, while they can \emph{identify} the spine, they do not readily isolate it for duplication, as would be required for spinal full laziness.

The basis of the present work is the observation that the \emph{switch} rule in open deduction functions as a proof-theoretic end-of-scope construction. However, it does so in a \emph{structural} way: it forces a deconstruction of a proof into readily duplicable parts, which together may form the spine of an abstraction. We illustrate this below with two typing derivations for our example, where we let $x$ have type $A$ and $y,z$ type $A\imp B$, shortened to $\BA$. For a formal definition of how these derivations are constructed, see the next section.
\[
\scalebox{0.9}{
\drv{
 \drv[orange]{\top;-[\lambda];\BA\imp\BA}
 ;-[\lambda];
 A\imp
 \drv[blue!60!white]{
  (\BA\rightarrow\BA)\con A
  ;-[\lambda];
  \BA\imp
  \drv[blue!80!white]{
   (\BA\imp\BA)\con A\con\BA
   ;.;
   \drv[blue]{(\BA\imp\BA)\con\BA;-[@];\BA}\con A
   ;-[@];
   B
}}}}
\qquad\qquad
\scalebox{0.9}{
\drv{
 \drv[red]{\top;-[a];A\imp A}
 \con
 \drv[yellow!60!white]{
  \top
  ;-[a];
  \BA\imp\drv[yellow]{
   \BA
   ;.;
   \drv[orange]{\top;-[a];\BA\imp\BA}
   \con\BA
   ;-[@];\BA
 }}
 ;-[s];
 \drv[red!60!white]{
  A\imp
  \drv[red!80!white]{
   A\con(\BA\imp\BA)
   ;.;
   (\BA\imp\BA)\con A
   ;-[s];
   \BA\imp\drv[red]{\BA\con A;-[@];B}
}}}}
\]
An abstraction $\lambda x$ corresponds in the proof system to an implication $A\imp$, explicitly scoping over its right-hand side. On the left, with the \emph{abstraction} rule $(\lambda)$, scopes must be balanced, and the proof system may identify the \emph{skeleton}; here, that of $\lambda x$ as the largest blue box. Decomposing the abstraction $(\lambda)$ into \emph{axiom} $(a)$ and \emph{switch} $(s)$, on the right the proof system may express unbalanced scope. It does so by separating the scope of an abstraction into multiple parts; here, that of $\lambda x$ is captured as the two top-level red boxes. Each box is ready to be duplicated; in this way, one may duplicate only the spine of an abstraction.

Our investigation is then focused on the interaction of switch and distribution (later observed in the rewrite rule \ref{red:distshare}). The use of the distribution rule allows us to perform duplication atomically, and thus provides a natural strategy for spinal full laziness. In our example on the right, this means duplicating the two top-level red boxes can be done independently from duplicating the yellow box.

%In Section \ref{sec:typingacalculus}, we introduce a simple sharing calculus that we expand on in Section \ref{chap:salc}, where we introduce the syntax and semantics of the spinal atomic $\lambda$-calculus, and its typing system. In Section \ref{chap:snosr} we further study the reduction rules that allow for spinal duplication, and prove natural properties of these rules such as termination and confluence. In Section \ref{chap:posn} we extend these results to include beta reduction, and show preservation of strong normalisation with respect to the $\lambda$-calculus. We conclude in Section \ref{chap:conc}.



\section{Typing a $\lambda$-calculus in open deduction}

\label{sec:typingacalculus}

We work in \emph{open deduction}~\cite{Guglielmi-Gundersen-Parigot-2010}, a formalism of deep-inference proof theory, using the following proof system for (conjunction--implication) intuitionistic logic. A \emph{derivation} from a \emph{premise} formula $X$ to a \emph{conclusion} formula $Z$ is constructed inductively as in Figure \ref{fig:derivations}, with from left to right: a propositional atom $a$, where $X = Z = a$; \emph{horizontal composition} with a connective $\rightarrow$, where $X = Y \rightarrow X_{2}$ and $Z = Y \rightarrow Z_{2}$; \emph{horizontal composition} with a connective $\wedge$, where $X = X_{1} \wedge X_{2}$ and $Z = Z_{1} \wedge Z_{2}$; and \emph{rule composition}, where $r$ is an inference rule (Figure \ref{fig:abstraction}) from $Y_{1}$ to $Y_{2}$. The boxes serve as parentheses (since derivations extend in two dimensions) and may be omitted. Derivations are considered up to associativity of rule composition. One may consider formulas as derivations that omit rule composition. We work modulo associativity, symmetry, and unitality of conjunction, justifying the $n$-ary contraction, and may omit $\top$ from the axiom rule. A $0$-ary contraction, with conclusion $\top$, is a \emph{weakening}. Figure \ref{fig:abstraction}: the abstraction rule ($\lambda$) is derived from axiom and switch. \emph{Vertical composition} of a derivation from $X$ to $Y$ and one from $Y$ to $Z$, depicted by a dashed line, is a defined operation, given in Figure \ref{fig:vertical}, where $* \in \set{\wedge, \rightarrow}$.

\begin{figure}[h]
\centering
  \begin{subfigure}[b]{0.45\textwidth}
    \scalebox{0.9}{$
      \drv{X;|;Z}
      ~{:}{:}{=}~ a
      ~\mid~	  Y \imp \drv[yellow]{X_{2};|;Z_{2}}
      ~\mid~	  \drv[yellow]{X_1\!;|;Z_1\!} \con 
      			  \drv[yellow]{X_2\!;|;Z_2\!}
      ~\mid~ \drv{\drv[yellow]{X;|;Y_1\!} ;-[r];
      			  \drv[yellow]{Y_2\!;|;Z}}
    $}
    \caption{\small Derivations}
    \label{fig:derivations}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.525\textwidth}
	\scalebox{0.9}{$
	  \begin{array}{@{}c@{\qquad}c@{\qquad}c@{}}
		  \drv{\top\vphantom(;-[a];X\imp X}
		& \drv{(X\imp Y)\con X;-[@];Y}
		& \drv{X\vphantom(;-[\sharerule];X\con\dots\con X}
		\\ \\
		  \drv{(X\imp Y)\con Z;-[s];X\imp(Y\con Z)}
		& \multicolumn{2}{@{}c@{}}{
			\drv{X\vphantom(;-[\lambda];Y\imp(X\con Y)} ~~{:}{=}~~
			\drv{
			  \drv[yellow]{\top;-[a];Y\imp Y} \con X 
			  ;-[s]; 
			  Y\imp(X\con Y)
		  }}
	  \end{array}
	$}
	\caption{\small Axiom, Application, Contraction, Switch, Abstraction}
	\label{fig:abstraction}
	\end{subfigure}
	\\
	\begin{subfigure}[b]{\textwidth}
\scalebox{0.9}{ 
\drv{\drv[yellow]{X ; | ; Y} ; . ; \drv[yellow]{Y ; | ; Z}} ~{:}{=}~ \drv{X ; . ; \drv[yellow]{X ; | ; Z}} $=$ \drv{\drv[yellow]{X ; | ; Z} ; . ; Z} $=$ \drv{X ; | ; Z}}
\hfill
 \scalebox{0.9}{\drv{\drv[yellow]{\drv[magenta]{A ; | ; B} ; -[r] ; \drv[green]{C ; | ; D}} ; . ; \drv[cyan]{D ; | ; E}} $=$ \drv{ \drv[magenta]{A ; | ; B} ; -[r] ; \drv[yellow]{ \drv[green]{C ; | ; D} ; . ; \drv[cyan]{D ; | ; E}}}
} 
\hfill
 \scalebox{0.9}{\drv{ \drv[magenta]{A ; | ; B} ; . ; \drv[yellow]{ \drv[green]{B ; | ; C} ; -[r] ; \drv[cyan]{D ; | ; E}}} $=$ \drv{\drv[yellow]{\drv[magenta]{A ; | ; B} ; . ; \drv[green]{B ; | ; C}} ; -[r] ; \drv[cyan]{D ; | ; E}}
} 
 \hfill
\scalebox{0.9}{
\drv{ \drv[yellow]{\drv[magenta]{X_{1} ; | ; Y_{1}} * \drv[orange]{X_{2} ; | ; Y_{2}}} ; . ; \drv[yellow]{\drv[cyan]{Y_{1} ; | ; Z_{1}} * \drv[green]{Y_{2} ; | ; Z_{2}}}}
=
\drv{\drv[yellow]{ \drv[magenta]{X_{1} ; | ; Y_{1}} ; . ; \drv[cyan]{Y_{1} ; | ; Z_{1}}} * \drv[yellow]{ \drv[orange]{X_{2} ; | ; Y_{2}} ; . ; \drv[green]{Y_{2} ; | ; Z_{2}} }}
}
	\caption{Vertical composition}
	\label{fig:vertical}
	\end{subfigure}
%	\begin{subfigure}[b]{0.2\textwidth}
%	\centering
%		{\small \drv{Y \rightarrow \drv[yellow]{X ; | ; Z}}}
%	\caption{Implication}
%	\label{fig:implication}
%	\end{subfigure}
%	\hfill
	\caption{Intuitionistic Proof System in Open Deduction}
\end{figure}

\subsection{The Sharing Calculus}

Our starting point is the \emph{sharing calculus} ($\SLC$), a calculus with an explicit sharing construct, similar to explicit substitution.

\begin{definition}
\label{def:sharingcalsyntax}
The \defn{pre-terms} $r,s,t,u$ and \defn{sharings} $[\Gamma]$ of the $\SLC$ are defined by:
\[
	s,t 
	~{:}{:}{=}~ x 
	~\mid~ \abs xt 
	~\mid~ \app st 
	~\mid~ u[\Gamma] 
\qquad
	[\Gamma] ~{:}{:}{=}~ \share{}{x_{1}, \dots, x_{n}}{s}
\]
with from left to right: a \defn{variable}; an \defn{abstraction}, where $x$ occurs free in $t$ and becomes bound; an \defn{application}, where $t$ and $s$ use distinct variable names; and a \defn{closure}; in $\share{u}{\vec{x}}{s}$ the variables in the vector $\vec{x} = x_{1}, \dots, x_{n}$ all occur in $t$ and become bound, and $t$ and $s$ use distinct variable names. \defn{Terms} are pre-terms modulo \defn{permutation} equivalence ($\sim$):
\[
	\share{t}{\vec{x}}{s} \share{}{\vec{y}}{r} \sim t \share{}{\vec{y}}{r} \share{}{\vec{x}}{s} \quad \quad (\set{\vec{y}} \cap \fv{s} = \set{} )
\]
A term is in \defn{sharing normal form} if all sharings occur as $\share{}{\vec{x}}{x}$ either at the top level or directly under a binding abstraction, as $\abs{x}{\share{t}{\vec{x}}{x}}$.
\end{definition}

\noindent Note that variables are \emph{linear}: variables occur at most once, and bound variables must occur. A vector $\vec{x}$ has length $\size{\vec{x}}$ and consist of the variables $x_{1}, \dots, x_{\size{\vec{x}}}$. An \emph{environment} is a sequence of sharings $\overline{[\Gamma]} = [\Gamma_{1}] \dots [\Gamma_{n}]$. Substitution is written $\sub{}{x}{t}$, and $\sub{}{t_{1}}{x_{1}} \dots \sub{}{t_{n}}{x_{n}}$ may be abbreviated to $\sub{}{t_{i}}{x_{i}}_{i \in [n]}$.

\begin{definition}
The \defn{interpretation} of a term $t$ as the $\lambda$-term $\readbackclose{t}$ given as follows
$$\readbackclose{x} = x \quad \readbackclose{\abs{x}{t}} = \abs{x}{\readbackclose{t}} \quad \readbackclose{\app{s}{t}} = \app{\readbackclose{s}}{\readbackclose{t}} \quad \readbackclose{\share{t}{\vec{x}}{s}} = \readbackclose{t} \sub{}{\readbackclose{s}}{x_{i}}_{i \in [n]}$$
The \defn{translation} $\compile{N}$ of a $\lambda$-term $N$ is the unique sharing-normal term $t$ such that $N = \readbackclose{t}$.
\end{definition}

A term $t$ will be typed by a derivation with restricted types, as shown below, where the \emph{context type} $\Gamma = A_{1} \wedge \dots \wedge A_{n}$ will have an $A_{i}$ for each free variable $x_{i}$ of $t$. We connect free variables to their premises by writing $A^{x}$ and $\Gamma^{\vec{x}}$. The $\SLC$ is then typed as in Figure \ref{fig:SLCT}.

\begin{figure}[h]
\begin{center}
Basic Types: $A, B, C \quad {:}{=} \quad a \, \, \, \vert \, \, \, A \rightarrow B$ \hspace{1cm} Context Types: $\Gamma, \Delta, \Omega \quad {:}{=} \quad A \, \, \, \vert \, \, \, \top \, \, \, \vert \, \, \, \Gamma \wedge \Delta$
\end{center}
$x :$ \scalebox{0.9}{ \drv{A^{x}}}
\hfill
$\app{t}{s} :$ \scalebox{0.9}{ \drv{\drv[yellow]{\Gamma ; |[t] ; A \rightarrow B} \wedge \drv[yellow]{\Delta ; |[s] ; A} ; -[\apprule] ; B}}
\hfill
$\abs{x}{t} :$ \scalebox{0.9}{ \drv{\Gamma ; -[\lamrule] ; A \rightarrow \drv[yellow]{\Gamma \wedge A^{x} ; |[t] ; B}}}
\hfill
$\share{t}{\vec{x}}{s} :$ \scalebox{0.9}{ \drv{\Gamma \wedge \drv[yellow]{\Delta ; |[s] ; A ; -[\sharerule] ; A \wedge \dots \wedge A} ; . ; \Gamma \wedge (A \wedge \dots \wedge A)^{\vec{x}} ; |[t] ; B}}
\caption{Typing System for $\SLC$}
\label{fig:SLCT}
\end{figure}

\section{The Spinal Atomic $\lambda$-Calculus}
\label{chap:salc}

We now formally introduce the syntax of the spinal atomic $\lambda$-calculus ($\FALC$), by extending the definition of the sharing calculus in Definition \ref{def:sharingcalsyntax} with a \emph{distributor} construct that allows for atomic duplication of terms.

\begin{definition}[Pre-Terms] The \defn{pre-terms} $r, s, t$, \defn{closures} $[\Gamma]$, and \defn{environments} $\overline{[\Gamma]}$ of the $\FALC$ are defined by:

\begin{center}
$t \quad {:}{:}{=} \quad x \quad \vert \quad \app{s}{t} \quad \vert \quad \fake{x}{\vec{y}}{t} \quad \vert \quad t[\Gamma]$
%\end{center}
%\begin{center}
\\[0.2cm]
$[\Gamma] \quad {:}{:}{=} \quad  [\vec{x} \leftarrow t] \quad \vert \quad \dist{}{\fakedist{e_{1}}{\vec{x_{1}}} \dots \fakedist{e_{n}}{\vec{x_{n}}}}{\overline{[\Gamma]}}{d}{\vec{y}}$  \quad \quad $\overline{[\Gamma]} \quad {:}{:}{=} \quad [\Gamma] \quad \vert \quad \overline{[\Gamma]}[\Gamma]$
\end{center}

\end{definition}

First note that we denote abstractions such that $\abs{x}{t} \equiv \fake{x}{x}{t}$. We introduce a new notion of abstraction called \emph{phantom-abstraction}, which can be intuitively be thought of as a partially duplicated abstraction. An abstraction $\fake{x}{x}{t}$ and a phantom-abstraction $\fake{x}{\vec{y}}{t}$ are two instances of the same construct. We call the variables inside the brackets the \emph{cover} of the abstraction. If the cover is the same as the preceeding variable, then it is an abstraction, otherwise it is a phantom-abstraction and we call the preceeding variable a \emph{phantom-variable}.

The distributor $\dist{u}{\fakedist{e_{1}}{\vec{x_{1}}} \dots \fakedist{e_{n}}{\vec{x_{n}}}}{\overline{[\Gamma]}}{d}{\vec{y}}$ captures the phantom-variables $e_{1}, \dots, e_{n}$ in $u$ and the covers associated with those phantom-variables are captured by the environment $\overline{[\Gamma]}$. We sometimes write the distributor as $\dist{u}{\vecdist{e}{x}}{\overline{[\Gamma]}}{d}{\vec{y}}$ when we are not concerned about the binding of phantom-variables. Terms are then pre-terms with sensible and correct bindings. To define terms, we first define \emph{free} and \emph{bound} variables and phantom variables; variables are bound by abstractions (not phantoms) and by sharings, while phantom-variables are bound by distributors. 

\begin{definition}[Free and Bound Variables]
\label{def:freeboundvar} The free variables $\fv{-}$ and bound variables $\bv{-}$ of a pre-term $t$ are defined as follows
\begingroup
\allowdisplaybreaks
	\begin{align*}
		\fv{x} &= \set{x} & \bv{x} &= \set{} \\
		\fv{\app{s}{t}} &= \fv{s} \cup \fv{t} & \bv{\app{s}{t}} &= \bv{s} \cup \bv{t} \\
		\fv{\fake{x}{x}{t}} &= \fv{t} - \set{x} & \bv{\fake{x}{x}{t}} &= \bv{t} \cup \set{x} \\
		\fv{\fake{c}{\vec{x}}{t}} &= \fv{t} & \bv{\fake{c}{\vec{x}}{t}} &= \bv{t} \\
		\fv{\share{u}{\vec{x}}{t}} &= \fv{u} \cup \fv{t} - \set{\vec{x}} & \bv{\share{u}{\vec{x}}{t}} &= \bv{u} \cup \bv{t} \cup \set{\vec{x}}  \\
		\fv{\dist{u}{\vecdist{e}{x}}{\overline{[\Gamma]}}{c}{c}} &= \fv{u \overline{[\Gamma]}} - \set{c} & \bv{\dist{u}{\vecdist{e}{x}}{\overline{[\Gamma]}}{c}{c}} &= \bv{u \overline{[\Gamma]}} \\
		\fv{\dist{u}{\vecdist{e}{x}}{\overline{[\Gamma]}}{c}{\vec{y}}} &= \fv{u \overline{[\Gamma]}} \cup \set{c} & \bv{\dist{u}{\vecdist{e}{x}}{\overline{[\Gamma]}}{c}{\vec{y}}} &= \bv{u \overline{[\Gamma]}} \\
	\end{align*}
\endgroup
\end{definition}

\begin{definition}[Free and Bound Phantom-Variables]
\label{def:freeboundphan}
The free phantom-variables $\fp{-}$ and bound phantom-variables $\bp{-}$ of the pre-term $t$ are defined as follows
\begingroup
\allowdisplaybreaks
	\begin{align*}
		\fp{x} &= \set{} & \bp{x} &= \set{} \\
		\fp{\app{s}{t}} &= \fp{s} \cup \fp{t} & \bp{\app{s}{t}} &= \bp{s} \cup \bp{t} \\
		\fp{\fake{x}{x}{t}} &= \fp{t} & \bp{\fake{x}{x}{t}} &= \bp{t}  \\
		\fp{\fake{c}{\vec{x}}{t}} &= \fp{t} \cup \set{c}& \bp{\fake{c}{\vec{x}}{t}} &= \bp{t} \\
		\fp{\share{u}{\vec{x}}{t}} &= \fp{u} \cup \fp{t} & \bp{\share{u}{\vec{x}}{t}} &= \bp{u} \cup \bp{t}
	\end{align*}
	\begin{align*}
	\fp{\dist{u}{\fakedist{e_{1}}{\vec{x_{1}}} \dots \fakedist{e_{n}}{\vec{x_{n}}}}{\overline{[\Gamma]}}{c}{c}} &= \fp{u \overline{[\Gamma]}} - \set{e_{1}, \dots, e_{n}} \\
	\bp{\dist{u}{\fakedist{e_{1}}{\vec{x_{1}}} \dots \fakedist{e_{n}}{\vec{x_{n}}}}{\overline{[\Gamma]}}{c}{c}} &= \bp{u \overline{[\Gamma]}} \cup \set{e_{1}, \dots, e_{n}} \\
	\fp{\dist{u}{\fakedist{e_{1}}{\vec{x_{1}}} \dots \fakedist{e_{n}}{\vec{x_{n}}}}{\overline{[\Gamma]}}{c}{\vec{y}}} &= \fp{u \overline{[\Gamma]}} \cup \set{c} - \set{e_{1}, \dots, e_{n}} \\
	\bp{\dist{u}{\fakedist{e_{1}}{\vec{x_{1}}} \dots \fakedist{e_{n}}{\vec{x_{n}}}}{\overline{[\Gamma]}}{c}{\vec{y}}} &= \bp{u \overline{[\Gamma]}} \cup \set{e_{1}, \dots, e_{n}}
	\end{align*}
\endgroup
\end{definition}

\noindent With these definitions, we can formally define the terms of $\FALC$.

\begin{definition}[Terms]
\label{def:falcterms}
A \defn{term} $t \in \FALC$ is a pre-term with the following constraints
\begin{enumerate}
	\item  Each variable may occur at most once.
	\item In an abstraction $\fake{x}{x}{t}$, $x \in \fv{t}$.
	\item In a phantom-abstraction $\fake{c}{x_{1}, \dots, x_{n}}{t}$, $\set{x_{1}, \dots, x_{n}} \subset \fv{t}$.
	\item  In a sharing $\share{u}{x_{1}, \dots, x_{n}}{t}$, $\set{x_{1}, \dots, x_{n}} \subset \fv{u}$.
	\item  In a distributor $\dist{u}{\fakedist{e_{1}}{w^{1}_{1}, \dots, w^{1}_{k_{1}}} \dots \fakedist{e_{n}}{w^{n}_{1}, \dots, w^{n}_{k_{n}}}}{\overline{[\Gamma]}}{c}{c}$
	\begin{enumerate}
		\item For all $1 \leq i \leq n$ and $1 \leq m \leq k_{n}$, $w^{i}_{m} \fv{u}$ and becomes bound by $\overline{[\Gamma]}$ .
		\item $\set{\fakedist{e_{1}}{w^{1}_{1}, \dots, w^{1}_{k_{1}}}, \dots, \fakedist{e_{n}}{w^{n}_{1}, \dots, w^{n}_{k_{n}}}} \subset \fc{u}$, and $\set{e_{1}, \dots, e_{n}} \subset \fp{u}$, and each $e_{i}$ becomes bound.
		\item The variable $c$ occurs somewhere in the environments $\overline{[\Gamma]}$.
	\end{enumerate}
	\item  In a distributor $\dist{u}{\fakedist{e_{1}}{w^{1}_{1}, \dots, w^{1}_{k_{1}}} \dots \fakedist{e_{n}}{w^{n}_{1}, \dots, w^{n}_{k_{n}}}}{\overline{[\Gamma]}}{c}{y_{1}, \dots, y_{m}}$
	\begin{enumerate}
		\item Both $5(a)$ and $5(b)$ hold.
		\item For all $1 \leq i \leq m$, $y_{i}$ occurs in the environments $\overline{[\Gamma]}$.
	\end{enumerate}
\end{enumerate}

\end{definition}

We also work modulo permutation with respect to the variables in the cover of phantom-abstractions. Let $\vec{x}$ be a list of variables and let $\vec{x_{P}}$ be a permutation of that list, then the following terms are considered equal.

\begin{center}
	$\share{u}{\vec{x}}{t} \sim \share{u}{\vec{x_{P}}}{t}$
	\hspace{1cm}
	$\fake{c}{\vec{x}}{t} \sim \fake{c}{\vec{x_{P}}}{t}$
\end{center}

\noindent Terms are typed with the typing system for $\SLC$ extended with the \emph{distribution} inference rule. This rule is the result of computationally interpreting the medial rule as done in \cite{Gundersen-Heijltjes-Parigot-2013-LICS}. We obtain this variant of the medial rule due to the restriction for implications and to avoid introducing disjunction to the typing system. The terms of $\FALC$ are then typed as in both Figure \ref{fig:SLCT} and Figure \ref{fig:derivphandist}. Note environments are typed by the derivations of all its closures composed horizontally with the conjunction connective.


\begin{figure}[h]
$\fake{c}{\vec{x}}{t}:$ \scalebox{0.9}{ \drv{(A \rightarrow \Gamma) \wedge \Delta ; -[\switchrule] ; A^{c} \rightarrow \drv[yellow]{\Gamma^{\vec{x}} \wedge \Delta ; |[t] ; C}}}
\hspace{1cm}
$\dist{u}{\vecdist{e}{x}}{\overline{[\Gamma]}}{c}{\vec{z}}: $ \scalebox{0.9}{ \drv{\drv{\drv[yellow]{(C \rightarrow \Gamma) \wedge \Delta ; -[\switchrule] ; C^{c} \rightarrow
	\drv[cyan]{\Gamma^{\color{black} \vec{z}} \wedge \Delta ; |[{\color{black} \overline{[\Gamma]}} ] ; \Sigma_{1} \wedge \dots \wedge \Sigma_{n}} ; -[\distrule] ; (C^{\color{black}e_{1}} \rightarrow \Sigma_{1}^{\vec{\color{black}x_{1}}}) \wedge \dots \wedge  (C^{\color{black}e_{n}} \rightarrow \Sigma_{n}^{\vec{\color{black}x_{n}}})}
	\wedge \Omega} ; . ; (C \rightarrow \Sigma_{1}) \wedge \dots \wedge (C \rightarrow \Sigma_{n}) \wedge \Omega ; |[u] ; E} }
\caption{Typing derivations for phantom-abstractions and distributors}
\label{fig:derivphandist}
\end{figure}

\subsection{Compilation and Readback}

We now define the translations between $\FALC$ and the original $\lambda$-calculus. First we define the interpretation $\Lambda \rightarrow \FALC$ (\emph{compilation}). Intuitively, it replaces each abstraction $\lambda x . -$ with the term $\fake{x}{x}{\share{-}{x_{1}, \dots, x_{n}}{x}}$ where $x_{1}, \dots, x_{n}$ replace the occurrences of $x$. Actual substitutions are denoted as $\sub{}{t}{x}$. Let $\size{M}_{x}$ denote the number of occurrences of $x$ in $M$, and if $\size{M}_{x} = n$ let $M \frac{n}{x}$ denote $M$ with the occurrences of $x$ by fresh, distinct variables $x^{1}, \dots, x^{n}$. First, the translation of a \emph{closed} term $M$ is $\compile{M}'$, defined below

\begin{definition}[Compilation]
\label{def:compile}
The interpretation for closed lambda terms, $\compile{\Lambda}' : \Lambda \rightarrow \FALC$ is defined below
%\begin{align*}
%	\compile{x}' &= x \\
%	\compile{\app{M}{N}}' &= \app{\compile{M}'}{\compile{N}'} \\
%	\compile{\abs{x}{M}}' &=
%	\begin{cases}
%		\fake{x}{x}{\compile{M}'} & \text{if } \size{M}_{x} = 1 \\
%		\fake{x}{x}{\share{\compile{M \frac{n}{x}}'}{x^{1}, \dots, x^{n}}{x}} & \text{if } \size{M}_{x} = n \neq 1
%	\end{cases}
%\end{align*}
\[
\begin{aligned}
	\compile{x}' &= x \\
	\compile{\app{M}{N}}' &= \app{\compile{M}'}{\compile{N}'}
\end{aligned}
\qquad
	\compile{\abs{x}{M}}' =
	\begin{cases}
		\fake{x}{x}{\compile{M}'} & \text{if } \size{M}_{x} = 1 \\
		\fake{x}{x}{\share{\compile{M \frac{n}{x}}'}{x^{1}, \dots, x^{n}}{x}} & \text{if } \size{M}_{x} = n \neq 1
	\end{cases}
\]
For an arbitrary term $M$, if $x_{1}, \dots, x_{k}$ are the free variables of $M$ such that $\size{M}_{x_{i}} = n_{i} > 1$, the translation $\compile{M}$ is:
\[
\compile{M \frac{n_{1}}{x_{1}} \dots \frac{n_{k}}{x_{k}} }' \share{}{x^{1}_{1}, \dots, x^{n_{1}}_{1}}{x_{1}} \dots \share{}{x^{1}_{k}, \dots, x^{n_{k}}_{k}}{x_{k}}~.
\]
\end{definition}

The readback into the $\lambda$-calculus is slightly more complicated, specifically due to the bindings induced by the distributor. Interpreting a distributor $\trans{\dist{u}{\fakedist{e_{1}}{\vec{x_{1}}} \dots \fakedist{e_{n}}{\vec{x_{n}}}}{\overline{[\Gamma]}}{c}{c}}$ construct as a $\lambda$-term requires (1) converting the phantom-abstractions it binds in $u$ into abstractions (2) collapsing the environment (3) maintaining the bindings between the converted abstractions and the intended variables located in the environment.


\begin{definition}
Given a total function $\sigma$ with domain $D$ and codomain $C$, we \defn{overwrite} the function with case $x \mapsto V$ where $x \in D$ and $V \in C$ such that

$\sigma [ x \mapsto V ] (z) = \begin{cases} V & z = x \\ \sigma(z) & \text{otherwise}  \end{cases}$
\end{definition}

When using the map $\sigma$ as part of the translation, the intuition is that for all bound variables $x$ in the term we are translatings, it should be that $\sigma(x) = x$. The purpose of the map $\gamma : V \rightarrow V$ is to keep track of the binding of phantom-variables.

\begin{definition}
\label{def:readback}
The interpretation $\readbackwmap{-}{-}{-} : \FALC \times (V \rightarrow \Lambda) \times (V \rightarrow V) \rightarrow \Lambda$ is defined as
\begingroup
\allowdisplaybreaks
\begin{align*}
	\readbackwmap{x}{\sigma}{\gamma} &= \sigma(x) \\[0.2cm]
	\readbackwmap{\app{s}{t}}{\sigma}{\gamma} &= \app{\readbackwmap{s}{\sigma}{\gamma}}{\readbackwmap{t}{\sigma}{\gamma}} \\[0.2cm]
	\readbackwmap{\fake{c}{c}{t}}{\sigma}{\gamma} &= \abs{c}{\readbackwmap{t}{\sigma[c \mapsto c]}{\gamma}} \\[0.2cm]
	\readbackwmap{\fake{c}{x_{1}, \dots, x_{n}}{t}}{\sigma}{\gamma} &= \abs{c}{\readbackwmap{t}{\sigma[x_{i} \mapsto \sigma(x_{i}) \sub{}{c}{\gamma(c)}]_{i \in [n]}}{\gamma}} \\[0.2cm]
	\readbackwmap{\share{u}{x_{1}, \dots, x_{n}}{t}}{\sigma}{\gamma} &= \readbackwmap{u}{\sigma[x_{i} \mapsto \readbackwmap{t}{\sigma}{\gamma}]_{i \in [n]}}{\gamma} \\[0.2cm]
%\end{align*}
%\begin{align*}
	\readbackwmap{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}}, \dots, \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]}}{c}{c}}{\sigma}{\gamma} &= \readbackwmap{u \overline{[\Gamma]}}{\sigma}{\gamma[e_{i} \mapsto c]_{i \in [n]}} \\[0.2cm]
	\readbackwmap{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}}, \dots, \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]}}{c}{x_{1}, \dots, x_{m}}}{\sigma}{\gamma} &= \readbackwmap{u \overline{[\Gamma]}}{\sigma'}{\gamma[e_{i} \mapsto c]_{i \in [n]}} \\
	 & \text{ where } \sigma' = \sigma[x_{i} \mapsto \sigma(x_{i}) \sub{}{c}{\gamma(c)}]_{i \in [n]} \\
\end{align*}
\endgroup

\end{definition}


\noindent The following Proposition justifies working modulo permutation equivalence.

\begin{proposition}
\label{lem:preservedenotationsim}
For $s, t \in \FALC$, if $s \sim t$ then $\trans{s} = \trans{t}$
\end{proposition}

\noindent The following Lemma not only proves we have good translations, but is also important for proving confluence of $\FALC$ (Theorem \ref{theo:strongnormal}).

\begin{lemma}
\label{lem:preserve1to1correspondance}
For a closed $t \in \FALC$, in sharing normal form, and a closed $N \in \Lambda$.
$$\readback{\compile{N}'}{I} = N \hspace{1.5cm} \compile{\readback{t}{I}}' = t \hspace{1.5cm} \exists_{ M \in \Lambda} . t = \compile{M}'$$
\end{lemma}

\subsection{Rewrite Rules}

Both the spinal atomic $\lambda$-calculus and the atomic $\lambda$-calculus of \cite{Gundersen-Heijltjes-Parigot-2013-LICS} follow atomic reduction steps, i.e.\ they apply on individual constructors. The biggest difference is that our calculus is capable of duplicating not only the skeleton but also the spine. The rewrite rules in our calculus make use of 3 operations, \emph{substitution}, \emph{book-keeping}, and \emph{exorcism}. Full definitions can be found in the Appendix, here we describe the intuition.

The operation \emph{substitution} $\sub{t}{s}{x}$ propagates through the term $t$, and replaces the free occurences of the variable $x$ with the term $s$. Moreover, if $x$ occurs in the cover of a phantom-variable $\fakedist{e}{\vec{y} \cdot x}$, then substitution replaces the $x$ in the cover with $\fv{s}$, $\fakedist{e}{\vec{y} \cdot \fv{s}}$. 

Although substitution performs some book-keeping on phantom-abstractions, we define an explicit notion of book-keeping $\psub{}{\vec{y}}{e}$ that updates the variables stored in a free cover i.e.\ for a term $t$, $\fakedist{e}{\vec{x}} \in \fc{t}$ then $\fakedist{e}{\vec{y}} \in \fc{\psub{t}{\vec{y}}{e}}$. 

The last operation we introduce is called \emph{exorcism} $\exor{}{c}{\vec{x}}$. We perform exorcisms on phantom-abstractions to convert them to abstractions. Intuitively, this will be performed on phantom-abstractions with phantom-variables bound to a distributor when said distributor is eliminated. It converts phantom-abstractions to abstractions by introducing a sharing of the phantom-variable that captures the variables in the cover, i.e.\ $\fake{c}{\vec{x}}{t} \exor{}{c}{\vec{x}} = \fake{c}{c}{\share{t}{\vec{x}}{c}}$. 

\begin{proposition}
\label{prop:suboutcomm}
\label{prop:bkcomm}
\label{prop:exorcomm}
The translation $\readbackwmap{u}{\sigma}{\gamma}$ commutes with substitutions, book-keepings, and exorcisms in the following way
\begin{align*}
	\readbackwmap{u \sub{}{t}{x}}{\sigma}{\gamma} &= \readbackwmap{u}{\sigma[x \mapsto \readbackwmap{t}{\sigma}{\gamma}]}{\gamma} \\[0.2cm]
	\readbackwmap{u \psub{}{\vec{x}}{c}}{\sigma}{\gamma} &= \readbackwmap{u}{\sigma}{\gamma} \\[0.2cm]
	\readbackwmap{u \exor{}{c}{x_{1}, \dots, x_{n}}}{\sigma}{\gamma} &= \readbackwmap{u}{\sigma[x_{i} \mapsto c]_{i \in [n]}}{\gamma}
\end{align*}

%$$\readbackwmap{u}{\sigma'}{\gamma} = \readbackwmap{u}{\sigma}{\gamma} \sub{}{M}{x}$$
%
%where $\sigma'(z) = \begin{cases} \sigma(z) \sub{}{M}{x} & z \neq x \\ M & \text{otherwise} \end{cases}$
\end{proposition}

Using these operations, we define the rewrite rules that allow for spinal duplication. Firstly we have beta reduction ($\rightsquigarrow_{\beta}$), which strictly requires an abstraction (not a phantom).
\begin{equation}  \label{red:beta} \tag{$\beta$}
\app{(\fake{x}{x}{t})}{s} \rightsquigarrow_{\beta} \sub{t}{s}{x} \hspace{1cm} 
\begin{tabular}{c c c}
	\scalebox{0.9}{ 
		\drv{\drv{\Gamma ; -[\lamrule] ; A \rightarrow \drv[yellow]{A^{x} \wedge \Gamma ; |[t] ; B}} \wedge \drv[green]{\Delta ; |[s] ; A} ; -[\apprule] ; B}
	}
	&
	$\rightsquigarrow_{\beta}$
	&
	\scalebox{0.9}{\drv{\drv{\drv[green]{\Delta ; |[{s}] ; A} \wedge \Gamma} ; . ; \drv[yellow]{A \wedge \Gamma ; |[t] ; B}}}
\end{tabular}
\end{equation}
Here $\beta$-reduction is a linear operation, since the bound variable $x$ occurs exactly once in the body $t$. Any duplication of the term t in the atomic $\lambda$-calculus proceeds via the sharing reductions. 

The first set of sharing reduction rules move closures towards the outside of a term. Most of these rewrite rules only change the typing derivations in the way that subderivations are composed, with the exception of moving a closure out of scope of a distributor.
\begin{align}
\app{s[\Gamma]}{t} &\rightsquigarrow_{L} (\app{s}{t})[\Gamma]   \label{red:liftappleft} \tag{$l_{1}$} \\
\app{s}{t[\Gamma]} &\rightsquigarrow_{L} (\app{s}{t})[\Gamma] \label{red:liftappright} \tag{$l_{2}$} \\
\fake{d}{\vec{x}}{t[\Gamma]} &\rightsquigarrow_{L} (\fake{d}{\vec{x}}{t})[\Gamma]  \text{ if } \set{\vec{x}} \cap \fv{t} = \set{\vec{x}}  \label{red:liftabs} \tag{$l_{3}$} \\
\share{u}{\vec{x}}{t[\Gamma]} &\rightsquigarrow_{L} \share{u}{\vec{x}}{t}[\Gamma] \label{red:liftshare} \tag{$l_{4}$}
\end{align}
For the case of lifting a closure outside a distributor, we use a notation $\bindvars{[\Gamma]}$ to identify the variables captured by a closure, i.e.$\bindvars{\share{}{\vec{x}}{t}} = \set{\vec{x}}$ and $\bindvars{\dist{}{\fakedist{e_{1}}{\vec{x_{1}}}, \dots, \fakedist{e_{n}}{\vec{x_{x}}}}{\overline{[\Gamma]}}{c}{c}} = \set{\vec{x_{1}}, \dots, \vec{x_{n}}}$. Then let $\set{\vec{z}} = \bindvars{[\Gamma]}$ in the following rewrite rule, that can only occur if $\set{\vec{x}} \cap \fv{[\Gamma]} = \set{}$.
\begin{equation} \label{red:distshare} \tag{$l_{5}$}
\begin{multlined}
\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}} \dots \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]} [\Gamma]}{c}{\vec{x}} \\ \rightsquigarrow_{L} \dist{u {\psub{}{(\vec{w_{i}} / \vec{z})}{e_{i}}}_{i \in [n]}}{\fakedist{e_{1}}{\vec{w_{1}} / \vec{z}} \dots \fakedist{e_{n}}{\vec{w_{n}} / \vec{z}}}{\overline{[\Gamma]}}{c}{\vec{x}}[\Gamma]
\end{multlined}
\end{equation}

The proof rewrite rule corresponding with the rewrite rule \ref{red:distshare} can be broken down into two parts. The first part is readjusting how the derivations compose as shown below.

\begin{center}
\begin{tabular}{c c c}
	\scalebox{0.9}{\drv{(C \rightarrow \Gamma) \wedge \Delta \wedge \Omega ; -[\switchrule] ; C^{\color{red} c} \rightarrow \drv[yellow]{\drv[green]{\Gamma^{\color{red} \vec{x}} \wedge \Delta \wedge \drv[cyan]{\Omega ; |[\color{red} {[\Gamma]} ] ; A \wedge \dots \wedge A}} ; |[{\color{red} \overline{[\Gamma]}}] ; \Sigma_{1}^{{\color{red} \vec{w_{1}}}} \dots \Sigma_{n}^{{\color{red} \vec{w_{n}}}} } ; -[\distrule] ; (C \rightarrow \Sigma_{1}) \wedge \dots \wedge (C \rightarrow \Sigma_{n})}}
	& $\rightsquigarrow_{L}$ &
	\scalebox{0.9}{\drv{(C \rightarrow \Gamma) \wedge \Delta \wedge \drv[cyan]{\Omega ; |[\color{red} {[\Gamma]}] ; A \wedge \dots \wedge A} ; -[\switchrule] ; C^{\color{red} c} \rightarrow \drv[yellow]{\drv[green]{\Gamma^{\color{red} \vec{x}} \wedge \Delta \wedge A \dots A} ; |[\color{red} { \overline{[\Gamma]}}] ; \Sigma_{1}^{{\color{red} \vec{w_{1}}}} \dots \Sigma_{n}^{{\color{red} \vec{w_{n}}}} } ; -[\distrule] ; (C \rightarrow \Sigma_{1}) \wedge \dots \wedge (C \rightarrow \Sigma_{n})}}
\end{tabular}
\end{center}
The second part of the rewrite rule justifies the need for the book-keeping operation. In the rewrite below, let $A$ be the type of a variable $z$ where $z \in \vec{z}$. After lifting, we want to remove the variable from the cover as to ensure correctness since the variables in the cover denote the variables captured by the environment. Book-keeping allows us to remove these variables simultaneously.
\begin{center}
\begin{tabular}{c c c}
	\scalebox{0.9}{\drv{(C \rightarrow \Gamma^{\color{red} \vec{x}}) \wedge \Delta \wedge A ; -[\switchrule] ; C^{\color{red} c} \rightarrow \drv[yellow]{\drv[green]{\Gamma \wedge \Delta ; |[{\color{red} \overline{[\Gamma]}}] ; \Sigma_{1} \wedge \dots \wedge \Sigma_{n}} \wedge A^{{\color{red} z}} ; . ; \Sigma_{1} \wedge \dots \wedge \Sigma_{i} \wedge A \wedge \dots \wedge \Sigma_{n}}  ; -[\distrule] ; \dots \wedge (C^{{\color{red} e_{i}}} \rightarrow \Sigma_{i}^{{\color{red} \vec{w}}} \wedge A) \wedge \dots}}
	& $\rightsquigarrow$ &
	\scalebox{0.9}{\drv{\drv{(C \rightarrow \Gamma^{\color{red} \vec{x}}) \wedge \Delta ; -[\switchrule] ; C^{\color{red} c} \rightarrow \drv[yellow]{\drv[green]{\Gamma \wedge \Delta ; |[{\color{red} \overline{[\Gamma]}}] ; \Sigma_{1} \wedge \dots \wedge \Sigma_{n}} ; . ; \Sigma_{1} \wedge \dots \wedge \Sigma_{i} \wedge \dots \wedge \Sigma_{n}}  ; -[\distrule] ; \dots \wedge (C \rightarrow \Sigma_{i}) \wedge \dots}\wedge A^{\color{red} z} ; . ; \dots \wedge \drv[cyan]{(C^{\color{red} e_{i}} \rightarrow \Sigma_{i}^{{\color{red} \vec{w} }}) \wedge A ; -[\switchrule] ; C \rightarrow \Sigma_{i} \wedge A} \wedge \dots}}
\end{tabular}
\end{center}

The lifting rules ($l_{i}$) are justified by the need to lift closures out of the distributor, as opposed to duplicating them. The second set of rewrite rules, consecutive sharings are compounded and unary sharings are applied as substitutions. For simplicity, in the equivalent proof rewrite step we only show the binary case for each rule.
\begin{align}
\share{\share{u}{w_{1}, \dots, w_{m}}{y_{i}}}{y_{1}, \dots, y_{n}}{t} & \rightsquigarrow_{C} \share{u}{y_{1}, \dots, y_{i-1}, w_{1}, \dots, w_{m}, y_{i+1}, \dots, y_{n}}{t}   \label{red:mergeshare} \tag{$c_{1}$} \\
\share{u}{x}{t} & \rightsquigarrow_{C} \sub{u}{t}{x} \label{red:compshare} \tag{$c_{2}$}
\end{align}
\begin{center}
\begin{tabular}{c c}
	{\small \drv{A ; -[\sharerule] ; A \wedge \drv[yellow]{A ; -[\sharerule] ; A \wedge A}}} \hspace{0.1cm} $\rightsquigarrow_{C}$ \hspace{0.1cm} {\small \drv{A ; -[\sharerule] ; A \wedge A \wedge A}} \hspace{0.5cm} & 
{\small \drv{A ; -[\sharerule] ; A}} \hspace{0.1cm} $\rightsquigarrow_{C}$ \hspace{0.1cm} {\small \drv{A}}
\end{tabular}
\end{center}
The atomic steps for duplicating are given in the third and final set of rewrite rules. The first being the atomic duplication step of an application, which is the same rule used in \cite{Gundersen-Heijltjes-Parigot-2013-LICS}. The binary case proof rewrite steps for each rule are also provided. 
\begin{equation} \label{red:appdup} \tag{$d_{1}$}
\share{u}{x_{1} \dots x_{n}}{\app{s}{t}} \rightsquigarrow_{D} \share{\share{\sub{\sub{u}{\app{z_{1}}{y_{1}}}{x_{1}}\dots}{\app{z_{n}}{y_{n}}}{x_{n}}}{z_{1} \dots z_{n}}{s}}{y_{1} \dots y_{n}}{t}
\end{equation}
\begin{center}
{\small \drv{(A \rightarrow B) \wedge A ; -[\apprule] ; B ; -[\sharerule] ; B \wedge B}}
\hspace{0.25cm}
$\rightsquigarrow_{D}$
\hspace{0.25cm}
{\small \drv{\drv{(A \rightarrow B) ; -[\sharerule] ; (A \rightarrow B) \wedge (A \rightarrow B)} \wedge \drv{B ; -[\sharerule] ; B \wedge B} ; . ; \drv{(A \rightarrow B) \wedge A ; -[\apprule] ; B} \wedge \drv{(A \rightarrow B) \wedge A ; -[\apprule] ; B}}}
\end{center}
\begin{equation} \label{red:absdup} \tag{$d_{2}$}
\begin{multlined}
\share{u}{x_{1}, \dots, x_{n}}{\fake{c}{\vec{y}}{t}} \rightsquigarrow_{D} \\
\sub{u}{\fake{e_{i}}{w_{i}}{w_{i}}}{x_{i}}_{i \in [n]} \dist{}{\fakedist{e_{1}}{w_{1}} \dots \fakedist{e_{n}}{w_{n}}}{\share{}{w_{1}, \dots, w_{n}}{t}}{c}{\vec{y}}
\end{multlined}
\end{equation}
\begin{center}
{\small \drv{(A \rightarrow B) \wedge \Gamma ; -[\switchrule] ; A \rightarrow \drv[yellow]{B \wedge \Gamma ; | ; C} ; -[\sharerule] ; (A \rightarrow C) \wedge (A \rightarrow C)}}
\hspace{0.25cm}
$\rightsquigarrow_{D}$
\hspace{0.25cm}
{\small \drv{(A \rightarrow B) \wedge \Gamma ; -[\switchrule] ; A \rightarrow \drv[yellow]{B \wedge \Gamma ; | ; C ; -[\sharerule] ; C \wedge C} ; -[\distrule] ; (A \rightarrow C) \wedge (A \rightarrow C)}}
\end{center}
\begin{equation} \label{red:distelim} \tag{$d_{3}$}
\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}} \dots \fakedist{e_{n}}{\vec{w_{n}}}}{\share{}{\vec{w_{1}}, \dots, \vec{w_{n}}}{c}}{c}{c} \rightsquigarrow_{D} \exor{\exor{u}{e_{1}}{\vec{w_{1}}} \dots}{e_{n}}{\vec{w_{n}}}
\end{equation}
\begin{center}
{\small \drv{ ; -[a] ; A \rightarrow \drv{A ; -[\sharerule] ; A \wedge A} ; -[\distrule] ; (A \rightarrow A) \wedge (A \rightarrow A)}}
\hspace{0.25cm}
$\rightsquigarrow_{D}$
\hspace{0.25cm}
{\small \drv{\drv{ ; -[a] ; A \rightarrow A} \wedge \drv{ ; -[a] ; A \rightarrow A}}}
\end{center}

\noindent As an example, observe $\share{u}{z_{1}, z_{2}}{\abs{x}{\app{(\abs{z}{z})}{\abs{y}{\app{(\app{y}{y})}{x}}}}}$ (note $\abs{x}{t} \equiv \fake{x}{x}{t}$). By (\ref{red:absdup}) we obtain $\dist{u'}{\fakedist{e_{1}}{z_{1}}, \fakedist{e_{2}}{z_{2}}}{\share{}{z_{1}, z_{2}}{\app{(\abs{z}{z})}{\abs{y}{\app{(\app{y}{y})}{x}}}}}{x}{x}$ where $u' = u\sub{}{\fake{e_{i}}{z_{i}}{z_{i}}}{z_{i}}_{i \in [2]}$. Then by reductions (\ref{red:appdup}, \ref{red:distshare}), we obtain the distributor $\dist{u''}{\fakedist{e_{1}}{z_{1}}, \fakedist{e_{2}}{z_{2}}}{\share{}{z_{1}, z_{2}}{\abs{y}{\app{(\app{y}{y})}{x}}}}{x}{x}$ where $u'' = u\sub{}{\fake{e_{i}}{z_{i}}{\app{a_{i}}{z_{i}}}}{z_{i}}_{i \in [2]}$. Then by (\ref{red:absdup}, \ref{red:appdup}, \ref{red:distshare}, \ref{red:distshare}) we obtain the distributor $\dist{u'''}{\fakedist{e_{1}}{z_{1}}, \fakedist{e_{2}}{z_{2}}}{\share{}{z_{1}, z_{2}}{x}}{x}{x}$ which can be eliminated by (\ref{red:distelim}). A full example can be found in the Appendix. 

Each rewrite rule preserves the conclusion of the derivation, and thus the following proposition is easy to observe.

\begin{proposition}
If $s \rightsquigarrow_{(L, C, D, \beta)} t$ and $s : C$, then $t : C$
\end{proposition}

\noindent The readback translation collapses the shared terms. The lifting, duplication, and compound rules are used solely for the duplication of terms. Therefore it is expected that the following Lemma be true (proven in Appendix by induction). It is also important for proving confluence of $\FALC$ (Theorem \ref{theo:strongnormal}).

\begin{lemma}
\label{lem:preservesdenotation}
 If $s \rightsquigarrow_{(L, D, C)} t$ then $\readbackwmap{s}{\sigma}{\gamma} = \readbackwmap{t}{\sigma}{\gamma}$
\end{lemma}

\section{Strong Normalisation of Sharing Reductions}
\label{chap:snosr}

In order to show our calculus is strongly normalising, we first show that the sharing reduction rules are strongly normalising. To do this, we make use of an intermediate calculus called the \emph{weakening calculus}. Following the approach of \cite{Gundersen-Heijltjes-Parigot-2013-LICS}, we indite a measure on terms based on its connection with the weakening calculus. We show that this measure strictly decreases as sharing reduction progresses. Additionally, similar ideas and results can be found elsewhere: with \emph{memory} in \cite{Klop-1980}, the \emph{$\lambda$-$I$ calculus} in \cite{Barendregt-1984}, the \emph{$\lambda$-void calculus} \cite{Accattoli-Kesner-2012}, and the weakening $\lambda\mu$-calculus \cite{He-2018}.


\begin{definition}
\label{def:weakterms}
The $\weaksymbol$-terms of the weakening calculus ($\WEAK$) are
\begin{equation*}
	T, U, V \quad {:}{:}{=} \quad x \quad \vert \quad \abs{x}{T^{*}}\quad \vert \quad \app{U}{V} \quad \vert \quad \share{T}{}{U} \quad \vert \quad \bullet \hfill \text{(*) where $x \in \fv{T}$}
\end{equation*}
\end{definition}

The terms are variable, abstraction, application, weakening, and a bullet. In the weakening $\share{T}{}{U}$, the subterm $U$ is \emph{weakened}. The interpretation of atomic terms to weakening terms $\readweakwmap{-}{-}{-}$ can be seen as an extension of the translation into the $\lambda$-calculus (Definition \ref{def:readback}).

\begin{definition}
\label{def:transfalcweak}
	The interpretation $\readweakwmap{-}{-}{-} : \FALC \times (V \rightarrow \WEAK) \times (V \rightarrow V) \rightarrow \WEAK$ with maps $\sigma : V \rightarrow \WEAK$ and $\gamma : V \rightarrow V$ is defined as an extension of the translation in (Definition \ref{def:readback}) with the following additional special cases.
	\begin{align*}
		\readweakwmap{\share{u}{}{t}}{\sigma}{\gamma} &= \share{\readweakwmap{u}{\sigma}{\gamma}}{}{\readweakwmap{t}{\sigma}{\gamma}} \\[0.2cm]
		\readweakwmap{\dist{u}{}{\overline{[\Gamma]}}{c}{c}}{\sigma}{\gamma} &= \readweakwmap{u \overline{[\Gamma]}}{\sigma[c \mapsto \bullet]}{\gamma} \\[0.2cm]
		\readweakwmap{\dist{u}{}{\overline{[\Gamma]}}{c}{x_{1}, \dots, x_{n}}}{\sigma}{\gamma} &= \readweakwmap{u \overline{[\Gamma]}}{\sigma'}{\gamma} \\
		& \text{where } \sigma'(z) = \begin{cases} \sigma(z) \sub{}{\bullet}{\gamma(c)} & z \in \set{x_{1}, \dots, x_{n}} \\ \sigma(z) & \text{otherwise} \end{cases} \\
	\end{align*}
\end{definition}

\noindent We also have translations of the weakening calculus to and from the lambda calculus. Both of these translations were provided in \cite{Gundersen-Heijltjes-Parigot-2013-LICS}. The interpretation $\readbackweak{-}$ from weakening terms to $\lambda$-terms discards all weakenings. The interpretation $\compweak{-} : \Lambda \rightarrow \WEAK$ is defined below.

\begin{definition}
\label{def:transweak}
The interpretation $M \in \Lambda$, $\compweak{-} : \Lambda \rightarrow \WEAK$ is defined by
\begin{align*}
	\compweak{x} &= x \\
	\compweak{\app{M}{N}} &= \app{\compweak{M}}{\compweak{N}} \\
	\compweak{\abs{x}{N}} &=
	\begin{cases}
		\abs{x}{\compweak{N}} & \text{if } x \in \fv{N} \\
		\abs{x}{\compweak{N} \share{}{}{x}} & \text{otherwise}
	\end{cases}
\end{align*}
\end{definition}
\noindent The following equalities can be observed, where $\sigma^{\Lambda}(z) = \readbackweak{\sigma^{\weaksymbol}(z)} $.
\begin{proposition}
\label{prop:equalterms}
For $N \in \Lambda$ and $t \in \FALC$ the following properties hold
\begin{center}
\begin{tabular}{c@{\hskip 0.5in} c@{\hskip 0.5in} c}
	$\readbackweak{\readweakwmap{t}{\sigma^{\weaksymbol}}{\gamma}} = \readbackwmap{t}{\sigma^{\Lambda}}{\gamma}$
	&
	$\composeweak{\compile{N}} = \compweak{N}$
	&
	$\readbackweak{\compweak{N}} = N$
\end{tabular}

\end{center}

\end{proposition}

\begin{definition}
In the weakening calculus, $\beta$-reduction is defined as follows, where $\overline{[\Gamma]}$ are weakening constructs.
\begin{equation}
\tag{$\weaksymbol_{\beta}$}
	\app{((\abs{x}{T}) \overline{[\Gamma]})}{U} \rightarrow_{\beta} \sub{T}{U}{x} \overline{[\Gamma]} \\
\end{equation}
\end{definition}

\noindent Here we can take advantage that preservation of strong normalisation has been proven for this weakening calculus already in~\cite{Gundersen-Heijltjes-Parigot-2013-LICS}, providing the proof for Proposition \ref{prop:willemresult}.

\begin{proposition}
\label{prop:willemresult}
 If $N \in \Lambda$ is strongly normalising, then so is $\compweak{N}$
\end{proposition}

When translating from the spinal atomic $\lambda$-calculus to the weakening calculus, weakenings are maintained whilst sharings are interpreted through duplication via substitution. Thus the reduction rules in the weakening calculus cover the spinal reductions for nullary distributors and weakenings.

\begin{definition}
Weakening reduction ($\rightarrow_{\weaksymbol}$) proceeds as follows.
\begingroup
\allowdisplaybreaks
\begin{align*}
	\tag{$\weaksymbol_{1}$}
	\abs{x}{\share{T}{}{U}} &\rightarrow_{\weaksymbol} (\abs{x}{T})\share{}{}{U} \quad \text{if } x \not\in \fv{U} \\
	\tag{$\weaksymbol_{2}$}
	\app{\share{U}{}{T}}{V} &\rightarrow_{\weaksymbol} (\app{U}{V}) \share{}{}{T} \\
	\tag{$\weaksymbol_{3}$}
	\app{U}{\share{V}{}{T}} &\rightarrow_{\weaksymbol} (\app{U}{V}) \share{}{}{T} \\
	\tag{$\weaksymbol_{4}$}
	\share{T}{}{\share{U}{}{V}} &\rightarrow_{\weaksymbol} \share{T}{}{U} \share{}{}{V} \\
	\tag{$\weaksymbol_{5}$}
	\share{T}{}{\abs{x}{U}} &\rightarrow_{\weaksymbol} \share{T}{}{U \sub{}{\bullet}{x}} \\
	\tag{$\weaksymbol_{6}$}
	\share{T}{}{\app{U}{V}} &\rightarrow_{\weaksymbol} T \share{}{}{U} \share{}{}{V} \\
	\tag{$\weaksymbol_{7}$}
	\share{T}{}{\bullet} &\rightarrow_{\weaksymbol} T \\
	\tag{$\weaksymbol_{8}$}
	\share{T}{}{U} &\rightarrow_{\weaksymbol} T \quad \text{if $U$ is a subterm of $T$}
\end{align*}
\endgroup
\end{definition}
\noindent It is easy to see that most these rules correspond to special cases of the sharing reduction rules for $\FALC$. It is not so obvious to see what the case ($\weaksymbol_{8}$) corresponds to. If $U$ is a subterm of $T$, then in the corresponding $\FALC$-term this term would be shared and one of the copies would be in a weakening. Thus this reduction relates to the case (\ref{red:mergeshare}), where we remove the weakening. We demonstrate by considering $t \share{}{}{y} \share{}{\vec{x} \cdot y \cdot \vec{z}}{u}  \rightsquigarrow_{C} t \share{}{\vec{x} \cdot \vec{z}}{u}$. On the left hand side, the corresponding weakening-term (obtained by $\compweak{-}$) would have the weakening $\share{}{}{U}$ where $U = \compweak{u}$. This is because $U$ is substituted into $\share{}{}{y}$, but on the right hand side this would be gone. This situation can only occur if there are other copies of $U$ substituted into the term. This corresponds to if only the corresponding (\ref{red:mergeshare}) reduction rule can occur. This resemblace is confirmed by the following Lemmas.

\begin{lemma}
\label{lem:sharepreservebeta}
	If $t \rightsquigarrow_{\beta} u$ then $\composeweak{t} \rightarrow^{\plus}_{\beta} \composeweak{u}$
\end{lemma}

\begin{lemma}
\label{theo:sharepreserve}
	If $t \rightsquigarrow_{(C, D, L)} u$ and for any $x \in \bv{t} \cup \fp{t}$ and for all $z$, $x \not\in \fv{\sigma(z)}$.  $$\readweakwmap{t}{\sigma}{\gamma} \rightarrow^{*}_{\weaksymbol} \readweakwmap{u}{\sigma}{\gamma}$$

\end{lemma}

We now define the components that we use for our measure on spinal atomic $\lambda$-terms that we will use to prove strong normalisation of sharing reductions. The \emph{height} of a term is intuitively a multiset of integers that record the distance of each sharing. The distance is measured by the number of constructors from the sharing node to the root of the term in its graphical notation. The height is defined on terms as $\height{i}{-}$, where $i$ is an integer. We say $\height{}{t}$ for $\height{1}{t}$. We use $\cupdot$ to denote the disjoint union of two multisets. We denote $\height{i}{[\Gamma_{1}]} \cupdot \dots \cupdot \height{i}{[\Gamma_{n}]}$ as $\height{i}{\overline{[\Gamma]}}$ for the environment $\overline{[\Gamma]} = [\Gamma_{1}], \dots, [\Gamma_{n}]$.

\begin{definition}[Sharing Height]
The sharing height $\height{i}{t}$ of a term $t$ is given by
\begingroup
\allowdisplaybreaks
\begin{align*}
	\height{i}{x} &= \set{} \\
	\height{i}{ \app{s}{t} } &= \height{i+1}{s} \cupdot \height{i+1}{t} \\
	\height{i}{\fake{c}{\vec{x}}{t}} &= \height{i + 1}{t} \\
	\height{i}{t[\Gamma]} &= \height{i}{t} \cupdot \height{i}{[\Gamma]} \cupdot \set{i^{1}} \\
	\height{i}{\share{}{x_{1}, \dots, x_{n}}{t}} &= \height{i+1}{t}\\
	\height{i}{\dist{}{\vecdist{e}{\vec{w}}}{\overline{[\Gamma]}}{c}{\vec{x}}} &= \height{i + 1}{\overline{[\Gamma]}} \cupdot \set{(i + 1)^{n}} \text{ where $n$ is the number of closures in $\overline{[\Gamma]}$}
\end{align*}
\endgroup
\end{definition}

\noindent This measure then strictly decreases for the rewrite rules \ref{red:liftappleft}, \ref{red:liftappright}, \ref{red:liftabs}, \ref{red:liftshare} and \ref{red:distshare}.

\begin{lemma}
\label{theo:liftingheight}
If $t \rightsquigarrow_{L} u$ then $\height{i}{t} > \height{i}{u}$
\end{lemma}

The other measure we consider is the \emph{weight} of a term. Intuitively this quantifies the remaining duplications, which are performed with $\rightsquigarrow_{D}$ reductions. Calculating the weight of a term requires an auxiliary function from variables to integers. This function is defined by assigning integer weights to the variables of a term. This auxiliary function is defined on terms $\weightvar{i}{-}$, where $i$ is an integer. To measure variables independently of binders is vital. It allows to measure distributors, which duplicate $\lambda$'s but not the bound variable. Also, only bound variables for abstractions are measured since variables bound by sharings are substituted in the interpretation.

\begin{definition}[Variable Weights]
The function $\weightvar{i}{t}$ returns a function that assigns integer weights to the free variables of $t$. It is defined by the following
\begingroup
\allowdisplaybreaks
\begin{align*}
	\weightvar{i}{x} &= \set{x \mapsto i} \\
	\weightvar{i}{\app{s}{t}} &= \weightvar{i}{s} \cupdot \weightvar{i}{t} \\
	\weightvar{i}{\fake{c}{c}{t}} &= \weightvar{i}{t} / \set{c} \\
	\weightvar{i}{\fake{c}{\vec{x}}{t}} &= \weightvar{i}{t} \cupdot \set{c \mapsto i} \\
	\weightvar{i}{\share{t}{}{s}} &= \weightvar{i}{t} \cupdot \weightvar{1}{s} \\
	\weightvar{i}{\share{t}{x_{1}, \dots, x_{n}}{s}} &= \weightvar{i}{t} / \set{x_{1}, \dots, x_{n}} \cupdot \weightvar{f(x_{1}) + \dots + f(x_{n})}{s} \text{ where } f = \weightvar{i}{t} \\
	\weightvar{i}{\dist{t}{\fakedist{e_{1}}{\vec{w_{1}}} \dots \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]}}{c}{c}} &= \weightvar{i}{t\overline{[\Gamma]}} / \set{c, e_{1}, \dots, e_{n}} \\
	\weightvar{i}{\dist{t}{\fakedist{e_{1}}{\vec{w_{1}}} \dots \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]}}{c}{\vec{x}}} &= \weightvar{i}{t\overline{[\Gamma]}} / \set{e_{1}, \dots, e_{n}} \cupdot \set{c \mapsto i}
\end{align*}
\endgroup
\end{definition}

\noindent The weight of a term can then be defined via the use of this auxiliary function. The auxiliary function is used when calculating the weight of a sharing, where the sharing weight of the variables bound by the sharing play a significant role in calculating the weight of the shared term. In the case of a weakening, we assign an initial weight of $1$ to indicate that the constructor is not duplicated by appears at least once in the weakening calculus. Again we say $\weight{}{t} = \weight{1}{t}$.

\begin{definition}[Sharing Weight]
The sharing weight $\weight{i}{t}$ of a term $t$ is a multiset of integers computed by the function defined below
\begingroup
\allowdisplaybreaks
\begin{align*}
	\weight{i}{x} &= \set{} \\
	\weight{i}{\app{s}{t}} &= \weight{i}{s} \cupdot \weight{i}{t} \cupdot \set{i}\\
	\weight{i}{\fake{c}{c}{t}} &= \weight{i}{t} \cupdot \set{i} \cupdot \set{\weightvar{i}{t}(c)} \\
	\weight{i}{\fake{c}{\vec{x}}{t}} &= \weight{i}{t} \cupdot \set{i} \\
	\weight{i}{\share{t}{}{s}} &= \weight{i}{t} \cupdot \weight{1}{s} \\
	\weight{i}{\share{t}{x_{1}, \dots, x_{n}}{s}} &= \weight{i}{t} \cupdot \weight{f(x_{1}) + \dots + f(x_{n})}{s} \text{ where } f = \weightvar{i}{t} \\
	\weight{i}{\dist{t}{\fakedist{e_{1}}{\vec{w_{1}}} \dots \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]}}{c}{c}} &= \weight{i}{t\overline{[\Gamma]}} \cupdot \set{\weightvar{i}{t\overline{[\Gamma]}} (c)} \\ % \cupdot \set{f(e_{1}), \dots, f(e_{n})} \\
	\weight{i}{\dist{t}{\fakedist{e_{1}}{\vec{w_{1}}} \dots \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]}}{c}{\vec{x}}} &= \weight{i}{t\overline{[\Gamma]}}
\end{align*}
\endgroup
\end{definition}

\noindent We show that this measure then strictly decreases on the rewrite rules \ref{red:appdup}, \ref{red:absdup}, \ref{red:distelim} and is unaffected by all the other sharing reduction rules.

\begin{lemma}
\label{theo:decreaseweight}
If $t \rightsquigarrow_{D} u$ then $\weight{i}{t} > \weight{i}{u}$. If $t \rightsquigarrow_{(L, C)} u$ then $\weight{i}{t} = \weight{i}{u}$
\end{lemma}

The last measure we consider is the number of closures in the term, where is can be easily observed that the rewrite rules \ref{red:mergeshare} and \ref{red:compshare} strictly decrease this measure, and that the $\rightsquigarrow_{L}$ rules do not alter the number of closures. We then use this along with height and weight to define a \emph{sharing measure} on terms.

\begin{definition}
\label{def:sharingmeasure}
The \defn{sharing measure} of a $\FALC$-term $t$ is a triple ($\weight{}{t}$, $C$, $\height{}{t}$) where $C$ is the number of closures in $t$. We can compare two different sharing measures by considering the lexicographical preferences according to weight $>$ number of closures $>$ height.
\end{definition}

\begin{theorem}
\label{theo:sharingstronglynormal}
Sharing reduction $\rightsquigarrow_{(D, L, C)}$ is strongly normalising
\end{theorem}
\begin{proof}
From Lemma \ref{theo:decreaseweight} and Lemma \ref{theo:liftingheight}, it follows that the sharing measure of a term is strictly decreasing under $\rightsquigarrow_{(D, L, C)}$, proving the statement.
\end{proof}

\noindent Now that we have proven the sharing reductions are strongly normalising, we can prove that they are confluent for closed terms.

\begin{theorem}
\label{theo:strongnormal}
The sharing reduction relation $\rightsquigarrow_{(D, L, C)}$ is confluent
\end{theorem}
\begin{proof}
 Lemma \ref{lem:preservesdenotation} tells us that the preservation is preserved under reduction i.e.\ for $s \rightsquigarrow_{(D, L, C)} t$, $\readback{s}{} = \readback{t}{}$. Therefore given $t \rightsquigarrow^{*}_{(D, L, C)} s_{1}$ and $t \rightsquigarrow^{*}_{(D, L, C)} s_{2}$, $\readback{t}{} = \readback{s_{1}}{} = \readback{s_{2}}{}$. Since we know that sharing reductions are strongly normalising, we know there exists terms $u_{1}$ and $u_{2}$ in sharing normal form such that $s_{1} \rightsquigarrow^{*}_{(D, L, C)} u_{1}$ and $s_{2} \rightsquigarrow^{*}_{(D, L, C)} u_{2}$. Lemma \ref{lem:preserve1to1correspondance} tells us that terms in closed terms in sharing normal form are in correspondence with their denotations i.e.\ $ \compile{\readback{t}{I}}' = t $. Since by Lemma \ref{lem:preservesdenotation} we know $\readback{u_{1}}{} = \readback{s_{1}}{} = \readback{s_{2}}{} = \readback{u_{2}}{}$, and by Lemma \ref{lem:preserve1to1correspondance} $ \compile{\readback{u_{1}}{I}}' = u_{1} $ and $\compile{\readback{u_{2}}{I}}' = u_{2}$, we can conclude $u_{1} = u_{2}$. Hence, we prove confluence.
\end{proof}

\section{Preservation of Strong Normalisation}
\label{chap:posn}

Here we show how $\FALC$ preserves strong normalisation with respect to the $\lambda$-calculus. Recall that by Proposition \ref{prop:equalterms} that for all $N \in \Lambda$, $\composeweak{\compile{N}} = \compweak{N}$, and that Proposition \ref{prop:willemresult} states if a term $N \in \Lambda$ is strongly normalising then so is $\compweak{N}$. Observe that the statement `if term $M$ has an infinite reduction sequence then term $N$ has an infinite reduction sequence' is equivalent to `if term $N$ is strongly normalising then term $M$ is strongly normalising' by contraposition. Therefore, given a strongly normalising term $N \in \Lambda$, we know that its corresponding weakening term is also strongly normalising. Furthermore, since $\composeweak{\compile{N}} = \compweak{N}$, we know that $\composeweak{\compile{N}}$ is also strongly normalising. We will use the following to prove that the spinal atomic $\lambda$-calculus preserves strong normalisation.

\begin{lemma}
\label{lem:infinitepath}
For $t \in \FALC$ has an infinite reduction path, then $\composeweak{t}$ also has an infinite reduction path.
\end{lemma}

\begin{proof}
Due to Theorem \ref{theo:strongnormal}, we know that the infinite reduction path contains an infinite $\beta$-reduction. This means in the reduction sequence, between each $\beta$-reduction, there are finite many $\rightsquigarrow_{(D, L, C)}$ reduction steps. Lemma \ref{theo:sharepreserve} says each $\rightsquigarrow_{(D, L, C)}$ step in $\FALC$ corresponds to zero or more weakening reductions ($\rightsquigarrow^{*}_{\weaksymbol}$). Lemma \ref{lem:sharepreservebeta} says that each beta reduction in $\FALC$ corresponds to one or more $\beta$-steps in $\WEAK$. Therefore, it is inevitable that $\composeweak{t}$ also has an infinite reduction path.
\end{proof}

\begin{theorem}
 If $N \in \Lambda$ is strongly normalising, then so is $\compile{N}$.
\end{theorem}

\begin{proof}
For a given $N \in \Lambda$ that is strongly normalising, we know by Lemma \ref{prop:willemresult} that $\compweak{N}$ is strongly normalising. Then $\composeweak{\compile{N}}$ is strongly normalising, since Proposition \ref{prop:equalterms} states that $\compweak{N} = \composeweak{\compile{N}}$. Then by Lemma \ref{lem:infinitepath}, which states that if $\composeweak{t}$ is strongly normalising, then $t$ is strongly normalising, proves that $\compile{N}$ is strongly normalising.
\end{proof}

\section{Conclusion, related work, and future directions}
\label{chap:conc}

%We have studied the computational interpretation of the switch rule and discovered its correspondence with scope in the $\lambda$-calculus. We have studied the interaction between the switch and the medial rule, the two characteristic inference rules of deep inference. We interpret a calculus based on this interaction, which not only has the ability to duplicate terms atomically but can also duplicate solely the spine of an abstraction such that beta reduction can be applied on the duplicates. We show that this resulting calculus has natural properties with respect to the $\lambda$-calculus. 

We have studied the computational interpretation of the switch rule and discovered its correspondence with scope in the $\lambda$-calculus. We have studied the interaction between the switch and the medial rule, the two characteristic inference rules of deep inference. We built a Curry--Howard interpretation based on this interaction, whose resulting calculus not only has the ability to duplicate terms atomically but can also duplicate solely the spine of an abstraction such that beta reduction can be applied on the duplicates. We show that this calculus has natural properties with respect to the $\lambda$-calculus.

This work fits into a broader effort to give a computational interpretation to intuitionistic deep-inference proof theory. Br\"unnler and McKinley~\cite{Brunnler-McKinley-2008} give a natural reduction mechanism without medial (or switch), and observe that preservation of strong normalization fails. Guenot and Stra\ss burger~\cite{Guenot-Strassburger-2014} investigate a different switch rule, corresponding to the implication-left rule of sequent calculus. He~\cite{He-2018} extends the atomic lambda-calculus to lambda-mu.

Our aim for the future is to develop the intuitionistic open deduction formalism towards optimal reduction~\cite{Levy-1980,Lamping-1990,Asperti-Guerrini-1998}, via the remaining medial and switch rules~\cite{Tiu-2006}.

%In the future we would like to have a full Curry-Howard correspondence rather than just an interpretation, i.e.\ where each inference rule in the typing system corresponds with a construct in the term calculus. This would mean introducing an explicit end-of-scope operator (such as done in \cite{berkling1976symmetric, hendriks2003lambda, fernandez2005lambda}) to correspond with the switch rule. %Additionally, we are interested in studying the computational interpretation of the same rules with different connectives.
%Additionally, we aim to translate the result of Blanc, L\'{e}vy, and Maranget \cite{blanc2007sharing} into our calculus. There they implement an optimal reduction strategy for Wadsworth's \emph{weak $\lambda$-calculus} \cite{wadsworth1971semantics} (further studied in \cite{CAGMAN1998239}), that makes use of spine duplication. By showing their result in our formalism, we would develop a logical framework that follows an optimal reduction strategy.


%%
%% Bibliography
%%

%% Please use bibtex,

%\bibliography{lipics-v2019-sample-article}

\bibliography{SALC}


%\end{document}

\newpage

\appendix

\section{The Spinal Atomic $\lambda$-Calculus}

\subsection{Compilation and Readback}

In this section we provide the proof for {\bf Proposition \ref{lem:preservedenotationsim}}: For $s, t \in \FALC$, if $s \sim t$ then $\trans{s} = \trans{t}$.

\begin{proof}
Let us consider the cases.
\newline
\newline
$t[\Gamma_{1}][\Gamma_{2}] \sim t[\Gamma_{2}][\Gamma_{1}]$
\newline
Consider $\readbackwmap{t[\Gamma_{1}][\Gamma_{2}]}{\sigma}{\gamma} = \readbackwmap{t[\Gamma_{1}]}{\sigma'}{\gamma'} = \readbackwmap{t}{\sigma''}{\gamma''}$. Since due to conditions any variable $x \in \bindvars{[\Gamma_{2}]}$ cannot occur in $[\Gamma_{1}]$, for all subterms $s$ located in $[\Gamma_{1}]$, $\readbackwmap{s}{\sigma'}{\gamma'} = \readbackwmap{s}{\sigma}{\gamma}$. Therefore $\readbackwmap{t}{\sigma''}{\gamma''} = \readbackwmap{t[\Gamma_{2}]}{\sigma'''}{\gamma'''} = \readbackwmap{t[\Gamma_{2}][\Gamma_{1}]}{\sigma}{\gamma}$.
\newline
\newline
The remaining cases discuss permutations of variables in sharings and phantom-abstractions. In both these cases, we overwrite $\sigma$ for the cases of the variables in said sharing or phantom-abstractions. The order in which they appear do not influence the translation since we do this for all variables regardless.
\end{proof}

\noindent We also provide the proof for {\bf Lemma \ref{lem:preserve1to1correspondance}}: For a closed $t \in \FALC$, where $t$ has no distributor constructs and only variables are shared, and a closed $N \in \Lambda$. the following
$$\readback{\compile{N}'}{I} = N \hspace{1.5cm} \compile{\readback{t}{I}}' = t \hspace{1.5cm} \exists_{ M \in \Lambda} . t = \compile{M}'$$

\begin{proof}
We prove $\readbackclose{\compile{N}'} = N $ by induction on $N$
\newline
\newline
Base Case: Variable
\newline
$\readbackclose{\compile{x}'} = \readbackclose{x} = x$
\newline
\newline
Inductive Case: Application
\newline
$\readbackclose{\compile{\app{M}{N}}'} = \app{\readbackclose{\compile{M}'}}{\readbackclose{\compile{N}'}} = \app{M}{N}$
\newline
\newline
Inductive Case: Abstraction
\newline
$\readbackclose{\compile{\abs{x}{M}}'} $
\newline
\indent Case: $\size{M}_{x} = 1$
\newline
\indent $= \abs{x}{\readbackclose{\compile{M}'}} = \abs{x}{M}$
\newline
\newline
\indent Case: $\size{M}_{x} = n$
\newline
\indent $= \abs{x}{\readbackclose{ \compile{M \frac{n}{x}}' \share{}{x_{1}, \dots, x_{n}}{x}}} = \abs{x}{\readbackwmap{\compile{M \frac{n}{x}}'}{\sigma}{I}} = \abs{x}{\readbackclose{\compile{M \frac{n}{x}}'}} \sub{}{x}{x_{i}}_{1 \leq i \leq n}$
\newline
\indent $\IH \abs{x}{M \frac{n}{x} \sub{}{x}{x_{i}}_{1 \leq i \leq n}} = \abs{x}{M}$
\newline
\newline
\newline
We prove $ \compile{\readbackclose{t}}' = t$ by induction on $t$
\newline
\newline
Base Case: Variable
\newline
$\compile{\readbackclose{x}}' = \compile{x}' = x$
\newline
\newline
Inductive Case: Application
\newline
$\compile{\readbackclose{\app{s}{t}}}' = \app{\compile{\readbackclose{s}}'}{\compile{\readbackclose{t}}'} \IH \app{s}{t}$
\newline
\newline
Inductive Case: Abstraction
\newline
\indent Case: $\compile{\readbackclose{\fake{x}{x}{t}}}' = \fake{x}{x}{\compile{\readbackclose{t}}'} \IH \fake{x}{x}{t}$
\newline
\newline
\indent Case: $\compile{\readbackclose{\fake{x}{x}{t \share{}{x_{1}, \dots, x_{n}}{x}}}}' = \compile{\abs{x}{\readbackwmap{t}{\sigma}{I}}}'$
\newline
\indent $= \compile{\abs{x}{\readbackclose{t} \sub{}{x}{x_{i}}_{1 \leq i \leq n}}}' = \fake{x}{x}{ \compile{\readbackclose{t}}' \share{}{x_{1}, \dots, x_{n}}{x}}$
\newline
\indent $ \IH \fake{x}{x}{ t \share{}{x_{1}, \dots, x_{n}}{x}} $
\newline
\newline
The proof for $\exists_{ M \in \Lambda} . t = \compile{M}'$ is the same as in \cite{gundersen2013atomic}.
\end{proof}

\subsection{Rewrite Rules}

Here we will give more concrete definitions of substitution, book-keeping and exorcisms respectively. 

\begin{definition}[Substitution] The operation \emph{substitution} is defined as
\label{def:sub}
\begingroup
\allowdisplaybreaks
	\begin{align*}
		\sub{x}{s}{x}	&=	s \\
		\sub{y}{s}{x} 	&= 	y \\
		\sub{(\app{u}{t})}{s}{x} &= \app{(\sub{u}{s}{x})}{\sub{t}{s}{x}} \\
		\sub{(\fake{c}{\vec{y}}{t})}{s}{x} &= \fake{c}{\vec{y}}{\sub{t}{s}{x}} \\
		\sub{(\fake{c}{\vec{y} \cdot x}{t})}{s}{x} &= \fake{c}{\vec{y} \cdot \vec{z}}{\sub{t}{s}{x}} \\
		\sub{\share{u}{\vec{y}}{t}}{s}{x} &= \share{\sub{u}{s}{x}}{\vec{y}}{\sub{t}{s}{x}} \\
		\sub{\dist{u}{\vecdist{e}{\vec{w}}}{\overline{[\Gamma]}}{c}{\vec{y}}}{s}{x} &= \dist{u}{\vecdist{e}{\vec{w}}}{\overline{[\Gamma]} \sub{}{s}{x}}{c}{\vec{y}} \\
		\sub{\dist{u}{\vecdist{e}{\vec{w}}}{\overline{[\Gamma]}}{c}{\vec{y} \cdot x}}{s}{x} &= \dist{u}{\vecdist{e}{\vec{w}}}{\overline{[\Gamma]}\sub{}{s}{x}}{c}{\vec{y} \cdot \vec{z}} \\
		\dist{u}{\vecdist{e}{\vec{w}}}{\sub{}{s}{x}\overline{[\Gamma]}}{c}{\vec{y}} &= \dist{\sub{u}{s}{x}}{\vecdist{e}{\vec{w}}}{\overline{[\Gamma]}}{c}{\vec{y}} \\
		\dist{u}{e \{ \fakedist{e_{i}}{\vec{w} \cdot x }\}}{\sub{}{s}{x} \overline{[\Gamma]}}{c}{\vec{y}} &= \dist{\sub{u}{s}{x}}{e\{ \fakedist{e_{i}}{ \vec{w} \cdot \vec{z}} \}}{\overline{[\Gamma]}}{c}{\vec{y}} \\
	\end{align*}
\vspace{-1cm}
\newline
\noindent Where $\vec{z} = \fv{s}$
\endgroup
\end{definition}

Although substitution performs some book-keeping on phantom-abstractions, we define an explicit notion that updates the variables stored in a free-cover i.e.\ for a term $t$, $\fakedist{e}{\vec{x}} \in \fc{t}$ then $\fakedist{e}{\vec{y}} \in \fc{\psub{t}{\vec{y}}{e}}$.

\begin{definition}[Book-Keeping] The operation \emph{book-keeping} is defined as
\label{def:bk}
\begingroup
\allowdisplaybreaks
	\begin{align*}
		\psub{x}{\vec{w}}{e} &= x \\
		\psub{\app{s}{t}}{\vec{w}}{e} &= \app{(\psub{s}{\vec{w}}{e})}{\psub{t}{\vec{w}}{e}} \\
		\psub{\fake{e}{\vec{z}}{t}}{\vec{w}}{e} &= \fake{e}{\vec{w}}{t} \\
		\psub{(\fake{c}{\vec{z}}{t})}{\vec{w}}{e} &= \fake{c}{\vec{z}}{\psub{t}{\vec{w}}{e}} \\
		\psub{\share{u}{\vec{z}}{t}}{\vec{w}}{e} &= \share{\psub{u}{\vec{w}}{e}}{\vec{z}}{\psub{t}{\vec{w}}{e}} \\
		\psub{\dist{u}{\vecdist{f}{\vec{y}}}{\overline{[\Gamma]}}{e}{\vec{z}}}{\vec{w}}{e} &= \dist{u}{\vecdist{f}{\vec{y}}}{\overline{[\Gamma]}}{e}{\vec{w}} \\
		\psub{\dist{u}{\vecdist{f}{\vec{y}}}{\overline{[\Gamma]}}{c}{\vec{z}}}{\vec{w}}{e} &= \dist{u}{\vecdist{f}{\vec{y}}}{\overline{[\Gamma]} \psub{}{\vec{w}}{e}}{c}{\vec{z}} \\
		\dist{u}{\vecdist{f}{\vec{y}}}{\psub{}{\vec{w}}{e}\overline{[\Gamma]}}{c}{\vec{z}} &= \dist{\psub{u}{\vec{w}}{e}}{\vecdist{f}{\vec{y}}}{\overline{[\Gamma]}}{c}{\vec{z}}
	\end{align*}
\endgroup
\end{definition}

\begin{definition}[Exorcism] The operation \emph{exorcism} is defined as
\label{def:exor}
\begingroup
\allowdisplaybreaks
	\begin{align*}
		\exor{y}{c}{\vec{x}} 	&= y \\
		\exor{\app{s}{t}}{c}{\vec{x}} &= \app{(\exor{s}{c}{\vec{x}})}{\exor{t}{c}{\vec{x}}} \\
		\exor{\fake{c}{\vec{x}}{t}}{c}{\vec{x}} &= \fake{c}{c}{\share{t}{\vec{x}}{c}} \\
		\exor{\fake{d}{\vec{y}}{t}}{c}{\vec{x}} &= \fake{d}{\vec{y}}{\exor{t}{c}{\vec{x}}}\\
		\exor{\share{u}{\vec{y}}{t}}{c}{\vec{x}} &= \share{\exor{u}{c}{\vec{x}}}{\vec{y}}{\exor{t}{c}{\vec{x}}} \\
		\exor{\dist{u}{\vecdist{e}{\vec{w}}}{\overline{[\Gamma]}}{c}{\vec{x}}}{c}{\vec{x}} &= \dist{u}{\vecdist{e}{\vec{w}}}{\overline{[\Gamma]} \share{}{\vec{x}}{c}}{c}{c} \\
		\exor{\dist{u}{\vecdist{e}{\vec{w}}}{\overline{[\Gamma]}}{d}{\vec{y}}}{c}{\vec{x}} &= \dist{u}{\vecdist{e}{\vec{w}}}{\exor{\overline{[\Gamma]}}{c}{\vec{x}}}{d}{\vec{y}} \\
		\dist{u}{\vecdist{e}{\vec{w}}}{ \exor{}{c}{\vec{x}} \overline{[\Gamma]}}{d}{\vec{y}} &= \dist{\exor{u}{c}{\vec{w}}}{\vecdist{e}{\vec{w}}}{\overline{[\Gamma]}}{d}{\vec{y}}
	\end{align*}
\endgroup
\end{definition}

First, observe the following example that demonstrates the rewrite rules. 

\begin{example}
Take the $\lambda$-term $M = \app{(\abs{f}{\abs{x}{\app{f}{(\app{f}{x})}}})}{\abs{g}{\abs{y}{\app{g}{(\app{g}{y})}}}}$. 

Then $\compile{M} = \app{(\fake{f}{f}{\fake{x}{x}{\share{\app{f_{1}}{(\app{f_{2}}{x})}}{f_{1}, f_{2}}{f}}})}{(\fake{g}{g}{\fake{y}{y}{\share{\app{g_{1}}{(\app{g_{2}}{y})}}{g_{1}, g_{2}}{g}}})}$. 

We then may have the following reduction sequence.
\begingroup
\allowdisplaybreaks
\begin{align*}
	 & & & \app{(\fake{f}{f}{\fake{x}{x}{\share{\app{f_{1}}{(\app{f_{2}}{x})}}{f_{1}, f_{2}}{f}}})}{(\fake{g}{g}{\fake{y}{y}{\share{\app{g_{1}}{(\app{g_{2}}{y})}}{g_{1}, g_{2}}{g}}})}&  \\
	  \rightsquigarrow_{\beta} & & & \fake{x}{x}{\share{\app{f_{1}}{(\app{f_{2}}{x})}}{f_{1}, f_{2}}{\fake{g}{g}{\fake{y}{y}{\share{\app{g_{1}}{(\app{g_{2}}{y})}}{g_{1}, g_{2}}{g}}}}} &  \text{(\ref{red:beta})} \displaybreak[0] \\ 
	%%%%%%%%
	\rightsquigarrow_{D}& & & \fake{x}{x}{(\app{\fake{f_{1}}{w_{1}}{w_{1}}}{(\app{(\fake{f_{2}}{w_{2}}{w_{2}})}{x})})} & \\
	& & & \indent \dist{}{\fakedist{f_{1}}{w_{1}}, \fakedist{f_{2}}{w_{2}}}{\share{}{w_{1}, w_{2}}{\fake{y}{y}{\share{\app{g_{1}}{(\app{g_{2}}{y})}}{g_{1}, g_{2}}{g}}}}{g}{g} & \text{(\ref{red:absdup})} \displaybreak[0] \\
	%%%%%%%%
	\rightsquigarrow_{D} & & & \fake{x}{x}{(\app{\fake{f_{1}}{z_{1}}{\fake{y_{1}}{z_{1}}{z_{1}}}}{(\app{(\fake{f_{2}}{z_{2}}{\fake{y_{2}}{z_{2}}{z_{2}}})}{x})})} & \\
	& & & \indent [ \fakedist{f_{1}}{z_{1}}, \fakedist{f_{2}}{z_{2}} \, \vert \, \fakedist{g}{g} [ \fakedist{y_{1}}{z_{1}}, \fakedist{y_{2}}{z_{2}} \, \vert \, \fakedist{y}{y} & \\
	& & & \indent \indent \share{}{z_{1}, z_{2}}{\share{\app{g_{1}}{(\app{g_{2}}{y})}}{g_{1}, g_{2}}{g}} ] ]   &  \text{(\ref{red:absdup})} \displaybreak[0] \\
	%%%%%%%%
	\rightsquigarrow_{L} & & & \fake{x}{x}{(\app{\fake{f_{1}}{z_{1}}{\fake{y_{1}}{z_{1}}{z_{1}}}}{(\app{(\fake{f_{2}}{z_{2}}{\fake{y_{2}}{z_{2}}{z_{2}}})}{x})})} & \\
	& & & \indent [ \fakedist{f_{1}}{z_{1}}, \fakedist{f_{2}}{z_{2}} \, \vert \, \fakedist{g}{g} [ \fakedist{y_{1}}{z_{1}}, \fakedist{y_{2}}{z_{2}} \, \vert \, \fakedist{y}{y} & \\
	& & & \indent \indent \share{}{z_{1}, z_{2}}{\app{g_{1}}{(\app{g_{2}}{y})}} \share{}{g_{1}, g_{2}}{g} ] ]   &  \text{(\ref{red:liftshare})} \displaybreak[0] \\
	%%%%%%%%
	\rightsquigarrow_{D} & & &  \fake{x}{x}{(\app{(\fake{f_{1}}{a_{1}, b_{1}}{\fake{y_{1}}{a_{1}, b_{1}}{\app{a_{1}}{b_{1}}}})}{(\app{(\fake{f_{2}}{a_{2}, b_{2}}{\fake{y_{2}}{a_{2}, b_{2}}{\app{a_{2}}{b_{2}}}})}{x})})} & \\
	& & & \indent [ \fakedist{f_{1}}{a_{1}, b_{1}}, \fakedist{f_{2}}{a_{2}, b_{2}} \, \vert \, \fakedist{g}{g} [ \fakedist{y_{1}}{a_{1}, b_{1}}, \fakedist{y_{2}}{a_{2}, b_{2}} \, \vert \, \fakedist{y}{y} & \\
	& & & \indent \indent \share{}{a_{1}, a_{2}}{g_{1}} \share{}{b_{1}, b_{2}}{\app{g_{2}}{y}} \share{}{g_{1}, g_{2}}{g} ] ]   &  \text{(\ref{red:appdup})} \displaybreak[0] \\
	%%%%%%%%
	\rightsquigarrow_{C} & & &  \fake{x}{x}{(\app{(\fake{f_{1}}{a_{1}, b_{1}}{\fake{y_{1}}{a_{1}, b_{1}}{\app{a_{1}}{b_{1}}}})}{(\app{(\fake{f_{2}}{a_{2}, b_{2}}{\fake{y_{2}}{a_{2}, b_{2}}{\app{a_{2}}{b_{2}}}})}{x})})} & \\
	& & & \indent [ \fakedist{f_{1}}{a_{1}, b_{1}}, \fakedist{f_{2}}{a_{2}, b_{2}} \, \vert \, \fakedist{g}{g} [ \fakedist{y_{1}}{a_{1}, b_{1}}, \fakedist{y_{2}}{a_{2}, b_{2}} \, \vert \, \fakedist{y}{y} & \\
	& & & \indent \indent \share{}{b_{1}, b_{2}}{\app{g_{2}}{y}} \share{}{a_{1}, a_{2}, g_{2}}{g} ] ]   &  \text{(\ref{red:mergeshare})} \displaybreak[0] \\
	%%%%%%%%%
	\rightsquigarrow_{D} & & &  \fake{x}{x}{}((\fake{f_{1}}{a_{1}, b_{1}, c_{1}}{\fake{y_{1}}{a_{1}, b_{1}, c_{1}}{\app{a_{1}}{(\app{b_{1}}{c_{1}})}}}) & \\
	& & & \indent (\app{(\fake{f_{2}}{a_{2}, b_{2}, c_{2}}{\fake{y_{2}}{a_{2}, b_{2}, c_{2}}{\app{a_{2}}{(\app{b_{2}}{c_{2}})}}})}{x}) & \\
	& & & \indent \indent [ \fakedist{f_{1}}{a_{1}, b_{1}, c_{1}}, \fakedist{f_{2}}{a_{2}, b_{2}, c_{2}} \, \vert \, \fakedist{g}{g} [ \fakedist{y_{1}}{a_{1}, b_{1}, c_{1}}, \fakedist{y_{2}}{a_{2}, b_{2}, c_{2}} \, \vert \, \fakedist{y}{y} & \\
	& & & \indent \indent \indent \share{}{b_{1}, b_{2}}{g_{2}} \share{}{c_{1}, c_{2}}{y} \share{}{a_{1}, a_{2}, g_{2}}{g} ] ]   &  \text{(\ref{red:appdup})} \displaybreak[0]  \\
	%%%%%%%%
	\rightsquigarrow_{C} & & &  \fake{x}{x}{}((\fake{f_{1}}{a_{1}, b_{1}, c_{1}}{\fake{y_{1}}{a_{1}, b_{1}, c_{1}}{\app{a_{1}}{(\app{b_{1}}{c_{1}})}}}) & \\
	& & & \indent (\app{(\fake{f_{2}}{a_{2}, b_{2}, c_{2}}{\fake{y_{2}}{a_{2}, b_{2}, c_{2}}{\app{a_{2}}{(\app{b_{2}}{c_{2}})}}})}{x}) & \\
	& & & \indent \indent [ \fakedist{f_{1}}{a_{1}, b_{1}, c_{1}}, \fakedist{f_{2}}{a_{2}, b_{2}, c_{2}} \, \vert \, \fakedist{g}{g} [ \fakedist{y_{1}}{a_{1}, b_{1}, c_{1}}, \fakedist{y_{2}}{a_{2}, b_{2}, c_{2}} \, \vert \, \fakedist{y}{y} & \\
	& & & \indent \indent \indent \share{}{c_{1}, c_{2}}{y} \share{}{a_{1}, b_{1},  a_{2}, b_{2}}{g} ] ]   &  \text{(\ref{red:mergeshare})} \displaybreak[0]  \\
	%%%%%%%%
	\rightsquigarrow_{L} & & &  \fake{x}{x}{}((\fake{f_{1}}{a_{1}, b_{1}, c_{1}}{\fake{y_{1}}{c_{1}}{\app{a_{1}}{(\app{b_{1}}{c_{1}})}}}) & \\
	& & & \indent (\app{(\fake{f_{2}}{a_{2}, b_{2}, c_{2}}{\fake{y_{2}}{c_{2}}{\app{a_{2}}{(\app{b_{2}}{c_{2}})}}})}{x}) & \\
	& & & \indent \indent [ \fakedist{f_{1}}{a_{1}, b_{1}, c_{1}}, \fakedist{f_{2}}{a_{2}, b_{2}, c_{2}} \, \vert \, \fakedist{g}{g} [ \fakedist{y_{1}}{c_{1}}, \fakedist{y_{2}}{c_{2}} \, \vert \, \fakedist{y}{y} & \\
	& & & \indent \indent \indent \share{}{c_{1}, c_{2}}{y} ] \share{}{a_{1}, b_{1},  a_{2}, b_{2}}{g} ]   &  \text{(\ref{red:distshare})} \displaybreak[0]  \\
	%%%%%%%
	\rightsquigarrow_{L} & & & \fake{x}{x}{(\app{(\fake{f_{1}}{a_{1}, b_{1}}{\fake{y_{1}}{c_{1}}{\app{a_{1}}{(\app{b_{1}}{c_{1}})}}})}{(\app{(\fake{f_{2}}{a_{2}, b_{2}}{\fake{y_{2}}{c_{2}}{\app{a_{2}}{(\app{b_{2}}{c_{2}})}}})}{x})})} & \\   		
	& & & \indent \dist{}{\fakedist{f_{1}}{a_{1}, b_{1}}, \fakedist{f_{2}}{a_{2}, b_{2}}}{\share{}{a_{1}, b_{1}, a_{2}, b_{2}}{g}}{g}{g} & \\
	& & & \indent \indent \dist{}{\fakedist{y_{1}}{c_{1}}, \fakedist{y_{2}}{c_{2}}}{\share{}{c_{1}, c_{2}}{y}}{y}{y} & \text{(\ref{red:distshare})} \displaybreak[0]  \\
	%%%%%%%
	\rightsquigarrow_{D} & & & \fake{x}{x}{}((\fake{f_{1}}{f_{1}}{\share{\fake{y_{1}}{c_{1}}{\app{a_{1}}{(\app{b_{1}}{c_{1}})}}}{a_{1}, b_{1}}{f_{1}}}) & \\
	& & & \indent (\app{(\fake{f_{2}}{f_{2}}{\share{\fake{y_{2}}{c_{2}}{\app{a_{2}}{(\app{b_{2}}{c_{2}})}}}{a_{2}, b_{2}}{f_{2}}})}{x}) & \\  	
	& & & \indent \indent \dist{}{\fakedist{y_{1}}{c_{1}}, \fakedist{y_{2}}{c_{2}}}{\share{}{c_{1}, c_{2}}{y}}{y}{y} & \text{(\ref{red:distelim})} \displaybreak[0]  \\
	%%%%%%%
	\rightsquigarrow_{D} & & & \fake{x}{x}{}((\fake{f_{1}}{f_{1}}{\share{\fake{y_{1}}{y_{1}}{\app{a_{1}}{(\app{b_{1}}{y_{1}})}}}{a_{1}, b_{1}}{f_{1}}}) & \\
	& & & \indent (\app{(\fake{f_{2}}{f_{2}}{\share{\fake{y_{2}}{y_{2}}{\app{a_{2}}{(\app{b_{2}}{y_{2}})}}}{a_{2}, b_{2}}{f_{2}}})}{x}) & \text{(\ref{red:distelim})} \displaybreak[0]  \\
\end{align*}
\endgroup

\end{example}

\noindent We provide the proof for {\bf Proposition \ref{prop:bkcomm}}: Given $M \in \Lambda$ such that for all $v \in V$, $\gamma(v) \not\in \fv{M}$  and $\sigma(x) = x$, the translation $\readbackwmap{u}{\sigma}{\gamma}$ commutes with substitution $\sub{}{M}{x}$ in the following way

$$\readbackwmap{u \sub{}{t}{x}}{\sigma}{\gamma} = \readbackwmap{u}{\sigma[x \mapsto \readbackwmap{t}{\sigma}{\gamma}]}{\gamma}$$

%$$\readbackwmap{u}{\sigma'}{\gamma} = \readbackwmap{u}{\sigma}{\gamma} \sub{}{M}{x}$$
%
%where $\sigma'(z) = \begin{cases} \sigma(z) \sub{}{M}{x} & z \neq x \\ M & \text{otherwise} \end{cases}$

\begin{proof}
We prove this by induction on $u$
\newline
\newline
Base Case: Variable
\newline
$\readbackwmap{x \sub{}{t}{x}}{\sigma}{\gamma} = \readbackwmap{t}{\sigma}{\gamma} = \readbackwmap{x}{\sigma'}{\gamma}$
\newline
\newline
$\readbackwmap{y}{\sigma}{\gamma} = \sigma(y) = \sigma'(y) = \readbackwmap{y}{\sigma'}{\gamma}$
\newline
\newline
Inductive Case: Application
\newline
$\readbackwmap{\app{u}{s} \sub{}{t}{x}}{\sigma}{\gamma} = \app{\readbackwmap{u \sub{}{t}{x}}{\sigma}{\gamma}}{\readbackwmap{s \sub{}{t}{x}}{\sigma}{\gamma}} \IH \app{\readbackwmap{u}{\sigma'}{\gamma}}{\readbackwmap{s}{\sigma'}{\gamma}} = \readbackwmap{\app{u}{s}}{\sigma'}{\gamma}$
\newline
\newline
Inductive Case: Abstraction
\newline
$\readbackwmap{(\fake{c}{c}{s}) \sub{}{t}{x}}{\sigma}{\gamma} = \abs{c}{\readbackwmap{s \sub{}{t}{x}}{\sigma}{\gamma}} \IH \abs{c}{\readbackwmap{s}{\sigma'}{\gamma}} = \readbackwmap{\fake{c}{c}{s}}{\sigma'}{\gamma}$
\newline
\newline
Inductive Case: Phantom-Abstraction
\newline
$\readbackwmap{(\fake{c}{x_{1}, \dots, x_{n}}{s}) \sub{}{t}{x}}{\sigma}{\gamma}$
\newline
\indent Case: $x \in \set{x_{1}, \dots, x_{n}}$
\newline
\indent $= \readbackwmap{(\fake{c}{x_{1}, \dots, x_{n}, x}{s}) \sub{}{t}{x}}{\sigma}{\gamma} = \readbackwmap{\fake{c}{x_{1}, \dots, x_{n}, y_{1}, \dots, y_{m}}{s} \sub{}{t}{x}}{\sigma}{\gamma}$
\newline
\indent where $\set{y_{1}, \dots, y_{m}} = \fv{t}$
\newline
\indent $= \abs{c}{\readbackwmap{s \sub{}{t}{x}}{\sigma''}{\gamma}} \IH \abs{c}{\readbackwmap{s}{\sigma'''_{1}}{\gamma}} = \abs{c}{\readbackwmap{s}{\sigma'''_{2}}{\gamma}} = \readbackwmap{\fake{c}{x_{1}, \dots, x_{n}, x}{s}}{\sigma'}{\gamma}$
\newline
\indent where $\sigma''(z) = \begin{cases} \sigma(z) \sub{}{c}{\gamma(c)} & \text{if } z \in \set{x_{1}, \dots, x_{n}, y_{1}, \dots, y_{m}} \\ \sigma(z) & \text{otherwise} \end{cases}$
\newline
\indent $\sigma'''_{1} = \sigma''[x \mapsto \readbackwmap{t}{\sigma''}{\gamma}]$
\newline
\indent $\sigma'''_{2}(z) = \begin{cases} \readbackwmap{t}{\sigma''}{\gamma} \sub{}{c}{\gamma(c)} & z = x \\ \sigma(z) \sub{}{c}{\gamma(c)} & z \in \set{x_{1}, \dots, x_{n}} \\ \sigma(z) & \text{otherwise} \end{cases}$
\newline
\newline
\indent Case: $x \not\in \set{x_{1}, \dots, x_{n}}$
\newline
\indent $= \readbackwmap{\fake{c}{x_{1}, \dots, x_{n}}{s \sub{}{t}{x}}}{\sigma}{\gamma} = \abs{c}{\readbackwmap{s \sub{}{t}{x}}{\sigma''}{\gamma}} \IH \abs{c}{\readbackwmap{t}{\sigma''[x \mapsto \readbackwmap{t}{\sigma''}{\gamma}]}{\gamma}} = \abs{c}{\readbackwmap{t}{\sigma''[x \mapsto \readbackwmap{t}{\sigma}{\gamma}]}{\gamma}} = \readbackwmap{\fake{c}{x_{1}, \dots, x_{n}}{s}}{\sigma[x \mapsto \readbackwmap{t}{\sigma}{\gamma}]}{\gamma}$
\newline
\indent where
\newline
\indent $\sigma'' = \sigma[x_{i} \mapsto \sigma(x_{i}) \sub{}{c}{\gamma(c)}]_{i \in [n]}$
\newline
\newline
Inductive Case: Sharing
\newline
$\readbackwmap{\share{u}{z_{1}, \dots, z_{n}}{s} \sub{}{t}{x}}{\sigma}{\gamma} = \readbackwmap{\share{u \sub{}{t}{x}}{z_{1}, \dots, z_{n}}{s \sub{}{t}{x}} }{\sigma}{\gamma} = \readbackwmap{u \sub{}{t}{x}}{\sigma''}{\gamma}$
\newline
$\IH \readbackwmap{u}{\sigma'''}{\gamma} = \readbackwmap{\share{u}{z_{1}, \dots, z_{n}}{s}}{\sigma'}{\gamma}$
\newline
where
\newline
$\sigma'' = \sigma [z_{1} \mapsto \readbackwmap{s \sub{}{t}{x}}{\sigma}{\gamma} , \dots , z_{n} \mapsto \readbackwmap{s \sub{}{t}{x}}{\sigma}{\gamma} ]$
\newline
$\sigma''' = \sigma' [z_{1} \mapsto \readbackwmap{s}{\sigma'}{\gamma} , \dots , z_{n} \mapsto \readbackwmap{s }{\sigma'}{\gamma} ]$
\newline
\newline
Inductive Case: Distributor 1
\newline
$\readbackwmap{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}}, \dots, \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]}}{c}{c} \sub{}{t}{x}}{\sigma}{\gamma}$
\newline
$= \readbackwmap{u \overline{[\Gamma]} \sub{}{t}{x}}{\sigma}{\gamma'} \IH \readbackwmap{u \overline{[\Gamma]}}{\sigma'}{\gamma'}$
\newline
$= \readbackwmap{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}}, \dots, \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]}}{c}{\vec{x}} }{\sigma'}{\gamma}$
\newline
where
\newline
$\gamma' = \gamma [e_{1} \mapsto c, \dots, e_{n} \mapsto c]$
\newline
\newline
Inductive Case: Distributor 2
\newline
$\readbackwmap{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}}, \dots, \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]}}{c}{\vec{x}} \sub{}{t}{x}}{\sigma}{\gamma}$
\newline
$= \readbackwmap{u \overline{[\Gamma]} \sub{}{t}{x}}{\sigma''}{\gamma'} \IH \readbackwmap{u \overline{[\Gamma]}}{\sigma'''}{\gamma'}$
\newline
$= \readbackwmap{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}}, \dots, \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]}}{c}{\vec{x}} }{\sigma'}{\gamma}$
\newline
where
\newline
$\gamma' = \gamma [e_{1} \mapsto c, \dots, e_{n} \mapsto c]$
\end{proof}

Book-keeping commutes with the translation in the following way

if $\fake{c}{y_{1}, \dots, y_{m}} \in \fc{u}$ such that $\set{x_{1}, \dots, x_{n}} \subset \set{y_{1}, \dots, y_{m}}$

and for those $z \in \set{y_{1}, \dots, y_{m}} / \set{x_{1}, \dots, x_{n}}$, $\gamma(c) \not\in \fv{\sigma(z)}$

or if simply $\set{x_{1}, \dots, x_{n}} \cap \fv{u} = \set{}$

$$\readbackwmap{u \psub{}{x_{1}, \dots, x_{n}}{c}}{\sigma}{\gamma} = \readbackwmap{u}{\sigma}{\gamma}$$

\begin{proof}
We prove this by induction on $u$
\newline
\newline
Base Case: Variable
\newline
$\readbackwmap{x \psub{}{x_{1}, \dots, x_{n}}{c}}{\sigma}{\gamma} = \readbackwmap{x}{\sigma}{\gamma} = \sigma(x) = \sigma'(x) = \readbackwmap{x}{\sigma'}{\gamma'}$
\newline
Since is cannot be that $x \in \set{x_{1}, \dots, x_{n}}$
\newline
\newline
Base Case: Phantom-Abstraction
\newline
$\readbackwmap{(\fake{c}{y_{1}, \dots, y_{m}}{t}) \psub{}{x_{1}, \dots, x_{n}}{c}}{\sigma}{\gamma} = \readbackwmap{\fake{c}{x_{1}, \dots, x_{n}}{t}}{\sigma}{\gamma}$
\newline
$= \abs{c}{\readbackwmap{t}{\sigma''}{\gamma}} = \abs{c}{\readbackwmap{t}{\sigma''}{\gamma'}}  = \readbackwmap{\fake{c}{y_{1}, \dots, y_{m}}{t}}{\sigma'}{\gamma'}$
\newline
where
\newline
$\sigma = \sigma_{1} [x_{1} \mapsto M_{1} , \dots ,  x_{n} \mapsto M_{n} ]$
\newline
$\sigma'' = \sigma_{1} [x_{1} \mapsto M_{1} \sub{}{c}{d} , \dots ,  x_{n} \mapsto M_{n} \sub{}{c}{d} ]$
\newline
$\gamma(c) = d$
\newline
Note: due to condition of Proposition any $\set{y_{i} \mapsto M_{i} \sub{}{c}{d}} = \set{ y_{i} \mapsto M_{i} }$
\newline
\newline
Base Case: Distributor
\newline
$\readbackwmap{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}}, \dots, \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]}}{c}{y_{1}, \dots, y_{m}}  \psub{}{x_{1}, \dots, x_{n}}{c}}{\sigma}{\gamma}$
\newline
$= \readbackwmap{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}}, \dots, \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]}}{c}{x_{1}, \dots, x_{n}} }{\sigma}{\gamma} = \readbackwmap{u \overline{[\Gamma]}}{\sigma'}{\gamma'}$
\newline
$= \readbackwmap{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}}, \dots, \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]}}{c}{y_{1}, \dots, y_{m}} }{\sigma}{\gamma}$
\newline
where
$\gamma' = \gamma [e_{1} \mapsto c, \dots, e_{n} \mapsto c]$
\newline
$\sigma = \sigma_{1} [x_{1} \mapsto M_{1} , \dots , x_{n} \mapsto M_{n} ]$
\newline
$\sigma' = \sigma_{1} [ x_{1} \mapsto M_{1} \sub{}{c}{\gamma(c)} , \dots , x_{n} \mapsto M_{n} \sub{}{c}{\gamma(c)} ]$
\newline
\newline
Inductive Case: Application
\newline
$\readbackwmap{(\app{s}{t})  \psub{}{x_{1}, \dots, x_{n}}{c}}{\sigma}{\gamma} = \app{\readbackwmap{s\psub{}{x_{1}, \dots, x_{n}}{c}}{\sigma}{\gamma}}{\readbackwmap{t\psub{}{x_{1}, \dots, x_{n}}{c}}{\sigma}{\gamma}}$
\newline
$\IH  \app{\readbackwmap{s}{\sigma}{\gamma}}{\readbackwmap{t}{\sigma}{\gamma}} = \readbackwmap{\app{s}{t}}{\sigma}{\gamma}$
\newline
\newline
Inductive Case: Abstraction
\newline
$\readbackwmap{(\fake{z}{z}{t})  \psub{}{x_{1}, \dots, x_{n}}{c}}{\sigma}{\gamma} = \abs{z}{\readbackwmap{t \psub{}{x_{1}, \dots, x_{n}}{c}}{\sigma}{\gamma}} \IH \abs{z}{\readbackwmap{t}{\sigma}{\gamma}} = \readbackwmap{\fake{z}{z}{t}}{\sigma}{\gamma}$
\newline
\newline
Inductive Case: Phantom-Abstraction
\newline
$\readbackwmap{(\fake{d}{z_{1}, \dots, z_{m}}{t}) \psub{}{x_{1}, \dots, x_{n}}{c}}{\sigma}{\gamma} = \abs{d}{\readbackwmap{t  \psub{}{x_{1}, \dots, x_{n}}{c}}{\sigma'}{\gamma}}$
\newline
$\IH \abs{d}{\readbackwmap{t}{\sigma'}{\gamma}} = \readbackwmap{\fake{d}{z_{1}, \dots, z_{m}}{t}}{\sigma}{\gamma}$
\newline
\newline
Inductive Case: Sharing
\newline
$\readbackwmap{\share{u}{z_{1}, \dots, z_{m}}{t} \psub{}{x_{1}, \dots, x_{n}}{c}}{\sigma}{\gamma}$
\newline
$ = \readbackwmap{\share{u \psub{}{x_{1}, \dots, x_{n}}{c}}{z_{1}, \dots, z_{m}}{t \psub{}{x_{1}, \dots, x_{n}}{c}} }{\sigma}{\gamma} $
\newline
$= \readbackwmap{u \psub{}{x_{1}, \dots, x_{n}}{c}}{\sigma'}{\gamma} \IH \readbackwmap{u}{\sigma''}{\gamma} = \readbackwmap{\share{u}{z_{1}, \dots, z_{m}}{t}}{\sigma}{\gamma}$
\newline
\newline
Inductive Case: Distributor
\newline
$\readbackwmap{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}}, \dots, \fakedist{e_{m}}{\vec{w_{m}}}}{\overline{[\Gamma]}}{d}{d}  \psub{}{x_{1}, \dots, x_{n}}{c}}{\sigma}{\gamma}$
\newline
$= \readbackwmap{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}}, \dots, \fakedist{e_{m}}{\vec{w_{m}}}}{\overline{[\Gamma]} \psub{}{x_{1}, \dots, x_{n}}{c}}{d}{d} }{\sigma}{\gamma}$
\newline
$= \readbackwmap{u \overline{[\Gamma]}\psub{}{x_{1}, \dots, x_{n}}{c}}{\sigma}{\gamma'} \IH \readbackwmap{u \overline{[\Gamma]}}{\sigma}{\gamma'}$
\newline
$= \readbackwmap{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}}, \dots, \fakedist{e_{m}}{\vec{w_{m}}}}{\overline{[\Gamma]}}{d}{d}}{\sigma}{\gamma}$
\end{proof}

Exorcisms commute with the translation in the following way

if $\fake{c}{x_{1}, \dots, x_{n}} \in \fc{u}$ or $\set{x_{1}, \dots, x_{n}} \cap \fv{u} = \set{}$

$$\readbackwmap{u \exor{}{c}{x_{1}, \dots, x_{n}}}{\sigma}{\gamma} = \readbackwmap{u}{\sigma[x_{i} \mapsto c]_{i \in [n]}}{\gamma}$$

\begin{proof}
We prove this by induction on $u$
\newline
\newline
Base Case: Variable
\newline
$\readbackwmap{z \exor{}{c}{x_{1}, \dots, x_{n}}}{\sigma}{\gamma} = \readbackwmap{z}{\sigma}{\gamma} = \sigma(z) = \sigma'(z) = \readbackwmap{z}{\sigma'}{\gamma}$
\newline
\newline
Base Case: Phantom-Abstraction
\newline
$\readbackwmap{(\fake{c}{x_{1}, \dots, x_{n}}{t})  \exor{}{c}{x_{1}, \dots, x_{n}} }{\sigma}{\gamma} = \readbackwmap{\fake{c}{c}{t \share{}{x_{1}, \dots, x_{n}}{c}}}{\sigma}{\gamma}$
\newline
$= \abs{c}{\readbackwmap{t \share{}{x_{1}, \dots, x_{n}}{c}}{\sigma}{\gamma}} = \abs{c}{\readbackwmap{t}{\sigma'}{\gamma}} = \readbackwmap{\fake{c}{x_{1}, \dots, x_{n}}{t}}{\sigma'}{\gamma}$
\newline
\newline
Base Case: Distributor
\newline
$\readbackwmap{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}}, \dots, \fakedist{e_{m}}{\vec{w_{m}}}}{\overline{[\Gamma]}}{c}{x_{1}, \dots, x_{n}} \exor{}{c}{x_{1}, \dots, x_{n}} }{\sigma}{\gamma}$
\newline
$= \readbackwmap{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}}, \dots, \fakedist{e_{m}}{\vec{w_{m}}}}{\overline{[\Gamma]} \share{}{x_{1}, \dots, x_{n}}{c}}{c}{c} }{\sigma}{\gamma}$
\newline
$= \readbackwmap{u \overline{[\Gamma]} \share{}{x_{1}, \dots, x_{n}}{c} }{\sigma}{\gamma'} = \readbackwmap{u \overline{[\Gamma]}}{\sigma'}{\gamma'}$
\newline
$= \readbackwmap{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}}, \dots, \fakedist{e_{m}}{\vec{w_{m}}}}{\overline{[\Gamma]}}{c}{x_{1}, \dots, x_{n}}}{\sigma'}{\gamma}$
\newline
\newline
Inductive Case: Application
\newline
$\readbackwmap{(\app{s}{t}) \exor{}{c}{x_{1}, \dots, x_{n}} }{\sigma}{\gamma} = \app{\readbackwmap{s \exor{}{c}{x_{1}, \dots, x_{n}}}{\sigma}{\gamma}}{\readbackwmap{t \exor{}{c}{x_{1}, \dots, x_{n}}}{\sigma}{\gamma}}$
\newline
$\IH \app{\readbackwmap{s}{\sigma'}{\gamma}}{\readbackwmap{t}{\sigma'}{\gamma}} = \readbackwmap{\app{s}{t}}{\sigma'}{\gamma}$
\newline
\newline
Inductive Case: Abstraction
\newline
$\readbackwmap{(\fake{z}{z}{t}) \exor{}{c}{x_{1}, \dots, x_{n}} }{\sigma}{\gamma} = \abs{z}{\readbackwmap{t  \exor{}{c}{x_{1}, \dots, x_{n}}}{\sigma}{\gamma}}$
\newline
$\IH \abs{z}{\readbackwmap{t}{\sigma'}{\gamma}} = \readbackwmap{\fake{z}{z}{t}}{\sigma'}{\gamma}$
\newline
\newline
Inductive Case: Phantom-Abstraction
\newline
$\readbackwmap{(\fake{d}{z_{1}, \dots, z_{m}}{t}) \exor{}{c}{x_{1}, \dots, x_{n}} }{\sigma}{\gamma} = \abs{d}{\readbackwmap{t  \exor{}{c}{x_{1}, \dots, x_{n}}}{\sigma''}{\gamma}}$
\newline
$\IH \abs{d}{\readbackwmap{t}{\sigma'''}{\gamma}} = \readbackwmap{\fake{d}{z_{1}, \dots, z_{m}}{t}}{\sigma'}{\gamma}$
\newline
\newline
Inductive Case: Sharing
\newline
$\readbackwmap{\share{u}{z_{1}, \dots, z_{m}}{t} \exor{}{c}{x_{1}, \dots, x_{n}} }{\sigma}{\gamma}$
\newline
$= \readbackwmap{\share{u \exor{}{c}{x_{1}, \dots, x_{n}}}{z_{1}, \dots, z_{m}}{t \exor{}{c}{x_{1}, \dots, x_{n}}}}{\sigma}{\gamma}$
\newline
$= \readbackwmap{u \exor{}{c}{x_{1}, \dots, x_{n}} }{\sigma''}{\gamma} \IH \readbackwmap{u}{\sigma'''}{\gamma} = \readbackwmap{\share{u}{z_{1}, \dots, z_{m}}{t}}{\sigma'}{\gamma}$
\newline
\newline
Inductive Case: Distributor
\newline
$\readbackwmap{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}}, \dots, \fakedist{e_{m}}{\vec{w_{m}}}}{\overline{[\Gamma]}}{d}{d} \exor{}{c}{x_{1}, \dots, x_{n}} }{\sigma}{\gamma}$
\newline
$= \readbackwmap{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}}, \dots, \fakedist{e_{m}}{\vec{w_{m}}}}{\overline{[\Gamma]} \exor{}{c}{x_{1}, \dots, x_{n}}}{d}{d}  }{\sigma}{\gamma}$
\newline
$= \readbackwmap{u \overline{[\Gamma]} \exor{}{c}{x_{1}, \dots, x_{n}}}{\sigma}{\gamma'} \IH \readbackwmap{u \overline{[\Gamma]}}{\sigma'}{\gamma'}$
\newline
$= \readbackwmap{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}}, \dots, \fakedist{e_{m}}{\vec{w_{m}}}}{\overline{[\Gamma]}}{d}{d} }{\sigma}{\gamma'}$
\end{proof}

\noindent We prove {\bf Lemma \ref{lem:preservesdenotation}}: If $s \rightsquigarrow_{L, D, C} t$ then $\readbackwmap{s}{\sigma}{\gamma} = \readbackwmap{t}{\sigma}{\gamma}$

\begin{proof}
We prove this by induction. First we to a case-by-case basis for the base case.
\newline
\newline
Case: (\ref{red:mergeshare})
$$\share{\share{u}{\vec{w}}{y}}{\vec{x} \cdot y}{t} \rightsquigarrow_{C} \share{u}{\vec{x} \cdot \vec{w}}{t} $$
$\readbackwmap{\share{\share{u}{\vec{w}}{y}}{\vec{x} \cdot y}{t}}{\sigma}{\gamma} = \readbackwmap{\share{u}{\vec{w}}{y}}{\sigma'}{\gamma} = \readbackwmap{u}{\sigma''}{\gamma} = \readbackwmap{\share{u}{\vec{x} \cdot \vec{w}}{t}}{\sigma}{\gamma}$
\newline
where
\newline
$\sigma' = \sigma [x \mapsto \readbackwmap{t}{\sigma}{\gamma}]_{\forall x \in \vec{x}} [y \mapsto \readbackwmap{t}{\sigma}{\gamma}]$
\newline
$\sigma'' = \sigma' [w \mapsto \readbackwmap{t}{\sigma}{\gamma}]_{\forall w \in \vec{w}}$
\newline
\newline
\newline
Case: (\ref{red:compshare})
$$\share{u}{x}{t} \rightsquigarrow_{C} \sub{u}{t}{x}$$
$\readbackwmap{\share{u}{x}{t}}{\sigma}{\gamma} = \readbackwmap{u}{\sigma[x \mapsto \readbackwmap{t}{\sigma}{\gamma}]}{\gamma} = \readbackwmap{\sub{u}{t}{x}}{\sigma}{\gamma} $\
\newline
\newline
Case: (\ref{red:appdup})
$$\share{u}{x_{1} \dots x_{n}}{\app{s}{t}} \rightsquigarrow_{D} \share{\share{\sub{\sub{u}{\app{z_{1}}{y_{1}}}{x_{1}}\dots}{\app{z_{n}}{y_{n}}}{x_{n}}}{z_{1} \dots z_{n}}{s}}{y_{1} \dots y_{n}}{t}$$
$\readbackwmap{\share{u}{x_{1} \dots x_{n}}{\app{s}{t}}}{\sigma}{\gamma} = \readbackwmap{u}{\sigma'}{\gamma}$
\newline
where
\newline
$\sigma' = \sigma [ x_{i} \mapsto \readbackwmap{\app{s}{t}}{\sigma}{\gamma}]_{1 \leq i \leq n} = \sigma [x_{i} \mapsto \app{\readbackwmap{s}{\sigma}{\gamma}}{\readbackwmap{t}{\sigma}{\gamma}}]_{1 \leq i \leq n}$
\newline
\newline
$\readbackwmap{ \share{\share{\sub{\sub{u}{\app{z_{1}}{y_{1}}}{x_{1}}\dots}{\app{z_{n}}{y_{n}}}{x_{n}}}{z_{1} \dots z_{n}}{s}}{y_{1} \dots y_{n}}{t}}{\sigma}{\gamma}$
\newline
$=\readbackwmap{\sub{\sub{u}{\app{z_{1}}{y_{1}}}{x_{1}}\dots}{\app{z_{n}}{y_{n}}}{x_{n}} }{\sigma''}{\gamma} $
\newline
where
\newline
$\sigma'' = \sigma [z_{i} \mapsto \readbackwmap{s}{\sigma}{\gamma}]_{1 \leq i \leq n} [y_{i} \mapsto \readbackwmap{t}{\sigma}{\gamma}]_{1 \leq i \leq n}$ since $y_{i} \not\in \fv{s}$
\newline
$= \readbackwmap{u}{\sigma'''}{\gamma}$
\newline
where
\newline
$\sigma''' = \sigma'' [x_{i} \mapsto \readbackwmap{\app{z_{i}}{y_{i}}}{\sigma''}{\gamma}]_{1 \leq i \leq n} = \sigma [x_{i} \mapsto \app{\readbackwmap{s}{\sigma}{\gamma}}{\readbackwmap{t}{\sigma}{\gamma}}]_{1 \leq i \leq n}$
\newline
since $z_{i}$ and $y_{i} \not\in \fv{u}$
\newline
\newline
Case: (\ref{red:absdup})
$$\share{u}{x_{1}, \dots, x_{n}}{\fake{c}{\vec{y}}{t}} \rightsquigarrow_{D}$$
$$\sub{u}{\fake{e_{i}}{w^{i}_{1}}{w^{i}_{1}}}{x_{i}}_{1 \leq i \leq n} \dist{}{\fakedist{e_{1}}{w^{1}_{1}} \dots \fakedist{e_{n}}{w^{n}_{1}}}{\share{}{w^{1}_{1}, \dots, w^{n}_{1}}{t}}{c}{\vec{y}}$$
\newline
SubCase: $\vec{y} = c$
\newline
$\readbackwmap{\share{u}{x_{1}, \dots, x_{n}}{\fake{c}{c}{t}}}{\sigma}{\gamma} = \readbackwmap{u}{\sigma'}{\gamma}$
\newline
where $\sigma' = \sigma [x_{i} \mapsto \readbackwmap{\fake{c}{c}{t}}{\sigma}{\gamma}]_{1 \leq i \leq n} = \sigma [x_{i} \mapsto \abs{c}{\readbackwmap{t}{\sigma}{\gamma}}]_{1 \leq i \leq n}$
\newline
\newline
$\readbackwmap{\sub{u}{\fake{e_{i}}{w^{i}_{1}}{w^{i}_{1}}}{x_{i}}_{1 \leq i \leq n} \dist{}{\fakedist{e_{1}}{w^{1}_{1}} \dots \fakedist{e_{n}}{w^{n}_{1}}}{\share{}{w^{1}_{1}, \dots, w^{n}_{1}}{t}}{c}{c}}{\sigma}{\gamma}$
\newline
$\readbackwmap{\sub{u}{\fake{e_{i}}{w^{i}_{1}}{w^{i}_{1}}}{x_{i}}_{1 \leq i \leq n} \share{}{w^{1}_{1}, \dots, w^{n}_{1}}{t} }{\sigma}{\gamma'}$
\newline
$= \readbackwmap{\sub{u}{\fake{e_{i}}{w^{i}_{1}}{w^{i}_{1}}}{x_{i}}_{1 \leq i \leq n}}{\sigma'}{\gamma'}$
\newline
where
\newline
$\gamma' = \gamma [e_{1}  \mapsto c, \dots, e_{n} \mapsto c]$
\newline
$\sigma' = \sigma [w^{i}_{1} \mapsto \readbackwmap{t}{\sigma}{\gamma'}]_{1 \leq i \leq n} = \sigma [w^{i}_{1} \mapsto \readbackwmap{t}{\sigma}{\gamma}]_{1 \leq i \leq n}$
\newline
$= \readbackwmap{u}{\sigma''}{\gamma'} = \readbackwmap{u}{\sigma''}{\gamma}$
\newline
where
\newline
$\sigma'' = \sigma' [x_{i} \mapsto \readbackwmap{\fake{e_{i}}{w^{i}_{1}}{w^{i}_{1}}}{\sigma'}{\gamma'}]_{1 \leq i \leq n} = \sigma' [x_{i} \mapsto \abs{e_{i}}{\readbackwmap{w^{i}_{1}}{\sigma'_{i}}{\gamma'}}]_{1 \leq i \leq n}$
\newline
\indent $= \sigma' [x_{i} \mapsto \abs{e_{i}}{\readbackwmap{t}{\sigma}{\gamma} \sub{}{e_{i}}{c}}]_{1 \leq i \leq n} =_{\alpha} \sigma' [x_{i} \mapsto \abs{c}{\readbackwmap{t}{\sigma}{\gamma}}]_{1 \leq i \leq n}$
\newline
\indent $=  \sigma [x_{i} \mapsto \abs{c}{\readbackwmap{t}{\sigma}{\gamma}}]_{1 \leq i \leq n}$ since $w^{i}_{1} \not\in \fv{u}$
\newline
\newline
SubCase: $\vec{y} = \set{y_{1}, \dots, y_{m}}$
\newline
$\readbackwmap{\share{u}{x_{1}, \dots, x_{n}}{\fake{c}{y_{1}, \dots, y_{m}}{t}}}{\sigma}{\gamma} = \readbackwmap{u}{\sigma'}{\gamma}$
\newline
where
\newline
$\sigma' = \sigma [x_{i} \mapsto \readbackwmap{\fake{c}{y_{1}, \dots, y_{m}}{t}}{\sigma}{\gamma}]_{1 \leq i \leq n} = \sigma [x_{i} \mapsto \abs{c}{\readbackwmap{t}{\sigma''}{\gamma}}]_{1 \leq i \leq n}$
\newline
$\sigma = \sigma_{1} [y_{1} \mapsto M_{1} , \dots , y_{m} \mapsto M_{m} ]$
\newline
$\sigma'' = \sigma_{1}[ y_{1} \mapsto M_{1} \sub{}{c}{\gamma(c)} , \dots , y_{m} \mapsto M_{m} \sub{}{c}{\gamma(c)}]$
\newline
\newline
$\readbackwmap{\sub{u}{\fake{e_{i}}{w^{i}_{1}}{w^{i}_{1}}}{x_{i}}_{1 \leq i \leq n} \dist{}{\fakedist{e_{1}}{w^{1}_{1}} \dots \fakedist{e_{n}}{w^{n}_{1}}}{\share{}{w^{1}_{1}, \dots, w^{n}_{1}}{t}}{c}{y_{1}, \dots, y_{m}}}{\sigma}{\gamma}$
\newline
$\readbackwmap{\sub{u}{\fake{e_{i}}{w^{i}_{1}}{w^{i}_{1}}}{x_{i}}_{1 \leq i \leq n} \share{}{w^{1}_{1}, \dots, w^{n}_{1}}{t}}{\sigma''}{\gamma'}$
\newline
where $\gamma' = \gamma[e_{1} \mapsto c, \dots, e_{n} \mapsto c]$
\newline
$= \readbackwmap{\sub{u}{\fake{e_{i}}{w^{i}_{1}}{w^{i}_{1}}}{x_{i}}_{1 \leq i \leq n}}{\sigma'''}{\gamma'}$
\newline
where $\sigma''' = \sigma'' [ w^{i}_{1} \mapsto \readbackwmap{t}{\sigma''}{\gamma'}]_{1 \leq i \leq n} = \sigma'' [w^{i}_{1} \mapsto \readbackwmap{t}{\sigma''}{\gamma}]_{1 \leq i \leq n}$
\newline
$= \readbackwmap{u}{\sigma''''}{\gamma'} = \readbackwmap{u}{\sigma''''}{\gamma}  = \readbackwmap{u}{\sigma''}{\gamma}$
\newline
where $\sigma'''' = \sigma''' [x_{i} \mapsto \readbackwmap{\fake{e_{i}}{w^{i}_{1}}{w^{i}_{1}}}{\sigma'''}{\gamma'}]_{1 \leq i \leq n} = \sigma''' [x_{i} \mapsto \abs{e_{i}}{\readbackwmap{w^{i}_{1}}{\sigma'''_{i}}{\gamma'}}]_{1 \leq i \leq n}$
\newline
\indent $= \sigma''' [x_{i} \mapsto \abs{e_{i}}{\readbackwmap{t}{\sigma''}{\gamma} \sub{}{e_{i}}{\gamma'(e_{i})}}]_{1 \leq i \leq n} =_{\alpha} \sigma''' [x_{i} \mapsto \abs{c}{\readbackwmap{t}{\sigma''}{\gamma}}]_{1 \leq i \leq n}$
\newline
\newline
Case: (\ref{red:distelim})
$$\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}} \dots \fakedist{e_{n}}{\vec{w_{n}}}}{\share{}{\vec{w_{1}}, \dots, \vec{w_{n}}}{c}}{c}{c} \rightsquigarrow_{D} \exor{\exor{u}{e_{1}}{\vec{w_{1}}} \dots}{e_{n}}{\vec{w_{n}}}$$
$\readbackwmap{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}} \dots \fakedist{e_{n}}{\vec{w_{n}}}}{\share{}{\vec{w_{1}}, \dots, \vec{w_{n}}}{c}}{c}{c} }{\sigma}{\gamma}$
\newline
$= \readbackwmap{u \share{}{\vec{w_{1}}, \dots, \vec{w_{n}}}{c} }{\sigma}{\gamma'} = \readbackwmap{u}{\sigma'}{\gamma'} $
\newline
$= \readbackwmap{ \exor{\exor{u}{e_{1}}{\vec{w_{1}}} \dots}{e_{n}}{\vec{w_{n}}}}{\sigma}{\gamma'} = \readbackwmap{ \exor{\exor{u}{e_{1}}{\vec{w_{1}}} \dots}{e_{n}}{\vec{w_{n}}}}{\sigma}{\gamma}$
\newline
\newline
For the remaining cases, we say $\readbackwmap{t[\Gamma]}{\sigma}{\gamma}$ produces $\readbackwmap{t}{\sigma_{\Gamma}}{\gamma_{\Gamma}}$ where $\sigma_{\Gamma}$ and $\gamma_{\Gamma}$ are the resulting maps from interpreting the closure $[\Gamma]$
\newline
Case: (\ref{red:liftappleft})
$$\app{s[\Gamma]}{t} \rightsquigarrow_{L} (\app{s}{t})[\Gamma]$$
\newline
$\readbackwmap{\app{s[\Gamma]}{t}}{\sigma}{\gamma} = \app{\readbackwmap{s}{\sigma_{\Gamma}}{\gamma_{\Gamma}}}{\readbackwmap{t}{\sigma}{\gamma}} = \app{\readbackwmap{s}{\sigma_{\Gamma}}{\gamma_{\Gamma}}}{\readbackwmap{t}{\sigma_{\Gamma}}{\gamma_{\Gamma}}} = \readbackwmap{(\app{s}{t}) [\Gamma]}{\sigma}{\gamma}$
\newline
\newline
Case: (\ref{red:liftappright})
$$\app{s[\Gamma]}{t} \rightsquigarrow_{L} (\app{s}{t})[\Gamma]$$
$\readbackwmap{\app{s}{(t [\Gamma])}}{\sigma}{\gamma} = \app{\readbackwmap{s}{\sigma}{\gamma}}{\readbackwmap{t}{\sigma_{\Gamma}}{\gamma_{\Gamma}}} = \app{\readbackwmap{s}{\sigma_{\Gamma}}{\gamma_{\Gamma}}}{\readbackwmap{t}{\sigma_{\Gamma}}{\gamma_{\Gamma}}} = \readbackwmap{(\app{s}{t}) [\Gamma]}{\sigma}{\gamma}$
\newline
\newline
Case: (\ref{red:liftabs})
$$\fake{d}{\vec{x}}{t[\Gamma]} \rightsquigarrow_{L} (\fake{d}{\vec{x}}{t})[\Gamma] $$
\newline
\indent SubCase: $\vec{x} = d$
\newline
$\readbackwmap{\fake{d}{d}{t[\Gamma]}}{\sigma}{\gamma} = \abs{d}{\readbackwmap{t [\Gamma]}{\sigma}{\gamma}} = \abs{d}{\readbackwmap{t}{\sigma_{\Gamma}}{\gamma_{\Gamma}}} = \readbackwmap{\fake{d}{d}{t}}{\sigma_{\Gamma}}{\gamma_{\Gamma}} = \readbackwmap{(\fake{d}{d}{t}) [\Gamma]}{\sigma}{\gamma}$
\newline
\newline
\indent SubCase: $\vec{x} = x_{1}, \dots, x_{n}$
\newline
$\readbackwmap{\fake{d}{x_{1}, \dots, x_{n}}{t[\Gamma]}}{\sigma}{\gamma} = \abs{d}{\readbackwmap{t [\Gamma]}{\sigma'}{\gamma}} = \abs{d}{\readbackwmap{t}{\sigma'_{\Gamma}}{\gamma_{\Gamma}}} = \readbackwmap{\fake{d}{x_{1}, \dots, x_{n}}{t}}{\sigma_{\Gamma}}{\gamma_{\Gamma}}$
\newline
$= \readbackwmap{(\fake{d}{x_{1}, \dots, x_{n}}{t}) [\Gamma]}{\sigma}{\gamma}$
\newline
since we know $x_{1}, \dots, x_{n} \not\in \fv{[\Gamma]}$
\newline
\newline
Case: (\ref{red:liftshare})
$$\share{u}{\vec{x}}{t[\Gamma]} \rightsquigarrow_{L} \share{u}{\vec{x}}{t}[\Gamma]$$
$\readbackwmap{\share{u}{\vec{x}}{t[\Gamma]}}{\sigma}{\gamma} = \readbackwmap{u}{\sigma'}{\gamma} = \readbackwmap{u}{\sigma''}{\gamma_{\Gamma}} = \readbackwmap{\share{u}{\vec{x}}{t}}{\sigma_{\Gamma}}{\gamma_{\Gamma}} = \readbackwmap{\share{u}{\vec{x}}{t[\Gamma]}}{\sigma}{\gamma}$
\newline
where
\newline
$\sigma' = \sigma [x \mapsto \readbackwmap{t [\Gamma]}{\sigma}{\gamma}]_{\forall x \in \vec{x}} = \sigma[x \mapsto \readbackwmap{t}{\sigma_{\Gamma}}{\gamma_{\Gamma}}]_{\forall x \in \vec{x}}$
\newline
$\sigma'' =  \sigma_{\Gamma} [x \mapsto \readbackwmap{t}{\sigma_{\Gamma}}{\gamma_{\Gamma}}]_{\forall x \in \vec{x}}$
\newline
\newline
Cases: (\ref{red:distshare})
$$\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}} \dots \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]} [\Gamma]}{c}{\vec{x}}  \rightsquigarrow_{L}$$ $$\dist{u {\psub{}{(\vec{w_{i}} / \vec{z})}{e_{i}}}_{i \in [n]}}{\fakedist{e_{1}}{\vec{w_{1}} / \vec{z}} \dots \fakedist{e_{n}}{\vec{w_{n}} / \vec{z}}}{\overline{[\Gamma]}}{c}{\vec{x}}[\Gamma] $$
\indent SubCase: $\vec{x} = c$
\newline
$\readbackwmap{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}} \dots \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]} [\Gamma]}{c}{c}}{\sigma}{\gamma} = \readbackwmap{u \overline{[\Gamma]} [\Gamma]}{\sigma}{\gamma'} = \readbackwmap{u \overline{[\Gamma]}}{\sigma_{\Gamma}}{\gamma'_{\Gamma}}$
\newline
$= \readbackwmap{u \overline{[\Gamma]} \psub{}{\vec{z_{1}}}{e_{1}} \dots \psub{}{\vec{z_{n}}}{e_{n}} }{\sigma_{\Gamma}}{\gamma'_{\Gamma}} =  \readbackwmap{u \psub{}{\vec{z_{1}}}{e_{1}} \dots \psub{}{\vec{z_{n}}}{e_{n}} \overline{[\Gamma]}}{\sigma_{\Gamma}}{\gamma'_{\Gamma}}$
\newline
$= \readbackwmap{ \dist{u \psub{}{\vec{z_{1}}}{e_{1}} \dots \psub{}{\vec{z_{n}}}{e_{n}} }{\fakedist{e_{1}}{\vec{z_{1}}} \dots \fakedist{e_{n}}{\vec{z_{n}}}}{\overline{[\Gamma]}}{c}{c}}{\sigma_{\Gamma}}{\gamma_{\Gamma}}$
\newline
$= \readbackwmap{ \dist{u \psub{}{\vec{z_{1}}}{e_{1}} \dots \psub{}{\vec{z_{n}}}{e_{n}} }{\fakedist{e_{1}}{\vec{z_{1}}} \dots \fakedist{e_{n}}{\vec{z_{n}}}}{\overline{[\Gamma]}}{c}{c} [\Gamma]}{\sigma}{\gamma}$
\newline
\newline
\indent SubCase: $\vec{x} = x_{1}, \dots, x_{m}$
\newline
$\readbackwmap{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}} \dots \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]} [\Gamma]}{c}{x_{1}, \dots, x_{m}}}{\sigma}{\gamma} $
\newline
$= \readbackwmap{u \overline{[\Gamma]} [\Gamma]}{\sigma'}{\gamma'} = \readbackwmap{u \overline{[\Gamma]}}{\sigma'_{\Gamma}}{\gamma'_{\Gamma}} = \readbackwmap{u \overline{[\Gamma]} \psub{}{\vec{z_{1}}}{e_{1}} \dots \psub{}{\vec{z_{n}}}{e_{n}} }{\sigma_{\Gamma}}{\gamma'_{\Gamma}}$
\newline
$ =  \readbackwmap{u \psub{}{\vec{z_{1}}}{e_{1}} \dots \psub{}{\vec{z_{n}}}{e_{n}} \overline{[\Gamma]}}{\sigma_{\Gamma}}{\gamma'_{\Gamma}}$
\newline
$= \readbackwmap{\dist{u \psub{}{\vec{z_{1}}}{e_{1}} \dots \psub{}{\vec{z_{n}}}{e_{n}} }{\fakedist{e_{1}}{\vec{z_{1}}} \dots \fakedist{e_{n}}{\vec{z_{n}}}}{\overline{[\Gamma]}}{c}{x_{1}, \dots, x_{n}}}{\sigma_{\Gamma}}{\gamma_{\Gamma}}$
\newline
$= \readbackwmap{\dist{u \psub{}{\vec{z_{1}}}{e_{1}} \dots \psub{}{\vec{z_{n}}}{e_{n}} }{\fakedist{e_{1}}{\vec{z_{1}}} \dots \fakedist{e_{n}}{\vec{z_{n}}}}{\overline{[\Gamma]}}{c}{x_{1}, \dots, x_{n}} [\Gamma]}{\sigma}{\gamma}$
\newline
\newline
Inductive Case: Application $t \rightsquigarrow_{(C, D, L)} t'$
\newline
$\readbackwmap{\app{t}{s}}{\sigma}{\gamma} = \app{\readbackwmap{t}{\sigma}{\gamma}}{\readbackwmap{s}{\sigma}{\gamma}} \IH \app{\readbackwmap{t'}{\sigma}{\gamma}}{\readbackwmap{s}{\sigma}{\gamma}} = \readbackwmap{\app{t'}{s}}{\sigma}{\gamma}$
\newline
\newline
Inductive Case: Application $s \rightsquigarrow_{(C, D, L)} s'$
\newline
$\readbackwmap{\app{t}{s}}{\sigma}{\gamma} = \app{\readbackwmap{t}{\sigma}{\gamma}}{\readbackwmap{s}{\sigma}{\gamma}} \IH \app{\readbackwmap{t}{\sigma}{\gamma}}{\readbackwmap{s'}{\sigma}{\gamma}} = \readbackwmap{\app{t}{s'}}{\sigma}{\gamma}$
\newline
\newline
Inductive Case: Abstraction $t \rightsquigarrow_{(C, D, L)} t'$
\newline
$\readbackwmap{\fake{x}{x}{t}}{\sigma}{\gamma} = \abs{x}{\readbackwmap{t}{\sigma[x \mapsto x]}{\gamma}} \IH \abs{x}{\readbackwmap{t'}{\sigma[x \mapsto x]}{\gamma}} = \readbackwmap{\fake{x}{x}{t'}}{\sigma}{\gamma}$
\newline
\newline
Inductive Case: Phantom-Abstraction $t \rightsquigarrow_{(C, D, L)} t'$
\newline
$\readbackwmap{\fake{c}{\vec{x}}{t}}{\sigma}{\gamma} = \abs{c}{\readbackwmap{t}{\sigma'}{\gamma}} \IH \abs{c}{\readbackwmap{t'}{\sigma'}{\gamma}} = \readbackwmap{\fake{c}{\vec{x}}{t'}}{\sigma}{\gamma}$
\newline
\newline
Inductive Case: Sharing $t \rightsquigarrow_{(C, D, L)} t'$
\newline
$\readbackwmap{\share{u}{x_{1}, \dots, x_{n}}{t}}{\sigma}{\gamma} = \readbackwmap{u}{\sigma[x_{i} \mapsto \readbackwmap{t}{\sigma}{\gamma}]_{i \in [n]}}{\gamma}$
\newline
$\IH \readbackwmap{u}{\sigma[x_{i} \mapsto \readbackwmap{t'}{\sigma}{\gamma}]_{i \in [n]}}{\gamma} = \readbackwmap{\share{u}{x_{1}, \dots, x_{n}}{t'}}{\sigma}{\gamma}$
\newline
\newline
Inductive Case: Sharing $u \rightsquigarrow_{(C, D, L)} u'$
\newline
$\readbackwmap{\share{u}{x_{1}, \dots, x_{n}}{t}}{\sigma}{\gamma} = \readbackwmap{u}{\sigma[x_{i} \mapsto \readbackwmap{t}{\sigma}{\gamma}]_{i \in [n]}}{\gamma}$
\newline
$\IH \readbackwmap{u'}{\sigma[x_{i} \mapsto \readbackwmap{t}{\sigma}{\gamma}]_{i \in [n]}}{\gamma} = \readbackwmap{\share{u'}{x_{1}, \dots, x_{n}}{t}}{\sigma}{\gamma}$
\newline
\newline
Inductive Case: Distributor $\dist{u}{\vecdist{e}{\vec{x}}}{\overline{[\Gamma]}}{c}{c} \rightsquigarrow_{(C, D, L)} \dist{u'}{\vecdist{e}{\vec{x'}}}{\overline{[\Gamma']}}{c}{c}$
\newline
$\readbackwmap{\dist{u}{\vecdist{e}{\vec{x}}}{\overline{[\Gamma]}}{c}{c}}{\sigma}{\gamma} = \readbackwmap{u \overline{[\Gamma]}}{\sigma}{\gamma'} \IH \readbackwmap{u' \overline{[\Gamma']}}{\sigma}{\gamma'} = \readbackwmap{\dist{u'}{\vecdist{e}{\vec{x'}}}{\overline{[\Gamma']}}{c}{c}}{\sigma}{\gamma}$
\end{proof}

\newpage

\section{Strong Normalisation of Sharing Reductions}

The weakening calculus is used to show preservation of strong normalisation with respect to the $\lambda$-calculus. A $\beta$-step in our calculus may occur within a weakening, and therefore is simulated by zero $\beta$-steps in the $\lambda$-calculus. Therefore if there is an infinite reduction path located inside a weakening in $\FALC$, then the reduction path is not preserved in the corresponding $\lambda$-term as there are no weakenings. To deal with this, just as done in \cite{Accattoli-Kesner-2012, Gundersen-Heijltjes-Parigot-2013-LICS, He-2018}, we make use of the weakening calculus. A $\beta$-step is non-deleteing precisely because of the weakening construct. If a $\beta$-step would be deleting in the $\lambda$-calculus, then the weakening calculus would instead keep the deleted term around as `garbage', which can continue to reduce unless explicitly `garbage-collected' by extra (non-$\beta$) reduction steps. The weakening calculus has already been shown to preserve strong normalisation through the use of a perpetual strategy in \cite{gundersen2013atomic}. A part of proving PSN is then using the weakening calculus to prove that if $t \in \FALC$ has a infinite reduction path, then its translation into the weakening calculus also has an infinite reduction path.

\noindent We demonstrate that our readback translation (Definition \ref{def:transfalcweak}) is truly an extention of the translation into the $\lambda$-calculus (Definition \ref{def:readback}). We therefore demonstrate that our operations (substitution, book-keeping, and exorcisms) commute with the two translation functions in the same way.

\begin{proposition}
\label{prop:suboutcomm}
Given $M \in \Lambda$ such that for all $v \in V$, $\gamma(v) \not\in \fv{M}$  and $\sigma(x) = x$, the translation $\readweakwmap{u}{\sigma}{\gamma}$ commutes with substitution $\sub{}{M}{x}$ in the following way

$$\readweakwmap{u \sub{}{t}{x}}{\sigma}{\gamma} = \readweakwmap{u}{\sigma[x \mapsto \readweakwmap{t}{\sigma}{\gamma}]}{\gamma}$$
\end{proposition}

\begin{proof}
We prove this by induction on $u$. The argument is similar to the proof of Proposition \ref{prop:suboutcomm}. We only discuss here to cases involving the three special cases defined in Definition \ref{def:transfalcweak}.
\newline
\newline
Inductive Case: Weakening
\newline
$\readweakwmap{\share{u}{}{s} \sub{}{t}{x}}{\sigma}{\gamma} = \share{\readweakwmap{u \sub{}{t}{x}}{\sigma}{\gamma}}{}{\readweakwmap{s \sub{}{t}{x}}{\sigma}{\gamma}}$
\newline
$\IH \share{ \readweakwmap{u}{\sigma'}{\gamma}}{}{ \readweakwmap{s}{\sigma'}{\gamma}} =  \readweakwmap{\share{u}{}{s}}{\sigma'}{\gamma}$
\newline
\newline
Inductive Case: Distributor
\newline
$\readweakwmap{\dist{u}{}{\overline{[\Gamma]}}{c}{\vec{x}} \sub{}{t}{x}}{\sigma}{\gamma}$
\newline
\newline
\indent SubCase: $\vec{x} = c$
\newline
$\readweakwmap{\dist{u}{}{\overline{[\Gamma]}}{c}{c} \sub{}{t}{x}}{\sigma}{\gamma} = \readweakwmap{\dist{u}{}{\overline{[\Gamma]} \sub{}{t}{x}}{c}{c} }{\sigma}{\gamma}$
\newline
$= \readweakwmap{u \overline{[\Gamma]} \sub{}{t}{x}}{\sigma''}{\gamma'} \IH \readweakwmap{u \overline{[\Gamma]}}{\sigma'''}{\gamma'} = \readweakwmap{\dist{u}{}{\overline{[\Gamma]}}{c}{c}}{\sigma'}{\gamma}$
\newline
where
\newline
$\sigma'' = \sigma[c \mapsto \bullet]$
\newline
$\sigma''' = \sigma [c \mapsto \bullet] [x \mapsto \readweakwmap{t}{\sigma''}{\gamma'}] = \sigma [c \mapsto \bullet][x \mapsto \readweakwmap{t}{\sigma}{\gamma}] $
\newline
\newline
\indent SubCase: $\vec{x} = x_{1}, \dots, x_{n}$
\newline
$\readweakwmap{\dist{u}{}{\overline{[\Gamma]}}{c}{x_{1}, \dots, x_{n}} \sub{}{t}{x}}{\sigma}{\gamma}$
\newline
\newline
\indent \indent SubSubCase: $\vec{x} = x_{1}, \dots, x_{n}, x$
\newline
$\readweakwmap{\dist{u}{}{\overline{[\Gamma]}}{c}{x_{1}, \dots, x_{n}, x} \sub{}{t}{x}}{\sigma}{\gamma}$
\newline
$\readweakwmap{\dist{u}{}{\overline{[\Gamma]}  \sub{}{t}{x}}{c}{x_{1}, \dots, x_{n}, y_{1}, \dots, y_{m}}}{\sigma}{\gamma}$
\newline
where $\set{y_{1}, \dots, y_{m}} = \fv{t}$
\newline
$= \readweakwmap{u \overline{[\Gamma]} \sub{}{t}{x}}{\sigma''}{\gamma}$
\newline
where
\newline
$\sigma = \sigma_{1}[x_{1} \mapsto M_{1}, \dots, x_{n} \mapsto M_{n}, y_{1} \mapsto N_{1}, \dots, y_{m} \mapsto N_{m}]$
\newline
$\sigma'' = \sigma_{1} [ x_{1} \mapsto M_{1} \sub{}{\bullet}{\gamma(c)}, \dots, x_{n} \mapsto M_{n}\sub{}{\bullet}{\gamma(c)}, y_{1} \mapsto N_{1}\sub{}{\bullet}{\gamma(c)}, \dots, y_{m} \mapsto N_{m}\sub{}{\bullet}{\gamma(c)} ] $
\newline
$\IH \readweakwmap{u \overline{[\Gamma]} }{\sigma'''}{\gamma} = \readweakwmap{\dist{u}{}{\overline{[\Gamma]}}{c}{x_{1}, \dots, x_{n}, x}}{\sigma'}{\gamma}$
\newline
where
$\sigma''' = \sigma'' [x \mapsto \readweakwmap{t}{\sigma''}{\gamma}] = \sigma'' [x \mapsto \readweakwmap{t}{\sigma'}{\gamma} \sub{}{\bullet}{\gamma(c)}]$
\newline
since $\set{y_{1}, \dots, y_{m}} = \fv{t}$
\newline
\newline
\indent \indent SubSubCase: $\vec{x} = x_{1}, \dots, x_{n}$
\newline
$\readweakwmap{\dist{u}{}{\overline{[\Gamma]}}{c}{x_{1}, \dots, x_{n}} \sub{}{t}{x}}{\sigma}{\gamma} = \readweakwmap{\dist{u}{}{\overline{[\Gamma]} \sub{}{t}{x} }{c}{x_{1}, \dots, x_{n}} }{\sigma}{\gamma}$
\newline
$\readweakwmap{u \overline{[\Gamma]} \sub{}{t}{x}}{\sigma''}{\gamma} \IH \readweakwmap{u \overline{[\Gamma]}}{\sigma'''}{\gamma} = \readweakwmap{\dist{u}{}{\overline{[\Gamma]}}{c}{x_{1}, \dots, x_{n}} }{\sigma'}{\gamma} $
\newline
$\sigma = \sigma_{1} [x_{1} \mapsto M_{1}, \dots, x_{n} \mapsto M_{n}]$
\newline
$\sigma'' = \sigma_{1} [x_{1} \mapsto M_{1} \sub{}{\bullet}{\gamma(c)}, \dots, x_{n} \mapsto M_{n} \sub{}{\bullet}{\gamma(c)}]$
\newline
$\sigma''' = \sigma'' [x \mapsto \readweakwmap{t}{\sigma''}{\gamma}] = \sigma'' [x \mapsto \readweakwmap{t}{\sigma}{\gamma}]$
\newline
since $\set{x_{1}, \dots, x_{n}} \cap \fv{t} = \set{}$
\end{proof}

\begin{proposition}
\label{prop:bkcommweak}
Book-keeping commutes with the translation in the following way

if $\fake{c}{y_{1}, \dots, y_{m}} \in \fc{u}$ such that $\set{x_{1}, \dots, x_{n}} \subset \set{y_{1}, \dots, y_{m}}$

and for those $z \in \set{y_{1}, \dots, y_{m}} / \set{x_{1}, \dots, x_{n}}$, $\gamma(c) \not\in \fv{\sigma(z)}$

or if simply $\set{x_{1}, \dots, x_{n}} \cap \fv{u} = \set{}$

$$\readweakwmap{u \psub{}{x_{1}, \dots, x_{n}}{c}}{\sigma}{\gamma} = \readweakwmap{u}{\sigma}{\gamma}$$

\end{proposition}

\begin{proof}
We prove this by induction on $u$. The argument is similar to the proof of Proposition \ref{prop:bkcomm}. We only discuss here to cases involving the three special cases defined in Definition \ref{def:transfalcweak}.
\newline
\newline
Inductive Case: Weakening
\newline
$\readweakwmap{\share{u}{}{t} \psub{}{x_{1}, \dots, x_{n}}{c}}{\sigma}{\gamma} = \share{\readweakwmap{u \psub{}{x_{1}, \dots, x_{n}}{c}}{\sigma}{\gamma}}{}{\readweakwmap{t \psub{}{x_{1}, \dots, x_{n}}{c}}{\sigma}{\gamma}}$
\newline
$\IH \share{\readweakwmap{u}{\sigma}{\gamma}}{}{\readweakwmap{t}{\sigma}{\gamma}} = \readweakwmap{\share{u}{}{t}}{\sigma}{\gamma}$
\newline
\newline
Base Case: Distributor
\newline
$\readweakwmap{\dist{u}{}{\overline{[\Gamma]}}{c}{\vec{x}} \psub{}{x_{1}, \dots, x_{n}}{c}}{\sigma}{\gamma} = \readweakwmap{\dist{u}{}{\overline{[\Gamma]}}{c}{x_{1}, \dots, x_{n}} }{\sigma}{\gamma}$
\newline
$\readweakwmap{u \overline{[\Gamma]}}{\sigma'}{\gamma} = \readweakwmap{\dist{u}{}{\overline{[\Gamma]}}{c}{\vec{x}}}{\sigma}{\gamma}$
\newline
where
$\sigma' = \sigma [x_{1} \mapsto \sigma(x_{1})\sub{}{\bullet}{\gamma(c)}, \dots, x_{n} \mapsto \sigma(x_{n}) \sub{}{\bullet}{\gamma(c)}]$
\newline
and notice for $x_{i} \neq y \in \vec{x}$, $[y \mapsto N] = [y \mapsto N \sub{}{\bullet}{\gamma(c)}]$
\newline
\newline
Inductive Case: Distributor
\newline
$\readweakwmap{\dist{u}{}{\overline{[\Gamma]}}{d}{d} \psub{}{x_{1}, \dots, x_{n}}{c}}{\sigma}{\gamma} = \readweakwmap{\dist{u}{}{\overline{[\Gamma]} \psub{}{x_{1}, \dots, x_{n}}{c}}{d}{d} }{\sigma}{\gamma}$
\newline
$\readweakwmap{u \overline{[\Gamma]} \psub{}{x_{1}, \dots, x_{n}}{c}}{\sigma'}{\gamma} \IH \readweakwmap{u \overline{[\Gamma]} }{\sigma'}{\gamma} = \readweakwmap{\dist{u}{}{\overline{[\Gamma]}}{d}{d}}{\sigma}{\gamma}$
\newline
where $\sigma' = \sigma [d \mapsto \bullet]$
\newline
\newline
$\readweakwmap{\dist{u}{}{\overline{[\Gamma]}}{d}{z_{1}, \dots, z_{n}}\psub{}{x_{1}, \dots, x_{n}}{c}}{\sigma}{\gamma} = \readweakwmap{\dist{u}{}{\overline{[\Gamma]} \psub{}{x_{1}, \dots, x_{n}}{c}}{d}{z_{1}, \dots, z_{n}} }{\sigma}{\gamma}$
\newline
$\readweakwmap{u \overline{[\Gamma]} \psub{}{x_{1}, \dots, x_{n}}{c}}{\sigma'}{\gamma} \IH \readweakwmap{u \overline{[\Gamma]} }{\sigma'}{\gamma} = \readweakwmap{\dist{u}{}{\overline{[\Gamma]}}{d}{z_{1}, \dots, z_{n}}}{\sigma}{\gamma}$
\newline
where
\newline
$\sigma' = \sigma [z_{1} \mapsto \sigma(x_{1}) \sub{}{\bullet}{\gamma(d)}, \dots, z_{n} \mapsto \sigma(x_{n}) \sub{}{\bullet}{\gamma(d)}]$
\end{proof}

\begin{proposition}
\label{prop:exorcommweak}
Exorcisms commute with the translation in the following way

if $\fake{c}{x_{1}, \dots, x_{n}} \in \fc{u}$ or $\set{x_{1}, \dots, x_{n}} \cap \fv{u} = \set{}$

$$\readweakwmap{u \exor{}{c}{x_{1}, \dots, x_{n}}}{\sigma}{\gamma} = \readweakwmap{u}{\sigma'}{\gamma}$$

where

$\sigma' = \sigma \cup \set{x_{1} \mapsto c, \dots , x_{n} \mapsto c}$
\end{proposition}

\begin{proof}
We prove this by induction on $u$. The argument is similar to the proof of Proposition \ref{prop:exorcomm}. We only discuss here to cases involving the three special cases defined in Definition \ref{def:transfalcweak}.
\newline
\newline
Inductive Case: Weakening
\newline
$\readweakwmap{\share{u}{}{t} \exor{}{c}{x_{1}, \dots, x_{n}}}{\sigma}{\gamma} = \share{\readweakwmap{u \exor{}{c}{x_{1}, \dots, x_{n}}}{\sigma}{\gamma}}{}{\readweakwmap{t \exor{}{c}{x_{1}, \dots, x_{n}}}{\sigma}{\gamma}}$
\newline
$\IH \share{\readweakwmap{u}{\sigma'}{\gamma}}{}{\readweakwmap{t}{\sigma'}{\gamma}} = \readweakwmap{\share{u}{}{t}}{\sigma'}{\gamma}$
\newline
\newline
Base Case: Distributor
\newline
$\readweakwmap{\dist{u}{}{\overline{[\Gamma]}}{c}{x_{1}, \dots, x_{n}} \exor{}{c}{x_{1}, \dots, x_{n}} }{\sigma}{\gamma} = \readweakwmap{\dist{u}{}{\overline{[\Gamma]} \share{}{x_{1}, \dots, x_{n}}{c}}{c}{c}  }{\sigma}{\gamma}$
\newline
$= \readweakwmap{u \overline{[\Gamma]}  \share{}{x_{1}, \dots, x_{n}}{c} }{\sigma''}{\gamma} = \readweakwmap{u \overline{[\Gamma]}}{\sigma'''}{\gamma} = \readweakwmap{\dist{u}{}{\overline{[\Gamma]}}{c}{x_{1}, \dots, x_{n}}}{\sigma'}{\gamma}$
\newline
where
\newline
$\sigma'' = \sigma [c \mapsto \bullet]$
\newline
$\sigma''' = \sigma [x_{1} \mapsto \bullet, \dots, x_{n} \mapsto \bullet]$
\newline
\newline
Inductive Case: Distributor
\newline
$\readweakwmap{\dist{u}{}{\overline{[\Gamma]}}{d}{d} \exor{}{c}{x_{1}, \dots, x_{n}} }{\sigma}{\gamma} = \readweakwmap{\dist{u}{}{\overline{[\Gamma]}  \exor{}{c}{x_{1}, \dots, x_{n}} }{d}{d} }{\sigma}{\gamma}$
\newline
$= \readweakwmap{u \overline{[\Gamma]}  \exor{}{c}{x_{1}, \dots, x_{n}} }{\sigma''}{\gamma} \IH \readweakwmap{u \overline{[\Gamma]} }{\sigma'''}{\gamma} = \readweakwmap{\dist{u}{}{\overline{[\Gamma]}}{d}{d} }{\sigma'}{\gamma} $
\newline
where
\newline
$\sigma'' = \sigma [d \mapsto \bullet]$
\newline
$\sigma''' = \sigma'' [x_{1} \mapsto c, \dots , x_{n} \mapsto c]$
\newline
\newline
$\readweakwmap{\dist{u}{}{\overline{[\Gamma]}}{d}{z_{1}, \dots, z_{m}} \exor{}{c}{x_{1}, \dots, x_{n}} }{\sigma}{\gamma}$
\newline
$ = \readweakwmap{\dist{u}{}{\overline{[\Gamma]}  \exor{}{c}{x_{1}, \dots, x_{n}} }{d}{z_{1}, \dots, z_{m}} }{\sigma}{\gamma}$
\newline
$= \readweakwmap{u \overline{[\Gamma]}  \exor{}{c}{x_{1}, \dots, x_{n}} }{\sigma''}{\gamma} \IH \readweakwmap{u \overline{[\Gamma]} }{\sigma'''}{\gamma} = \readweakwmap{\dist{u}{}{\overline{[\Gamma]}}{d}{d} }{\sigma'}{\gamma} $
\newline
where
\newline
$\sigma'' = \sigma[z_{1} \mapsto  \sigma(z_{1})  \sub{}{\bullet}{\gamma(d)}, \dots, z_{m} \mapsto \sigma(z_{m}) \sub{}{\bullet}{\gamma(d)}]$
\newline
$\sigma''' = \sigma'' [x_{1} \mapsto c, \dots , x_{n} \mapsto c]$
\end{proof}

Some of our proofs in the future also extract substitutions out of the map $\sigma$ and apply them to the resulting term. We use the following proposition to demonstrate how we do this. We use $\sigma \sub{}{M}{x}$ to denote for all variables $z$, $\sigma \sub{}{M}{x} (z) = \sigma(z) \sub{}{M}{x}$.

\begin{proposition}
\label{prop:suboutcommweak}
Given $M \in \WEAK$ such that for all $v \in V$, $\gamma(v) \not\in \fv{M}$  and $\sigma(x) = x$

$$\readbackwmap{u}{\sigma'}{\gamma} = \readbackwmap{u}{\sigma}{\gamma} \sub{}{M}{x}$$

where  $\sigma' = (\sigma \sub{}{M}{x}) [x \mapsto M]$
\end{proposition}

\begin{proof}
We prove this by induction on $u$
\newline
\newline
Base Case: Variable
\newline
$\readbackwmap{x}{\sigma}{\gamma} \sub{}{M}{x} = x \sub{}{M}{x} = M = \readbackwmap{x}{\sigma'}{\gamma}$
\newline
\newline
$\readbackwmap{y}{\sigma}{\gamma} \sub{}{M}{x} = N \sub{}{M}{x} = \readbackwmap{y}{\sigma'}{\gamma}$
\newline
\newline
Inductive Case: Application
\newline
$\readbackwmap{\app{s}{t}}{\sigma}{\gamma} \sub{}{M}{x} = \app{\readbackwmap{s}{\sigma}{\gamma} \sub{}{M}{x}}{\readbackwmap{t}{\sigma}{\gamma} \sub{}{M}{x}} \IH \app{\readbackwmap{s}{\sigma}{\gamma}}{\readbackwmap{t}{\sigma'}{\gamma}} = \readbackwmap{\app{s}{t}}{\sigma'}{\gamma}$
\newline
\newline
Inductive Case: Abstraction
\newline
$\readbackwmap{\fake{c}{c}{t}}{\sigma}{\gamma} \sub{}{M}{x} = \abs{c}{\readbackwmap{t}{\sigma}{\gamma} \sub{}{M}{x}} \IH \abs{c}{\readbackwmap{t}{\sigma'}{\gamma}} = \readbackwmap{\fake{c}{c}{t}}{\sigma'}{\gamma}$
\newline
\newline
Inductive Case: Phantom-Abstraction
\newline
$\readbackwmap{\fake{c}{x_{1}, \dots, x_{n}}{t}}{\sigma}{\gamma} \sub{}{M}{x} = (\abs{c}{\readbackwmap{t}{\sigma''}{\gamma}}) \sub{}{M}{x} = \abs{c}{\readbackwmap{t}{\sigma''}{\gamma} \sub{}{M}{x}} \IH \abs{c}{\readbackwmap{t}{\sigma'''}{\gamma}}$
\newline
$= \readbackwmap{\fake{c}{x_{1}, \dots, x_{n}}{t}}{\sigma'}{\gamma}$
\newline
where
\newline
$\sigma'' = \sigma [x_{1} \mapsto \sigma(x_{1}) \sub{}{c}{d} , \dots , x_{n} \mapsto \sigma(x_{n}) \sub{}{c}{d}]$
\newline
$\sigma''' = \sigma'' \sub{}{M}{x} [x \mapsto M]$
\newline
$\sigma''' =  \sigma\sub{}{M}{x} [x_{1} \mapsto \sigma(x_{1}) \sub{}{M}{x} \sub{}{c}{d} , \dots , x_{n} \mapsto \sigma(x_{n}) \sub{}{M}{x} \sub{}{c}{d} , x \mapsto M]$
\newline
\newline
Inductive Case: Sharing
\newline
$\readbackwmap{\share{u}{z_{1}, \dots, z_{n}}{t}}{\sigma}{\gamma} \sub{}{M}{x} = \readbackwmap{u}{\sigma''}{\gamma} \sub{}{M}{x} \IH \readbackwmap{u}{\sigma'''}{\gamma} = \readbackwmap{\share{u}{z_{1}, \dots, z_{n}}{t}}{\sigma'}{\gamma}$
\newline
where
\newline
$\sigma'' = \sigma [z_{i} \mapsto \readbackwmap{t}{\sigma}{\gamma}]_{i \in [n]}$
\newline
$\sigma''' = \sigma \sub{}{M}{x} [z_{i} \mapsto \readbackwmap{t}{\sigma \sub{}{x}{M} [x \mapsto M]}{\gamma} , x \mapsto M]_{i \in [n]}$
\newline
\newline
Inductive Case: Distributor 1
\newline
$\readbackwmap{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}}, \dots, \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]}}{c}{c}}{\sigma}{\gamma} \sub{}{M}{x}$
\newline
$= \readbackwmap{u \overline{[\Gamma]}}{\sigma}{\gamma'} \sub{}{M}{x} \IH \readbackwmap{u \overline{[\Gamma]}}{\sigma'}{\gamma'}$
\newline
$= \readbackwmap{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}}, \dots, \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]}}{c}{c}}{\sigma'}{\gamma}$
\newline
where
\newline
$\gamma' = \gamma [e_{1} \mapsto c, \dots, e_{n} \mapsto c]$
\newline
\newline
Inductive Case: Distributor 2
\newline
$\readbackwmap{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}}, \dots, \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]}}{c}{\vec{x}}}{\sigma}{\gamma} \sub{}{M}{x}$
\newline
$= \readbackwmap{u \overline{[\Gamma]}}{\sigma''}{\gamma'} \sub{}{M}{x} \IH \readbackwmap{u \overline{[\Gamma]}}{\sigma'''}{\gamma'}$
\newline
$= \readbackwmap{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}}, \dots, \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]}}{c}{\vec{x}}}{\sigma'}{\gamma}$
\newline
where
\newline
$\gamma' = \gamma [e_{1} \mapsto c, \dots, e_{n} \mapsto c]$
\newline
\newline
Inductive Case: Weakening
\newline
$\readweakwmap{\share{u}{}{t}}{\sigma'}{\gamma} = \share{\readbackwmap{u}{\sigma'}{\gamma}}{}{\readbackwmap{t}{\sigma'}{\gamma}} \IH \share{\readbackwmap{u}{\sigma}{\gamma} \sub{}{M}{x}}{}{\readbackwmap{t}{\sigma}{\gamma} \sub{}{M}{x}} $
\newline
$= \share{\readbackwmap{u}{\sigma}{\gamma}}{}{\readbackwmap{t}{\sigma}{\gamma}}  \sub{}{M}{x} = \readweakwmap{\share{u}{}{t}}{\sigma}{\gamma} \sub{}{M}{x}$
\newline
\newline
Inductive Case: Distributor
\newline
$\readweakwmap{\dist{u}{}{\overline{[\Gamma]}}{c}{\vec{x}}}{\sigma'}{\gamma}$
\newline
\newline
\indent SubCase: $\vec{x} = c$
\newline
$\readweakwmap{\dist{u}{}{\overline{[\Gamma]}}{c}{c}}{\sigma'}{\gamma} = \readweakwmap{u \overline{[\Gamma]}}{\sigma''}{\gamma} \IH \readweakwmap{u \overline{[\Gamma]}}{\sigma'''}{\gamma} \sub{}{M}{x}$
\newline
$ = \readweakwmap{\dist{u}{}{\overline{[\Gamma]}}{c}{c}}{\sigma}{\gamma}  \sub{}{M}{x}$
\newline
where
\newline
$\sigma''' = \sigma [c \mapsto \bullet]$
\newline
$\sigma'' = \sigma' [c \mapsto \bullet]$
\newline
\newline
\indent SubCase $\vec{x} = x_{1}, \dots, x_{n}$
\newline
$\readweakwmap{\dist{u}{}{\overline{[\Gamma]}}{c}{x_{1}, \dots, x_{n}}}{\sigma'}{\gamma} = \readweakwmap{u \overline{[\Gamma]}}{\sigma''}{\gamma} \IH \readweakwmap{u \overline{[\Gamma]}}{\sigma'''}{\gamma} \sub{}{M}{x}$
\newline
$ = \readweakwmap{\dist{u}{}{\overline{[\Gamma]}}{c}{c}}{\sigma}{\gamma}  \sub{}{M}{x}$
\newline
where
\newline
$\sigma' = \sigma_{1}\sub{}{M}{x} [x_{1} \mapsto M_{1}\sub{}{M}{x}, \dots, x_{n} \mapsto M_{n}\sub{}{M}{x}] [x \mapsto M]$
\newline
$\sigma'' = \sigma_{1}\sub{}{M}{x} [x_{1} \mapsto M_{1}\sub{}{M}{x} \sub{}{\bullet}{\gamma(c)}, \dots, x_{n} \mapsto M_{n} \sub{}{M}{x} \sub{}{\bullet}{\gamma(c)}] [x \mapsto M]$
\newline
$\sigma''' = \sigma_{1} [x_{1} \mapsto M_{1} \sub{}{\bullet}{\gamma(c)}, \dots, x_{n} \mapsto M_{n} \sub{}{\bullet}{\gamma(c)}]$
\end{proof}

\noindent Below we repeat Proposition {\bf \ref{prop:equalterms}}.

For $N \in \Lambda$ and $t \in \FALC$ the following properties hold
\begin{center}
\begin{tabular}{c@{\hskip 0.5in} c@{\hskip 0.5in} c}
	\begin{tikzpicture}[auto]
		\node (ale) at (-0.5, 0) {$\FALC$};
		\node (bob) at (2.5, 0) {$\WEAK$};
		\node (cat) at (1,-2) {$\Lambda$};
		%%%%%%%%%%%%%
		\draw [->,red] (ale) to node [black] {$\readweakwmap{-}{\sigma^{\weaksymbol}}{\gamma}$}  (bob);
		\draw [->,blue] (bob) to node [black] {$\readbackweak{-}$}  (cat);
		\draw [->, purple] (ale) to node [black, swap] {$\readbackwmap{-}{\sigma^{\Lambda}}{\gamma}$} (cat);
	\end{tikzpicture}
	&
	\begin{tikzpicture}[auto]
		\node (ale) at (0, 0) {$\FALC$};
		\node (bob) at (2, 0) {$\WEAK$};
		\node (cat) at (1,-2) {$\Lambda$};
		%%%%%%%%%%%%%
		\draw [->,red] (ale) to node [black] {$\composeweak{-}$}  (bob);
		\draw [->,orange] (cat) to node [black, swap] {$\compweak{-}$}  (bob);
		\draw [->, yellow] (cat) to node [black] {$\compile{-}$} (ale);
	\end{tikzpicture}
	&
	\begin{tikzpicture}[auto]
		\node (ale) at (0, -2) {$\Lambda$};
		\node (bob) at (2, -2) {$\Lambda$};
		\node (cat) at (1,0) {$\WEAK$};
		%%%%%%%%%%%%%
		\draw [->,black] (ale) to node [black] {$=$}  (bob);
		\draw [->,orange] (ale) to node [black] {$\compweak{-}$}  (cat);
		\draw [->, blue] (cat) to node [black] {$\readbackweak{-}$} (bob);
	\end{tikzpicture}
	\\
	$\readbackweak{\readweakwmap{t}{\sigma^{\weaksymbol}}{\gamma}} = \readbackwmap{t}{\sigma^{\Lambda}}{\gamma}$
	&
	$\composeweak{\compile{N}} = \compweak{N}$
	&
	$\readbackweak{\compweak{N}} = N$
\end{tabular}

\end{center}

\noindent where $\sigma^{\Lambda}(z) = \readbackweak{\sigma^{\weaksymbol}(z)} $.

\begin{proof}
We prove $\readbackweak{\readweakwmap{u}{\sigma^{\weaksymbol}}{\gamma}} = \readbackwmap{u}{\sigma^{\Lambda}}{\gamma}$ by induction on $u$.
\newline
\newline
Base Case: Variable
\newline
$\readbackweak{\readweakwmap{x}{\sigma^{\weaksymbol}}{\gamma}} = \readbackweak{\sigma^{\weaksymbol}(x)} = \readbackwmap{x}{\sigma^{\Lambda}}{\gamma}$
\newline
\newline
Inductive Case: Application
\newline
$\readbackweak{\readweakwmap{\app{s}{t}}{\sigma^{\weaksymbol}}{\gamma}} = \app{\readbackweak{\readweakwmap{s}{\sigma^{\weaksymbol}}{\gamma}}}{\readbackweak{\readweakwmap{t}{\sigma^{\weaksymbol}}{\gamma}}} \IH \app{\readbackwmap{s}{\sigma^{\Lambda}}{\gamma}}{\readbackwmap{t}{\sigma^{\Lambda}}{\gamma}} = \readbackwmap{\app{s}{t}}{\sigma^{\Lambda}}{\gamma}$
\newline
\newline
Inductive Case: Abstraction
\newline
$\readbackweak{\readweakwmap{\fake{x}{x}{t}}{\sigma^{\weaksymbol}}{\gamma}} = \abs{x}{\readbackweak{\readweakwmap{t}{\sigma^{\weaksymbol}}{\gamma}}} \IH \abs{x}{\readbackwmap{t}{\sigma^{\Lambda}}{\gamma}} = \readbackwmap{\fake{x}{x}{t}}{\sigma^{\Lambda}}{\gamma}$
\newline
\newline
Inductive Case: Phantom-Abstraction
\newline
$\readbackweak{\readweakwmap{\fake{c}{x_{1}, \dots, x_{n}}{t}}{\sigma^{\weaksymbol}}{\gamma}} = \abs{c}{\readbackweak{\readweakwmap{t}{\sigma_{1}^{\weaksymbol}}{\gamma}}} \IH \abs{c}{\readbackwmap{x}{\sigma_{1}^{\Lambda}}{\gamma}} = \readbackwmap{\fake{c}{x_{1}, \dots, x_{n}}{t}}{\sigma^{\Lambda}}{\gamma}$
\newline
where
\newline
$\sigma_{1}^{\weaksymbol} = \sigma [x_{1} \mapsto \sigma(x_{1}) \sub{}{c}{\gamma(c)}, \dots, x_{n} \mapsto \sigma(x_{n})  \sub{}{c}{\gamma(c)}]$
\newline
$\sigma_{1}^{\Lambda} = \sigma [x_{1} \mapsto \readbackweak{\sigma(x_{1})} \sub{}{c}{\gamma(c)}, \dots, x_{n} \mapsto \readbackweak{\sigma(x_{n})}  \sub{}{c}{\gamma(c)}]$
\newline
\newline
Inductive Case: Weakening
\newline
$\readbackweak{\readweakwmap{\share{u}{}{t}}{\sigma^{\weaksymbol}}{\gamma}} = \readbackweak{\readweakwmap{u}{\sigma^{\weaksymbol}}{\gamma}} \IH \readbackwmap{u}{\sigma^{\Lambda}}{\gamma} = \readbackwmap{\share{u}{}{t}}{\sigma^{\Lambda}}{\gamma}$
\newline
\newline
Inductive Case: Sharing
\newline
$\readbackweak{\readweakwmap{\share{u}{x_{1}, \dots, x_{n}}{t}}{\sigma^{\weaksymbol}}{\gamma}} = \readbackweak{\readweakwmap{u}{\sigma_{1}^{\weaksymbol}}{\gamma}} \IH \readbackwmap{u}{\sigma_{1}^{\Lambda}}{\gamma}= \readbackwmap{\share{u}{x_{1}, \dots, x_{n}}{t}}{\sigma^{\Lambda}}{\gamma}$
\newline
where
\newline
$\sigma_{1}^{\weaksymbol} = \sigma^{\weaksymbol} [x_{i} \mapsto \readweakwmap{t}{\sigma^{\weaksymbol}}{\gamma}]_{1 \leq i \leq n}$
\newline
$\sigma_{1}^{\Lambda} = \sigma^{\Lambda} [x_{i} \mapsto \readbackweak{\readweakwmap{t}{\sigma^{\weaksymbol}}{\gamma}}]_{1 \leq i \leq n} \IH  \sigma^{\Lambda} [x_{i} \mapsto \readbackwmap{t}{\sigma^{\Lambda}}{\gamma} ]_{1 \leq i \leq n} $
\newline
\newline
Inductive Case: Distributor
\newline
$\readbackweak{\readweakwmap{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}}, \dots, \fakedist{e_{m}}{\vec{w_{m}}}}{\overline{[\Gamma]}}{c}{\vec{x}}}{\sigma^{\weaksymbol}}{\gamma}}$
\newline
\newline
\indent SubCase: $\vec{x} = c$
\newline
$\readbackweak{\readweakwmap{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}}, \dots, \fakedist{e_{m}}{\vec{w_{m}}}}{\overline{[\Gamma]}}{c}{c}}{\sigma^{\weaksymbol}}{\gamma}}$
\newline
$= \readbackweak{\readweakwmap{u \overline{[\Gamma]}}{\sigma}{\gamma'}} \IH \readbackwmap{u \overline{[\Gamma]}}{\sigma^{\Lambda}}{\gamma'}$
\newline
$= \readbackwmap{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}}, \dots, \fakedist{e_{m}}{\vec{w_{m}}}}{\overline{[\Gamma]}}{c}{c}}{\sigma^{\Lambda}}{\gamma}$
\newline
\newline
\indent SubCase: $\vec{x} = x_{1}, \dots, x_{n}$
\newline
$\readbackweak{\readweakwmap{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}}, \dots, \fakedist{e_{m}}{\vec{w_{m}}}}{\overline{[\Gamma]}}{c}{x_{1}, \dots, x_{n}}}{\sigma^{\weaksymbol}}{\gamma}}$
\newline
$\readbackweak{\readweakwmap{u \overline{[\Gamma]}}{\sigma_{1}^{\weaksymbol}}{\gamma'}} \IH \readbackwmap{u \overline{[\Gamma]}}{\sigma_{1}^{\Lambda}}{\gamma'}$
\newline
$= \readbackwmap{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}}, \dots, \fakedist{e_{m}}{\vec{w_{m}}}}{\overline{[\Gamma]}}{c}{x_{1}, \dots, x_{n}}}{\sigma^{\Lambda}}{\gamma}$\
\newline
where
\newline
$\sigma_{1}^{\weaksymbol} = \sigma [x_{1} \mapsto \sigma(x_{1}) \sub{}{c}{\gamma(c)}, \dots, x_{n} \mapsto \sigma(x_{n})  \sub{}{c}{\gamma(c)}]$
\newline
$\sigma_{1}^{\Lambda} = \sigma [x_{1} \mapsto \readbackweak{\sigma(x_{1})} \sub{}{c}{\gamma(c)}, \dots, x_{n} \mapsto \readbackweak{\sigma(x_{n})}  \sub{}{c}{\gamma(c)}]$
\newline
\newline
We prove $\composeweak{\compile{N}} = \compweak{N}$ by induction on $N$. We prove this statement by first proving it for closed terms.
\newline
\newline
Base Case: Variable
\newline
$\composeweak{\compile{x}'} = \composeweak{x} =  x = \compweak{x}$
\newline
\newline
Inductive Case: Application
\newline
$\composeweak{\compile{\app{M}{N}}'}= \app{\composeweak{\compile{M}'}}{\composeweak{\compile{N}'}} \IH \app{\compweak{M}}{\compweak{N}} = \compweak{\app{M}{N}} $
\newline
\newline
Inductive Case: Abstraction
\newline
$\composeweak{\compile{\abs{x}{M}}'}$
\newline
\indent SubCase: $\size{M}_{x} = 0$
\newline
\indent $= \abs{x}{\composeweak{\compile{M}' \share{}{}{x}}} = \abs{x}{\composeweak{\compile{M}'} \share{}{}{x}} \IH \abs{x}{\compweak{M} \share{}{}{x}} = \compweak{\abs{x}{M}}$
\newline
\newline
\indent SubCase: $\size{M}_{x} = 1$
\newline
\indent $= \abs{x}{\composeweak{\compile{M}'}} \IH \abs{x}{\compweak{M}} = \compweak{\abs{x}{M}}$
\newline
\newline
\indent SubCase: $\size{M}_{x} = n > 1$
\newline
\indent $= \composeweak{\compile{M \frac{n}{x} }' \share{}{x^{1}, \dots, x^{n}}{x}} = \readweakwmap{\compile{M \frac{n}{x} }' }{\sigma}{I} \byprop{prop \ref{prop:suboutcommweak}} \composeweak{\compile{M \frac{n}{x}}'} \sub{}{x}{x_{i}}_{1 \leq i \leq n}$
\newline
\indent $\IH \compweak{M \frac{n}{x}} \sub{}{x}{x_{i}}_{1 \leq i \leq n} = \compweak{M}$
\newline
\newline
Now that we have proven is works for closed terms, we can show the statement $\composeweak{\compile{N}} = \compweak{N}$ holds
\newline
\newline
$\composeweak{\compile{N}} =  \composeweak{\compile{N \frac{n_{1}}{x_{1}} \dots \frac{n_{k}}{x_{k}}}' \share{}{x^{1}_{1}, \dots, x^{n_{1}}_{1}}{x_{1}} \dots \share{}{x^{1}_{k}, \dots, x^{n_{k}}_{k}}{x_{k}} }$
\newline
$\byprop{prop \ref{prop:suboutcommweak}} \composeweak{\compile{N \frac{n_{1}}{x_{1}} \dots \frac{n_{k}}{x_{k}}}' } \sub{}{x_{i}}{x^{j}_{i}}_{1 \leq i \leq k, 1 \leq j \leq n_{i}} = \compweak{N \frac{n_{1}}{x_{1}} \dots \frac{n_{k}}{x_{k}}}\sub{}{x_{i}}{x^{j}_{i}}_{1 \leq i \leq k, 1 \leq j \leq n_{i}} = \compweak{N}$
\end{proof}

We also discuss the proofs for Lemma \ref{lem:sharepreservebeta} and Lemma \ref{theo:sharepreserve}. These are:
	Given $t \rightsquigarrow_{\beta} u$ then $$\composeweak{t} \rightarrow^{\plus}_{\beta} \composeweak{u}$$
and given $t \rightsquigarrow_{(C, D, L)} u$ and for any $x \in \bv{t} \cup \fp{t}$ and for all $z$, $x \not\in \fv{\sigma(z)}$.  $$\readweakwmap{t}{\sigma}{\gamma} \rightarrow^{*}_{\weaksymbol} \readweakwmap{u}{\sigma}{\gamma}$$

\begin{proof} We prove this by induction. We first discuss all the case bases.
$\composeweak{\app{(\fake{x}{x}{t})}{s}} = \app{(\abs{x}{T})}{S} = \sub{T}{S}{x} = \composeweak{\sub{t}{s}{x}}$

\noindent where $T = \composeweak{t}$ and $S = \composeweak{s}$.
\newline
\newline
We prove this is true case-by-case, which is an extension of the proof for Lemma \ref{lem:preservesdenotation}. Therefore, we only show the interesting cases.
\newline
\newline
Case: (\ref{red:appdup})
$$\share{u}{}{\app{s}{t}} \rightsquigarrow_{R} \share{\share{u}{}{s}}{}{t} $$
$\readweakwmap{\share{u}{}{\app{s}{t}}}{\sigma}{\gamma} = \share{\readweakwmap{u}{\sigma}{\gamma}}{}{\app{\readweakwmap{s}{\sigma}{\gamma}}{\readweakwmap{t}{\sigma}{\gamma}}} $
\newline
$\rightarrow_{\weaksymbol} \readweakwmap{u}{\sigma}{\gamma} \share{}{}{\readweakwmap{s}{\sigma}{\gamma}} \share{}{}{\readweakwmap{t}{\sigma}{\gamma}} = \readweakwmap{\share{\share{u}{}{s}}{}{t}}{\sigma}{\gamma}$
\newline
\newline
%%%%%%%%%%%%%%%%%%%
Case: (\ref{red:absdup})
$$\share{u}{}{\fake{c}{\vec{x}}{t}} \rightsquigarrow_{R} \dist{u}{}{\share{}{}{t}}{c}{\vec{x}}$$
$\readweakwmap{\share{u}{}{\fake{c}{\vec{x}}{t}}}{\sigma}{\gamma}$
\newline
\indent SubCase: $\vec{x} = c$
\newline
\indent $\readweakwmap{\share{u}{}{\fake{c}{c}{t}}}{\sigma}{\gamma} = \readweakwmap{u}{\sigma}{\gamma} \share{}{}{\abs{c}{\readweakwmap{t}{\sigma}{\gamma}}} \rightarrow_{\weaksymbol} \readweakwmap{u}{\sigma}{\gamma}\share{}{}{\readweakwmap{t}{\sigma}{\gamma} \sub{}{\bullet}{c}} $
\newline
\indent $\byprop{prop \ref{prop:suboutcommweak}} \readweakwmap{u \share{}{}{t}}{\sigma'}{\gamma} = \readweakwmap{ \dist{u}{}{\share{}{}{t}}{c}{c}}{\sigma}{\gamma}$
\newline
\indent where $\sigma' = \sigma [c \mapsto \bullet]$
\newline
\newline
\indent SubCase: $\vec{x} = x_{1}, \dots, x_{n}$
\newline
\indent $\readweakwmap{\share{u}{}{\fake{c}{x_{1}, \dots, x_{n}}{t}}}{\sigma}{\gamma} = \readweakwmap{u}{\sigma}{\gamma} \share{}{}{\readweakwmap{\fake{c}{x_{1}, \dots, x_{n}}{t}}{\sigma}{\gamma}}$
\newline
\indent $\readweakwmap{u}{\sigma}{\gamma} \share{}{}{\abs{c}{\readweakwmap{t}{\sigma'}{\gamma}}} \rightarrow_{\weaksymbol} \readweakwmap{u}{\sigma}{\gamma} \share{}{}{\readweakwmap{t}{\sigma'}{\gamma} \sub{}{\bullet}{c}}$
\newline
\indent $\byprop{prop \ref{prop:suboutcommweak}} \readweakwmap{u \share{}{}{t}}{\sigma''}{\gamma} = \readweakwmap{ \dist{u}{}{\share{}{}{t}}{c}{x_{1}, \dots, x_{n}}}{\sigma}{\gamma}$
\newline
\newline
%%%%%%%%%%%%%%%%%%%
Case: (\ref{red:distelim})
$$\dist{u}{}{\share{}{}{c}}{c}{c} \rightsquigarrow_{R} u$$
$\readweakwmap{\dist{u}{}{\share{}{}{c}}{c}{c}}{\sigma}{\gamma} = \readweakwmap{u \share{}{}{c}}{\sigma'}{\gamma} = \readweakwmap{u}{\sigma'}{\gamma} \share{}{}{\bullet}$
\newline
$= \readweakwmap{u}{\sigma}{\gamma} \share{}{}{\bullet} \rightarrow_{\weaksymbol} \readweakwmap{u}{\sigma}{\gamma}$
%%%%%%%%%%%%%%%%%%%%%%
\newline
\newline
Case (\ref{red:compshare})
$$\share{u}{x}{t} \rightsquigarrow_{C} \sub{u}{t}{x}$$
$\readweakwmap{\share{u}{x}{t}}{\sigma}{\gamma} = \readweakwmap{u}{\sigma'}{\gamma} = \readweakwmap{\sub{u}{t}{x}}{\sigma}{\gamma} $\
\newline
where
\newline
$\sigma' = \sigma [x \mapsto \readweakwmap{t}{\sigma}{\gamma}]$
%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newline
\newline
\newline
For the remaining cases, we only show the cases for  $\readweakwmap{u \share{}{}{t}}{\sigma}{\gamma} = \share{\readweakwmap{u}{\sigma}{\gamma}}{}{\readweakwmap{t}{\sigma}{\gamma}}$. The other cases are similar to those in the proof for Lemma \ref{lem:preservesdenotation}.
\newline
\newline
%%%%%%%%%%%%%%%%%%%%%%%%%%
Case: (\ref{red:liftappleft})
$$\app{s \share{}{}{t}}{u} \rightsquigarrow_{L} (\app{s}{u}) \share{}{}{t}  $$
$\readweakwmap{\app{s \share{}{}{t}}{u}}{\sigma}{\gamma} = \app{\readweakwmap{s}{\sigma}{\gamma} \share{}{}{\readweakwmap{t}{\sigma}{\gamma}}}{\readweakwmap{u}{\sigma}{\gamma}} \rightarrow_{\weaksymbol} (\app{\readweakwmap{s}{\sigma}{\gamma}}{\readweakwmap{u}{\sigma}{\gamma}})  \share{}{}{\readweakwmap{t}{\sigma}{\gamma}} $
\newline
$\readweakwmap{(\app{s}{u}) \share{}{}{t}}{\sigma}{\gamma}$
\newline
\newline
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newline
The proofs for lifting past application (right) (\ref{red:liftappright}) and sharing (\ref{red:liftshare}) follow a similar argument so we choose to omit these cases
\newline
\newline
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Case: (\ref{red:liftabs})
$$\fake{d}{\vec{x}}{u  \share{}{}{t}} \rightsquigarrow_{L} (\fake{d}{\vec{x}}{u})  \share{}{}{t} \text{ iff $\vec{x} \not\in \fv{t}$}$$
\indent SubCase: $\vec{x} = d$
\newline
$\readweakwmap{\fake{d}{d}{u  \share{}{}{t}}}{\sigma}{\gamma} = \abs{d}{( \readweakwmap{u}{\sigma}{\gamma} \share{}{}{\readweakwmap{t}{\sigma}{\gamma}})} \rightarrow_{\weaksymbol} \abs{d}{ \readweakwmap{u}{\sigma}{\gamma}} \share{}{}{\readweakwmap{t}{\sigma}{\gamma}}$
\newline
$= \readweakwmap{(\fake{d}{\vec{x}}{u})  \share{}{}{t}}{\sigma}{\gamma}$
\newline
\newline
\indent SubCase: $\vec{x} = x_{1}, \dots, x_{n}$
\newline
$\readweakwmap{\fake{d}{x_{1}, \dots, x_{n}}{u  \share{}{}{t}}}{\sigma}{\gamma} = \abs{d}{( \readweakwmap{u}{\sigma'}{\gamma} \share{}{}{\readweakwmap{t}{\sigma'}{\gamma}} )}$
\newline
$\rightarrow_{\weaksymbol} \abs{d}{ \readweakwmap{u}{\sigma'}{\gamma}} \share{}{}{\readweakwmap{t}{\sigma'}{\gamma}} = \readweakwmap{(\fake{d}{x_{1}, \dots, x_{n}}{u}) \share{}{}{t}}{\sigma}{\gamma}$
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newline
\newline
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Case: (\ref{red:distshare})
$$\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}} \dots \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]} \share{}{}{t}}{c}{\vec{x}} \rightsquigarrow_{L}$$
$$\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}} \dots \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]}}{c}{\vec{x}} \share{}{}{t}$$
iff all $\vec{x} \not\in \fv{t}$
\newline
\newline
$\readweakwmap{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}} \dots \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]} \share{}{}{t}}{c}{\vec{x}}}{\sigma}{\gamma}$
\newline
\indent Case: $\vec{x} = c$
\newline
$= \readweakwmap{u \overline{[\Gamma] \share{}{}{t}}}{\sigma}{\gamma'} = \readweakwmap{u \overline{[\Gamma]}}{\sigma}{\gamma'} \share{}{}{\readweakwmap{t}{\sigma}{\gamma'}}$
\newline
$= \readweakwmap{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}} \dots \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]}}{c}{c}}{\sigma}{\gamma} \share{}{}{\readweakwmap{t}{\sigma}{\gamma'}}$
\newline
$= \readweakwmap{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}} \dots \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]}}{c}{c}}{\sigma}{\gamma} \share{}{}{\readweakwmap{t}{\sigma}{\gamma}}$
\newline
$= \readweakwmap{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}} \dots \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]}}{c}{c} \share{}{}{t}}{\sigma}{\gamma}$
\newline
\newline
\indent Case: $\vec{x} = x_{1}, \dots, x_{n}$
\newline
$= \readweakwmap{u \overline{[\Gamma] \share{}{}{t}}}{\sigma'}{\gamma'} = \readweakwmap{u \overline{[\Gamma]}}{\sigma'}{\gamma'} \share{}{}{\readweakwmap{t}{\sigma'}{\gamma'}}$
\newline
$= \readweakwmap{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}} \dots \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]}}{c}{x_{1}, \dots, x_{n}}}{\sigma}{\gamma} \share{}{}{\readweakwmap{t}{\sigma'}{\gamma'}}$
\newline
$= \readweakwmap{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}} \dots \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]}}{c}{x_{1}, \dots, x_{n}}}{\sigma}{\gamma} \share{}{}{\readweakwmap{t}{\sigma}{\gamma}}$
\newline
$= \readweakwmap{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}} \dots \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]}}{c}{x_{1}, \dots, x_{n}} \share{}{}{t}}{\sigma}{\gamma}$
\end{proof}

\subsection{Sharing Measure}

We prove strong normalisation of sharing reductions through the use of \emph{multisets}. Intuitively, a multiset can be interpreted as a set where elements can be repeated, or equivalently as lists that are considered equal up to the permutation of elements. We use multisets to measure aspects of a term, and show that these aspects strictly decrease via $\rightsquigarrow_{(R, D, L)}$ reduction.

\begin{definition}[Multisets]
\label{def:multisets}
A \emph{multiset} $m$ is a pair $(A, f)$ where $A$ is a set and $f : A \rightarrow \mathcal{N}$ is a function that maps elements of $A$ to a natural number.
\end{definition}

The formal definition of multisets in Definition \ref{def:multisets} follows intuition when we consider the function $f$ to tell us the number of occurrences of an element $x \in A$ in the multiset $m$.

\begin{example}
Let $m = (\set{x, y, z}, f)$ and $f(x) = 2$, $f(y) = 1$ and $f(z) = 3$. Then this multiset can also be written as $\set{x, x, y, z, z, z}$ or equivalently as $\set{x^{2}, y^{1}, z^{3}}$
\end{example}

\begin{remark}
The empty multiset is written as $\set{}$
\end{remark}

We will need to be able to reason about multisets in order to use them as part of our reasoning for strong normalisation. First we discuss the union of multisets, which will be needed when measuring a term recursively, e.g.\ in an application $\app{s}{t}$ we will need to measure aspects of $s$ and unionise them with the multiset corresponding to the measure of the same of $t$, to obtain the overall measure of the application.

\begin{definition}[Union of Multisets] The \emph{union} (or \emph{sum}) of two multisets $m = (A, f)$ and $n = (B, g)$ is the multiset $m \cupdot n = (A \cup B, h)$ such that for all $x \in A \cup B$, $h (x) = f(x) + g(x)$.
\end{definition}

\begin{example}
Let $m = \set{a^{1}, b^{3}, c^{2}}$ and $n = \set{c^{3}, d^{1}}$, then $m \cupdot n = \set{a^{1}, b^{3}, c^{5}, d^{1}}$
\end{example}

\begin{remark}
The notion $A \cup B$ is the union of the sets and \emph{not} a disjoint union.
\end{remark}

To show strong normalisation of sharing reductions, we need to show that aspects of terms that can be represented as multisets strictly decrease during reduction. In order to show this, we need to be able determine when a multiset is larger/smaller than another i.e.\ we need to be able to apply an ordering.

\begin{definition}[Ordering of Multisets] Given a totally ordered set $A$ and two multisets $m = (A, f)$ and $n = (A, g)$, we say $m$ is strictly larger than $n$, $m > n$, if the following conditions hold
\begin{align*}
	\bullet & m \neq n \\
	\bullet & \forall x \in A. (g(x) > f(x) \rightarrow \exists y \in A.[ (y > x) \wedge (f(y) > g(y))] )
\end{align*}
\end{definition}

\begin{example}
$\set{1^{5}, 2^{2}, 3^{1}} < \set{1^{3}, 2^{4}, 3^{3}}$
\end{example}

The \emph{height} of a term is intuitively a multiset of integers that record the scope of each sharing. The scope is measured by the number of constructors from the sharing node to the root of the term in its graphical notation. The formal definition of the height is given in Definition \ref{def:sharingmeasure}. First we prove {\bf Lemma \ref{theo:liftingheight}} on a case-by-case basis.

If $t \rightsquigarrow_{(L)} u$ then $\height{i}{t} > \height{i}{u}$

\begin{proof}
$$\app{s[\Gamma]}{t} \rightsquigarrow_{L} (\app{s}{t})[\Gamma] $$
$\height{i}{\app{(s[\Gamma])}{t}} = \height{i + 1}{s[\Gamma]} \cupdot \height{i + 1}{t} = \height{i + 1}{s} \cupdot \height{i + 1}{t} \cupdot  \height{i + 1}{[\Gamma]} \cupdot \set{i+1}$
\newline
$\height{i}{(\app{s}{t})[\Gamma]} = \height{i}{\app{s}{t}} \cupdot \height{i}{[\Gamma]} = \height{i+ 1}{s} \cupdot \height{i + 1}{t} \cupdot  \height{i}{[\Gamma]} \cupdot \set{i}$
\newline
$$\app{s}{t[\Gamma]} \rightsquigarrow_{L} (\app{s}{t})[\Gamma] $$
This case is similar to the one above and we omit it.
\newline
$$\fake{d}{\vec{x}}{t[\Gamma]} \rightsquigarrow_{L} (\fake{d}{\vec{x}}{t})[\Gamma] \text{ iff all $\vec{x} \in \fv{t}$}$$
$\height{i}{\fake{c}{\vec{x}}{t[\Gamma]}} = \height{i+1}{t[\Gamma]} = \height{i + 1}{t} \cupdot \height{i + 1}{[\Gamma]} \cupdot \set{i + 1}$
\newline
$\height{i}{(\fake{c}{\vec{x}}{t})[\Gamma]} = \height{i}{\fake{c}{\vec{x}}{t}} \cupdot \height{i}{[\Gamma]} \cupdot \set{i} = \height{i + 1}{t} \cupdot \height{i}{[\Gamma]} \cupdot \set{i}$
\newline
$$\share{u}{\vec{x}}{t[\Gamma]} \rightsquigarrow_{L} \share{u}{\vec{x}}{t}[\Gamma] $$
$\height{i}{\share{u}{\vec{x}}{t[\Gamma]}} = \height{i}{u} \cupdot \height{i}{\share{}{\vec{x}}{t[\Gamma]}} \cupdot \set{i} = \height{i}{u} \cupdot \height{i + 1}{t} \cupdot \height{i + 1}{[\Gamma]} \cupdot \set{i, i + 1}$
\newline
$\height{i}{\share{u}{\vec{x}}{t}[\Gamma]} = \height{i}{\share{u}{\vec{x}}{t}} \cupdot \height{i}{[\Gamma]} \cupdot \set{i} = \height{i}{u} \cupdot \height{i + 1}{t} \cupdot \height{i + 1}{[\Gamma]} \cupdot \set{i, i}$
\newline
$$\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}} \dots \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]} \share{}{\vec{y}}{t}}{c}{\vec{x}} \rightsquigarrow_{L}$$
$$\dist{\psub{ \psub{u}{(\vec{w_{1}} / \vec{y})}{e_{1}} \dots}{(\vec{w_{n}} / \vec{y})}{e_{n}}}{\fakedist{e_{1}}{\vec{w_{1}} / \vec{y}} \dots \fakedist{e_{n}}{\vec{w_{n}} / \vec{y}}}{\overline{[\Gamma]}}{c}{\vec{x}} \share{}{\vec{y}}{t}$$
iff all $\vec{x} \not\in \fv{t}$
\newline
$\height{i}{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}} \dots \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]} \share{}{\vec{y}}{t}}{c}{\vec{x}}}$
\newline
$= \height{i}{u} \cupdot \height{i}{\dist{}{\fakedist{e_{1}}{\vec{w_{1}}} \dots \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]} \share{}{\vec{y}}{t}}{c}{\vec{x}}} \cupdot \set{i}$
\newline
$= \height{i}{u} \cupdot \height{i + 1}{\overline{[\Gamma]}} \cupdot \height{i + 1}{\share{}{\vec{y}}{t}} \cupdot \set{i, (i + 1)^{n + 1}}$
\newline
where $n$ is the number of closures in the environment $\overline{[\Gamma]}$
\newline
$= \height{i}{u} \cupdot \height{i + 1}{\overline{[\Gamma]}} \cupdot \height{i + 2}{t} \cupdot \set{i, (i + 1)^{n + 1}}$
\newline
$\height{i}{\dist{\psub{ \psub{u}{(\vec{w_{1}} / \vec{y})}{e_{1}} \dots}{(\vec{w_{n}} / \vec{y})}{e_{n}}}{\fakedist{e_{1}}{\vec{w_{1}} / \vec{y}} \dots \fakedist{e_{n}}{\vec{w_{n}} / \vec{y}}}{\overline{[\Gamma]}}{c}{\vec{x}} \share{}{\vec{y}}{t}}$
\newline
$= \height{i}{\dist{\psub{ \psub{u}{(\vec{w_{1}} / \vec{y})}{e_{1}} \dots}{(\vec{w_{n}} / \vec{y})}{e_{n}}}{\fakedist{e_{1}}{\vec{w_{1}} / \vec{y}} \dots \fakedist{e_{n}}{\vec{w_{n}} / \vec{y}}}{\overline{[\Gamma]}}{c}{\vec{x}}} \cupdot \height{i + 1}{t} \cupdot \set{i}$
\newline
$= \height{i}{\psub{ \psub{u}{(\vec{w_{1}} / \vec{y})}{e_{1}} \dots}{(\vec{w_{n}} / \vec{y})}{e_{n}}} \cupdot \height{i + 1}{\overline{[\Gamma]}} \cupdot \height{i + 1}{t} \cupdot \set{i^{2}, (i + 1)^{n}}$
\newline
$= \height{i}{u} \cupdot \height{i + 1}{\overline{[\Gamma]}} \cupdot \height{i + 1}{t} \cupdot \set{i^{2}, (i + 1)^{n}}$
\newline
\newline
$$\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}} \dots \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]}\dist{}{\vecdist{f}{\vec{z}}}{\overline{[\Gamma']}}
{d}{\vec{a}}}{c}{\vec{x}} \rightsquigarrow_{L}$$
$$\dist{\psub{ \psub{u}{(\vec{w_{1}} / \vec{z})}{e_{1}} \dots}{(\vec{w_{n}} / \vec{z})}{e_{n}}}{\fakedist{e_{1}}{\vec{w_{1}} / \vec{z}} \dots \fakedist{e_{n}}{\vec{w_{n}} / \vec{z}}}{\overline{[\Gamma]}}{c}{\vec{x}}  \dist{}{\vecdist{f}{\vec{z}}}{\overline{[\Gamma']}}{d}{\vec{a}}$$
iff all $\vec{x} \in \fv{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}} \dots \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]}}{c}{\vec{x}}}$
\newline
$\height{i}{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}} \dots \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]}\dist{}{\vecdist{f}{\vec{z}}}{\overline{[\Gamma']}}
{d}{\vec{a}}}{c}{\vec{x}}}$
\newline
$= \height{i}{u} \cupdot \height{i+1}{\overline{[\Gamma]}} \cupdot \height{i+1}{\dist{}{\vecdist{f}{\vec{z}}}{\overline{[\Gamma']}}{d}{\vec{a}}} \cupdot \set{i, (i + 1)^{n + 1}}$
\newline
where $n$ is the number of closures in $\overline{[\Gamma]}$
\newline
$= \height{i}{u} \cupdot \height{i+1}{\overline{[\Gamma]}} \cupdot \height{i + 2}{\overline{[\Gamma']}} \cupdot \set{i, (i + 1)^{n + 1}, (i + 2)^{m}}$
\newline
where $m$ is the number of closures in $\overline{[\Gamma']}$
\newline
$\height{i}{\dist{\psub{ \psub{u}{(\vec{w_{1}} / \vec{z})}{e_{1}} \dots}{(\vec{w_{n}} / \vec{z})}{e_{n}}}{\fakedist{e_{1}}{\vec{w_{1}} / \vec{z}} \dots \fakedist{e_{n}}{\vec{w_{n}} / \vec{z}}}{\overline{[\Gamma]}}{c}{\vec{x}}  \dist{}{\vecdist{f}{\vec{z}}}{\overline{[\Gamma']}}{d}{\vec{a}}}$
\newline
$\height{i}{\dist{\psub{ \psub{u}{(\vec{w_{1}} / \vec{z})}{e_{1}} \dots}{(\vec{w_{n}} / \vec{z})}{e_{n}}}{\fakedist{e_{1}}{\vec{w_{1}} / \vec{z}} \dots \fakedist{e_{n}}{\vec{w_{n}} / \vec{z}}}{\overline{[\Gamma]}}{c}{\vec{x}}}$
\newline
\indent $ \cupdot \height{i + 1}{\overline{[\Gamma']}} \cupdot \set{i, (i + 1)^{m}}$
\newline
$= \height{i}{\psub{ \psub{u}{(\vec{w_{1}} / \vec{z})}{e_{1}} \dots}{(\vec{w_{n}} / \vec{z})}{e_{n}}} \cupdot \height{i + 1}{\overline{[\Gamma]}} \cupdot \height{i + 1}{\overline{[\Gamma']}} \cupdot \set{i, (i + 1)^{n + m}}$
\newline
$= \height{i}{u} \cupdot \height{i + 1}{\overline{[\Gamma]}} \cupdot \height{i + 1}{\overline{[\Gamma']}} \cupdot \set{i, (i + 1)^{n + m}}$
\end{proof}

The \emph{weight} of a term is intuitively the number or copies each constructor (abstraction, application and variable) will exist after duplication. Figure \ref{fig:weightexample} illustrates this, by showing a side-by-side comparison of the term $$\fake{x}{x}{\app{\fake{c_{1}}{w_{1}}{w_{1}}}{(\app{(\fake{c_{2}}{w_{2}}{w_{2}})}{x})}}$$ $$\dist{}{\fakedist{c_{1}}{w_{1}} \fakedist{c_{2}}{w_{2}}}{\share{}{w_{1}, w_{2}}{\fake{z}{z}{\app{z_{1}}{(\app{z_{2}}{y})}  \share{}{z_{1}, z_{2}}{z} }}}{y}{y}$$ and its equivalent in the $\WEAK$-calculus obtained by $\composeweak{-}$. Each red line shows the connection between the abstraction and application constructors in both calculi. The weight of a constructor is then the number of red lines associated with it, e.g.\ the weight of the example is the multiset $\set{1^{6}, 2^{4}, 4^{1}}$.

\begin{figure}[h]
\centering
\begin{tikzpicture}[scale = 0.8]
	\filldraw[fill = yellow!30, draw = yellow!70, rounded corners] (-0.75, 0.25) rectangle (2.25, -3.75);
	\filldraw[fill = green!30, draw = green!70, rounded corners] (-0.5, -3) rectangle (0.5, -2.25);
	\filldraw[fill = green!30, draw = green!70, rounded corners] (1, -3.5) rectangle (2, -2.75);
	\filldraw[fill = black!20, draw = black!70, rounded corners, thick] (-0.25, -4) rectangle (4.25, -9.5);
	\filldraw[fill = yellow!30, draw = yellow!70, rounded corners] (0.25, -5.25) rectangle (3, -9.25);
	%%%%%%%%%%%%%%%%%%%%%%%
	\ALnodeL{0, 0}a;
	\ALnodeA{0, -1}b;
	\draw [->] (0, 0.5) -- (a_1);
	\draw [->] (a_2) -- (b_1);
	\ALnodeP{0, -2.5}c;
	\draw [->] (b_2) -- (c_1);
	\ALnodeA{1.5, -2}d;
	\draw [->, rounded corners] (b_3) -| (d_1);
	\ALnodeP{1.5, -3}e;
	\draw [->] (d_2) -- (e_1);
	\draw [->, rounded corners] (d_3) -| (2, -1.5) |- (a_3);
	%%%%%%%%%%%%%%%%%%%%%%%
	\ALnodeS[0.75]{0.75, -4.5}f;
	\draw [->] (c_2) -- (f_left);
	\draw [->] (e_2) -- (f_right);
	\ALnodeL{0.75, -5.5}g;
	\draw [->] (f_tip) -- (g_1);
	\ALnodeA{0.75, -6.5}h;
	\draw [->] (g_2) -- (h_1);
	\ALnodeA{1.75, -7.5}i;
	\draw [->, rounded corners] (h_3) -| (i_1);
	\ALnodeS{1.25, -8.5}j;
	\draw [->] (h_2) -- (j_left);
	\draw [->] (i_2) -- (j_right);
	\ALnodeC{3.5, -4.5}k;
	\draw [->, rounded corners] (i_3) -| (k_tip);
	\draw [rounded corners] (j_tip) |- (2, -9) -| (2.5, -7.55);
	\draw [->, rounded corners] (2.5, -7.45) |- (g_3);
	\draw [->, rounded corners] (k_left) |- (e_3);
	\draw [rounded corners] (k_right) |- (1.55 , -2.5);
	\draw [->] (1.45, -2.5) -- (c_3);
	%%%%%%%%%%%%%%%%%%%%%%
	%%% PICTURE TWO %%%%%%%%%%%%
	%%%%%%%%%%%%%%%%%%%%
	\begin{scope}[yshift = -1cm, xshift = -1cm]
	\ALnodeL{8, 0}z;
	\draw [-] (8, 0.5) -- (z_1);
	\ALnodeA{8, -1}{z2};
	\draw [-] (z_2) -- (z2_1);
	\ALnodeL{8, -2}{z3};
	\draw [-] (z2_2) -- (z3_1);
	\ALnodeL{8, -3}{z4};
	\draw [-] (z3_2) -- (z4_1);
	\ALnodeA{8, -4}{z5};
	\draw [-] (z4_2) -- (z5_1);
	\ALnodeA{9, -5}{z6};
	\draw [-, rounded corners] (z5_3) -| (z6_1);
	\draw [-] (z5_2) -- (8, -7);
	\draw [-] (z6_2) -- (9, -7);
	\draw [-, rounded corners] (z6_3) -| (10, -7);
	\ALnodeA{11, -2}{y};
	\ALnodeL{11, -3}{y1};
	\draw [-] (y_2) -- (y1_1);
	\draw [-, rounded corners] (z2_3) -| (y_1);
	\ALnodeL{11, -4}{y2};
	\draw [-] (y1_2) -- (y2_1);
	\ALnodeA{11, -5}{y3};
	\ALnodeA{12, -6}{y4};
	\draw [-] (y2_2) -- (y3_1);
	\draw [-] (y3_2) -- (11, -7);
	\draw [-, rounded corners] (y3_3) -| (y4_1);
	\draw [-] (y4_2) -- (12, -7);
	\draw [-, rounded corners] (y4_3) -| (13, -7);
	\draw [-, rounded corners] (y_3) -| (14, -7);
	%%%%%%%%%%%%%
	\node (ale) at (8, -8) {\color{violet} $4$};
	\node (bob) at (11, -8) {\color{violet} $2$};
	\node (cai) at (14, -8) {\color{violet} $1$};
	\draw [dotted, violet] (8, -7) to (ale);
	\draw [dotted, violet] (9, -7) to (ale);
	\draw [dotted, violet] (11, -7) to (ale);
	\draw [dotted, violet] (12, -7) to (ale);
	\draw [dotted, violet] (10, -7) to (bob);
	\draw [dotted, violet] (13, -7) to (bob);
	\draw [dotted, violet] (14, -7) to (cai);
	\end{scope}
	%%%%%%%%%%%%%%%%%%%%%%%
	% Connect the 2 diagrams %
	%%%%%%%%%%%%%%%%%%%
	\draw [red, thick, bend left = 25] (a.east) to (z.west); %node [above] {1} (z.west);
	\draw [red, thick, bend left = 25] (b.east) to (z2.west);
	\draw [red, thick, bend left = 30] (d.east) to (y.west);
	\draw [red, thick, bend left = 20] (c.east) to (z3.west);
	\draw [red, thick, bend left = 30] (e.east) to (y1.west);
	\draw [red, thick, bend left = 30] (g.east) to (z4.west);
	\draw [red, thick, bend left = 40] (g.east) to (y2.west);
	\draw [red, thick, bend left = 20] (h.east) to (z5.west);
	\draw [red, thick, bend left = 20] (h.east) to (y3.west);
	\draw [red, thick, bend left = 20] (i.east) to (z6.west);
	\draw [red, thick, bend left = 10] (i.east) to (y4.west);
	%%%%%%%%%%%%%%%%%%%%
\end{tikzpicture}

\caption{The weight is the multiset of incoming red arcs for each application and abstraction; here $\set{1^{5}, 2^{3}}$, together with the number of purple dotted lines for each variable; here $\set{1, 2, 4}$. Thus the overall weight is $\set{1^{6}, 2^{4}, 4}$}
\label{fig:weightexample}
\end{figure}

\begin{proposition}
\label{prop:bkweight}
For $e \not\in \vec{w}$, $\weight{i}{t} = \weight{i}{\psub{t}{\vec{w}}{e}}$
\end{proposition}
\begin{proof}
To prove this, first we need to prove that book-keeping does not affect the function $\weightvar{i}{t}$. We prove this by induction on $t$.
\newline
{\ Base Case: Variable}
\newline
Vacuously True
\newline
\newline
{\ Base Case: Abstraction}
\newline
$\weightvar{i}{\fake{e}{\vec{y}}{t} \psub{}{\vec{w}}{e}} = \weightvar{i}{\fake{e}{\vec{w}}{t}} = \weightvar{i}{t} \cupdot \set{e \mapsto i} = \weightvar{i}{\fake{e}{\vec{y}}{t}}$
\newline
\newline
{ Base Case: Distributor}
\newline
$\weightvar{i}{\dist{u}{\vecdist{f}{\vec{z}}}{\overline{[\Gamma]}}{e}{\vec{y}} \psub{}{\vec{w}}{e}} = \weightvar{i}{\dist{u}{\vecdist{f}{\vec{z}}}{\overline{[\Gamma]}}{e}{\vec{w}}}$
\newline
$ = \weightvar{i}{u\overline{[\Gamma]}} \ \set{\vec{e}} = \weightvar{i}{\dist{u}{\vecdist{f}{\vec{z}}}{\overline{[\Gamma]}}{e}{\vec{y}}}$
\newline
\newline
{ Inductive Case: Application}
\newline
$\weightvar{i}{\app{s}{t} \psub{}{\vec{w}}{e}} = \weightvar{i}{\app{(s \psub{}{\vec{w}}{e})}{t \psub{}{\vec{w}}{e}}} = \weightvar{i}{s \psub{}{\vec{w}}{e}} \cupdot \weightvar{i}{t \psub{}{\vec{w}}{e}} \IH^{2} \weightvar{i}{s} \cupdot \weightvar{i}{t} = \weightvar{i}{\app{s}{t}}$
\newline
\newline
{ Inductive Case: Abstraction}
\newline
Case 1
\newline
$\weightvar{i}{(\fake{c}{c}{t}) \psub{}{\vec{w}}{e}} = \weightvar{i}{\fake{c}{c}{t  \psub{}{\vec{w}}{e} }} = \weightvar{i}{t \psub{}{\vec{w}}{e}} / \set{c} \IH \weightvar{i}{t} / \set{c} = \weightvar{i}{\fake{c}{c}{t}}$
\newline
Case 2
\newline
$\weightvar{i}{(\fake{c}{\vec{x}}{t}) \psub{}{\vec{w}}{e}} = \weightvar{i}{\fake{c}{\vec{x}}{t  \psub{}{\vec{w}}{e} }} = \weightvar{i}{t \psub{}{\vec{w}}{e}} \cupdot \set{c \mapsto i} \IH \weightvar{i}{t} \cupdot \set{c \mapsto i} = \weightvar{i}{\fake{c}{\vec{x}}{t}}$
\newline
\newline
{ Inductive Case: Weakening}
\newline
$\weightvar{i}{\share{u}{}{t} \psub{}{\vec{w}}{e}} = \weightvar{i}{\share{u \psub{}{\vec{w}}{e}}{}{t \psub{}{\vec{w}}{e}}} = \weightvar{i}{u \psub{}{\vec{w}}{e}} \cupdot \weightvar{1}{t \psub{}{\vec{w}}{e}}$
\newline
$ \IH^{2} \weightvar{i}{u} \cupdot \weightvar{1}{t} = \weightvar{i}{\share{u}{}{t}}$
\newline
\newline
{ Inductive Case: Sharing}
\newline
$\weightvar{i}{\share{u}{x_{1} \dots x_{n}}{t} \psub{}{\vec{w}}{e}} = \weightvar{i}{\share{u \psub{}{\vec{w}}{e}}{x_{1} \dots x_{n}}{t \psub{}{\vec{w}}{e}}}$
\newline
$ = (\weightvar{i}{u \psub{}{\vec{w}}{e}} / \set{x_{1}, \dots, x_{n}}) \cupdot \weightvar{}{t \psub{j}{\vec{w}}{e}}$ where $j = \weightvar{i}{t \psub{}{\vec{w}}{e}} + \dots + \weightvar{i}{t \psub{}{\vec{w}}{e}}$
\newline
$\IH^{n + 2} (\weightvar{i}{u } / \set{x_{1}, \dots, x_{n}}) \cupdot \weightvar{}{t }$ where $j = \weightvar{i}{t} + \dots + \weightvar{i}{t} = \weightvar{i}{\share{u}{x_{1}, \dots, x_{n}}{t}}$
\newline
\newline
{ Inductive Case: Distributor}
\newline
Case 1
\newline
$\weightvar{i}{\dist{u}{\vecdist{f}{\vec{z}}}{\overline{[\Gamma]}}{c}{c} \psub{}{\vec{w}}{e}} = \weightvar{i}{\dist{u}{\vecdist{f}{\vec{z}}}{\overline{[\Gamma]} \psub{}{\vec{w}}{e} }{c}{c}} = \weightvar{i}{u \overline{[\Gamma]} \psub{}{\vec{w}}{e}} / \set{c, \vec{f}}$
\newline
$\IH  \weightvar{i}{u \overline{[\Gamma]}} / \set{c, \vec{f}} = \weightvar{i}{\dist{u}{\vecdist{f}{\vec{z}}}{\overline{[\Gamma]}}{c}{c}}$
\newline
Case 2
\newline
$\weightvar{i}{\dist{u}{\vecdist{f}{\vec{z}}}{\overline{[\Gamma]}}{c}{\vec{x}} \psub{}{\vec{w}}{e}} = \weightvar{i}{\dist{u}{\vecdist{f}{\vec{z}}}{\overline{[\Gamma]} \psub{}{\vec{w}}{e} }{c}{\vec{x}}}$
\newline
$ = \weightvar{i}{u \overline{[\Gamma]} \psub{}{\vec{w}}{e}} / \set{\vec{f}} \cupdot \set{c \mapsto i}$
\newline
$\IH  \weightvar{i}{u \overline{[\Gamma]}} / \set{\vec{f}} \cupdot \set{c \mapsto i} = \weightvar{i}{\dist{u}{\vecdist{f}{\vec{z}}}{\overline{[\Gamma]}}{c}{\vec{x}}}$
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newline
\newline
We now prove this proposition by induction on $t$
\newline
{ Base Case: Variable}
\newline
$\weight{i}{\psub{x}{\vec{w}}{e}} = \weight{i}{x}$
\newline
\newline
{ Base Case: Abstraction}
\newline
$\weight{i}{\fake{e}{\vec{y}}{t} \psub{}{\vec{w}}{e}} = \weight{i}{\fake{e}{\vec{w}}{t}} = \weight{i}{t} \cupdot \set{i} = \weight{i}{\fake{e}{\vec{y}}{t}}$
\newline
\newline
{ Base Case: Distributor}
\newline
$\weight{i}{\dist{u}{\vecdist{e}{\vec{z}}}{\overline{[\Gamma]}}{e}{\vec{y}} \psub{}{\vec{w}}{e}} = \weight{i}{\dist{u}{\vecdist{e}{\vec{z}}}{\overline{[\Gamma]}}{e}{\vec{w}}} = \weight{i}{u\overline{[\Gamma]}}$
\newline
$ = \weight{i}{\dist{u}{\vecdist{e}{\vec{z}}}{\overline{[\Gamma]}}{e}{\vec{y}}}$
\newline
\newline
{ Inductive Case: Application}
\newline
$\weight{i}{\app{s}{t} \psub{}{\vec{w}}{e}} = \weight{i}{\app{(s \psub{}{\vec{w}}{e})}{t \psub{}{\vec{w}}{e}}} = \weight{i}{s \psub{}{\vec{w}}{e}} \cupdot \weight{i}{t \psub{}{\vec{w}}{e}} \cupdot \set{i}$
\newline
$\IH^{2} \weight{i}{s} \cupdot \weight{i}{t} \cupdot \set{i} = \weight{i}{\app{s}{t}}$
\newline
\newline
{ Inductive Case: Abstraction}
\newline
Case 1
\newline
$\weight{i}{(\fake{c}{c}{t}) \psub{}{\vec{w}}{e}} = \weight{i}{\fake{c}{c}{t \psub{}{\vec{w}}{e}}} = \weight{i}{t \psub{}{\vec{w}}{e}} \cupdot \set{i, \weightvar{i}{t \psub{}{\vec{w}}{e}}(c)}$
\newline
$\IH \weight{i}{t} \cupdot \set{i, \weightvar{i}{t}(c)} = \weight{i}{\fake{c}{c}{t}}$
\newline
Case 2
\newline
$\weight{i}{(\fake{c}{\vec{x}}{t}) \psub{}{\vec{w}}{e}} = \weight{i}{\fake{c}{\vec{x}}{t \psub{}{\vec{w}}{e}}} = \weight{i}{t \psub{}{\vec{w}}{e}} \cupdot \set{i} \IH \weight{i}{t} \cupdot \set{i}$
\newline
$ = \weight{i}{\fake{c}{\vec{x}}{t}}$
\newline
\newline
{ Inductive Case: Weakening}
\newline
$\weight{i}{\share{u}{}{t} \psub{}{\vec{w}}{e}} = \weight{i}{\share{u\psub{}{\vec{w}}{e}}{}{t\psub{}{\vec{w}}{e}}} = \weight{i}{u\psub{}{\vec{w}}{e}} \cupdot \weight{1}{t \psub{}{\vec{w}}{e}}$
\newline
$\IH^{2} \weight{i}{u} \cupdot \weight{1}{t } = \weight{i}{\share{u}{}{t}}$
\newline
\newline
{ Inductive Case: Sharing}
\newline
$\weight{i}{\share{u}{x_{1}, \dots, x_{n}}{t} \psub{}{\vec{w}}{e}} = \weight{i}{\share{u  \psub{}{\vec{w}}{e}}{x_{1}, \dots, x_{n}}{t  \psub{}{\vec{w}}{e}}}$
\newline
$ = \weight{i}{u  \psub{}{\vec{w}}{e}} \cupdot \weight{j}{t  \psub{}{\vec{w}}{e}}$ where $j = \weightvar{i}{u  \psub{}{\vec{w}}{e}}(x_{1}) + \dots + \weightvar{i}{u  \psub{}{\vec{w}}{e}}(x_{n})$
\newline
$\IH^{n + 2} \weight{i}{u} \cupdot \weight{j}{t}$ where $j = \weightvar{i}{u}(x_{1}) + \dots + \weightvar{i}{u}(x_{1}) = \weight{i}{\share{u}{x_{1}, \dots, x_{n}}{t}}$
\newline
\newline
{ Inductive Case: Distributor}
\newline
Case 1
\newline
$\weight{i}{\dist{u}{\vecdist{f}{\vec{z}}}{\overline{[\Gamma]}}{c}{c} \psub{}{\vec{w}}{e}} = \weight{i}{\dist{u}{\vecdist{f}{\vec{z}}}{\overline{[\Gamma]} \psub{}{\vec{w}}{e} }{c}{c}}$
\newline
$ = \weight{i}{u \overline{[\Gamma]} \psub{}{\vec{w}}{e}} \cupdot \set{\weightvar{i}{u \overline{[\Gamma]} \psub{}{\vec{w}}{e}}(c)} \IH \weight{i}{u \overline{[\Gamma]}} \cupdot \set{\weightvar{i}{u \overline{[\Gamma]}}(c)}$
\newline
$ = \weight{i}{\dist{u}{\vecdist{f}{\vec{z}}}{\overline{[\Gamma]}}{c}{c}}$
\newline
Case 2
\newline
$\weight{i}{\dist{u}{\vecdist{f}{\vec{z}}}{\overline{[\Gamma]}}{c}{\vec{x}} \psub{}{\vec{w}}{e}} = \weight{i}{\dist{u}{\vecdist{f}{\vec{z}}}{\overline{[\Gamma]} \psub{}{\vec{w}}{e} }{c}{\vec{x}}}$
\newline
$ = \weight{i}{u \overline{[\Gamma]} \psub{}{\vec{w}}{e}} \IH \weight{i}{u \overline{[\Gamma]}} = \weight{i}{\dist{u}{\vecdist{f}{\vec{z}}}{\overline{[\Gamma]}}{c}{\vec{x}}}$
\end{proof}

We now prove {\bf Lemma \ref{theo:decreaseweight}} on a case-by-case basis.
\begin{center}
If $t \rightsquigarrow_{D} u$ then $\weight{i}{t} > \weight{i}{u}$
\end{center}

\begin{center}
If $t \rightsquigarrow_{(L, C)} u$ then $\weight{i}{t} = \weight{i}{u}$
\end{center}

\begin{proof}
Duplication Rules
\newline
$$\share{u^{*}}{x_{1} \dots x_{n}}{\app{s}{t}} \rightsquigarrow_{D} \share{\share{\sub{\sub{u^{*}}{\app{z_{1}}{y_{1}}}{x_{1}}\dots}{\app{z_{n}}{y_{n}}}{x_{n}}}{z_{1} \dots z_{n}}{s}}{y_{1} \dots y_{n}}{t}$$
$\weight{i}{\share{u^{*}}{x_{1} \dots x_{n}}{\app{s}{t}}} = \weight{i}{u} \cupdot \weight{j}{\app{s}{t}}
= \weight{i}{u} \cupdot \weight{j}{s} \cupdot \weight{j}{s} \cupdot \set{j}$
\newline
where $j = \weightvar{i}{u}(x_{1}) + \dots + \weightvar{i}{u}(x_{n})$
\newline
$\weight{i}{\share{\share{\sub{\sub{u^{*}}{\app{z_{1}}{y_{1}}}{x_{1}}\dots}{\app{z_{n}}{y_{n}}}{x_{n}}}{z_{1} \dots z_{n}}{s}}{y_{1} \dots y_{n}}{t}}$
\newline
$= \weight{i}{\share{\sub{\sub{u^{*}}{\app{z_{1}}{y_{1}}}{x_{1}}\dots}{\app{z_{n}}{y_{n}}}{x_{n}}}{z_{1} \dots z_{n}}{s}} \cupdot \weight{k}{t}$
\newline
$= \weight{i}{\sub{\sub{u^{*}}{\app{z_{1}}{y_{1}}}{x_{1}}\dots}{\app{z_{n}}{y_{n}}}{x_{n}}} \cupdot \weight{l}{s} \cupdot \weight{k}{t}$
\newline
where $k = \weightvar{i}{\share{\sub{\sub{u^{*}}{\app{z_{1}}{y_{1}}}{x_{1}}\dots}{\app{z_{n}}{y_{n}}}{x_{n}}}{z_{1} \dots z_{n}}{s}}(y_{1}) + \dots$
\newline
\indent $\dots + \weightvar{i}{\share{\sub{\sub{u^{*}}{\app{z_{1}}{y_{1}}}{x_{1}}\dots}{\app{z_{n}}{y_{n}}}{x_{n}}}{z_{1} \dots z_{n}}{s}}(y_{n})$
\newline
$= \weightvar{i}{\sub{\sub{u^{*}}{\app{z_{1}}{y_{1}}}{x_{1}}\dots}{\app{z_{n}}{y_{n}}}{x_{n}}}(y_{1}) + \dots + \weightvar{i}{\sub{\sub{u^{*}}{\app{z_{1}}{y_{1}}}{x_{1}}\dots}{\app{z_{n}}{y_{n}}}{x_{n}}}(y_{n})$
\newline
$= \weightvar{i}{u}(x_{1}) + \dots + \weightvar{i}{u}(x_{n}) = j$
\newline
and where $l = \weightvar{i}{\sub{\sub{u^{*}}{\app{z_{1}}{y_{1}}}{x_{1}}\dots}{\app{z_{n}}{y_{n}}}{x_{n}}}(z_{1}) + \dots$
\newline
\indent $\dots + \weightvar{i}{\sub{\sub{u^{*}}{\app{z_{1}}{y_{1}}}{x_{1}}\dots}{\app{z_{n}}{y_{n}}}{x_{n}}}(z_{n})$
\newline
$= \weightvar{i}{u}(x_{1}) + \dots + \weightvar{i}{u}(x_{n}) = j$
\newline
Therefore
\newline
$= \weight{i}{\sub{\sub{u^{*}}{\app{z_{1}}{y_{1}}}{x_{1}}\dots}{\app{z_{n}}{y_{n}}}{x_{n}}} \cupdot \weight{j}{s} \cupdot \weight{j}{t}$
\newline
$= \weight{i}{u} \cupdot \weight{j}{s} \cupdot \weight{j}{t} \cupdot \set{\weightvar{i}{u}(x_{1}) , \dots , \weightvar{i}{u}(x_{n})}$
\newline
$$\share{u}{x_{1}, \dots, x_{n}}{\fake{c}{\vec{y}}{t}} \rightsquigarrow_{D}$$
$$\sub{u}{\fake{e_{i}}{w^{i}_{1}}{w^{i}_{1}}}{x_{i}}_{1 \leq i \leq n} \dist{}{\fakedist{e_{1}}{w^{1}_{1}} \dots \fakedist{e_{n}}{w^{n}_{1}}}{\share{}{w^{1}_{1}, \dots, w^{n}_{1}}{t}}{c}{\vec{y}}$$
Case 1:
\newline
$\weight{i}{\share{u}{x_{1}, \dots, x_{n}}{\fake{c}{c}{t}}} = \weight{i}{u} \cupdot \weight{j}{\fake{c}{c}{t}} =  \weight{i}{u} \cupdot \weight{j}{t} \cupdot \set{j, \weightvar{j}{t}(c)}$
\newline
where $j = \weightvar{i}{u}(x_{1}) + \dots + \weightvar{i}{u}(x_{n}) $
\newline
$\weight{i}{\sub{u}{\fake{e_{i}}{w^{i}_{1}}{w^{i}_{1}}}{x_{i}}_{1 \leq i \leq n} \dist{}{\fakedist{e_{1}}{w^{1}_{1}} \dots \fakedist{e_{n}}{w^{n}_{1}}}{\share{}{w^{1}_{1}, \dots, w^{n}_{1}}{t}}{c}{c}}$
\newline
$= \weight{i}{\sub{u}{\fake{e_{i}}{w^{i}_{1}}{w^{i}_{1}}}{x_{i}}_{1 \leq i \leq n} \share{}{w^{1}_{1}, \dots, w^{n}_{1}}{t}} \cupdot $
\newline
\indent $\weightvar{i}{\sub{u}{\fake{e_{i}}{w^{i}_{1}}{w^{i}_{1}}}{x_{i}}_{1 \leq i \leq n} \share{}{w^{1}_{1}, \dots, w^{n}_{1}}{t}}(c)$
\newline
$\weightvar{i}{\sub{u}{\fake{e_{i}}{w^{i}_{1}}{w^{i}_{1}}}{x_{i}}_{1 \leq i \leq n} \share{}{w^{1}_{1}, \dots, w^{n}_{1}}{t}}(c) = \weightvar{k}{t}(c) = \weightvar{j}{t}(c)$
\newline
where $k = \weightvar{i}{\sub{u}{\fake{e_{i}}{w^{i}_{1}}{w^{i}_{1}}}{x_{i}}_{1 \leq i \leq n} \share{}{w^{1}_{1}, \dots, w^{n}_{1}}{t}}(w^{1}_{1}) + \dots$
\newline
\indent $\dots + \weightvar{i}{\sub{u}{\fake{e_{i}}{w^{i}_{1}}{w^{i}_{1}}}{x_{i}}_{1 \leq i \leq n} \share{}{w^{1}_{1}, \dots, w^{n}_{1}}{t}}(w^{n}_{1}) = j$
\newline
$=  \weight{i}{\sub{u}{\fake{e_{i}}{w^{i}_{1}}{w^{i}_{1}}}{x_{i}}_{1 \leq i \leq n} \share{}{w^{1}_{1}, \dots, w^{n}_{1}}{t}} \cupdot  \weightvar{j}{t}(c)$
\newline
$= \weight{i}{\sub{u}{\fake{e_{i}}{w^{i}_{1}}{w^{i}_{1}}}{x_{i}}_{1 \leq i \leq n}} \cupdot \weight{k}{t} \cupdot  \set{\weightvar{j}{t}(c)}$
\newline
$= \weight{i}{u} \cupdot \weight{j}{t} \cupdot \set{\weightvar{i}{u}(x_{1}), \dots, \weightvar{i}{u}(x_{n}),  \weightvar{j}{t}(c)}$
\newline
Case: 2
\newline
$\weight{i}{\share{u}{x_{1}, \dots, x_{n}}{\fake{c}{\vec{y}}{t}}} = \weight{i}{u} \cupdot \weight{j}{\fake{c}{\vec{y}}{t}} = \weight{i}{u} \cupdot \weight{j}{t} \cupdot \set{j}$
\newline
where $j = \weightvar{i}{u}(x_{1}) + \dots + \weightvar{i}{u}(x_{n})$
\newline
$\weight{i}{\sub{u}{\fake{e_{i}}{w^{i}_{1}}{w^{i}_{1}}}{x_{i}}_{1 \leq i \leq n} \dist{}{\fakedist{e_{1}}{w^{1}_{1}} \dots \fakedist{e_{n}}{w^{n}_{1}}}{\share{}{w^{1}_{1}, \dots, w^{n}_{1}}{t}}{c}{\vec{y}}}$
\newline
$= \weight{i}{\sub{u}{\fake{e_{i}}{w^{i}_{1}}{w^{i}_{1}}}{x_{i}}_{1 \leq i \leq n} \share{}{w^{1}_{1}, \dots, w^{n}_{1}}{t}}$
\newline
$= \weight{i}{\sub{u}{\fake{e_{i}}{w^{i}_{1}}{w^{i}_{1}}}{x_{i}}_{1 \leq i \leq n} } \cupdot \weight{k}{t}$
\newline
where $k = \weightvar{i}{\sub{u}{\fake{e_{i}}{w^{i}_{1}}{w^{i}_{1}}}{x_{i}}_{1 \leq i \leq n}}(w^{1}_{1}) + \dots + \weightvar{i}{\sub{u}{\fake{e_{i}}{w^{i}_{1}}{w^{i}_{1}}}{x_{i}}_{1 \leq i \leq n}}(w^{n}_{1}) = j$
\newline
$= \weight{i}{\sub{u}{\fake{e_{i}}{w^{i}_{1}}{w^{i}_{1}}}{x_{i}}_{1 \leq i \leq n} } \cupdot \weight{j}{t}$
\newline
$= \weight{i}{u} \cupdot \weight{j}{t} \cupdot \set{\weightvar{i}{u}(x_{1}), \dots, \weightvar{i}{u}(x_{n})}$
\newline
$$\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}} \dots \fakedist{e_{n}}{\vec{w_{n}}}}{\share{}{\vec{w_{1}}, \dots, \vec{w_{n}}}{c}}{c}{c} \rightsquigarrow_{D} \exor{\exor{u}{e_{1}}{\vec{w_{1}}} \dots}{e_{n}}{\vec{w_{n}}}$$
$\weight{i}{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}} \dots \fakedist{e_{n}}{\vec{w_{n}}}}{\share{}{\vec{w_{1}}, \dots, \vec{w_{n}}}{c}}{c}{c}}$
\newline
$= \weight{i}{u \share{}{\vec{w_{1}}, \dots, \vec{w_{n}}}{c}} \cupdot \set{\weightvar{i}{u \share{}{\vec{w_{1}}, \dots, \vec{w_{n}}}{c}(c)}}$
\newline
$= \weight{i}{u} \cupdot \set{} \cupdot \set{j}$
\newline
where $j = \weightvar{i}{u}(\vec{w_{1}}) + \dots + \weightvar{i}{u}(\vec{w_{n}})$
\newline
$\weight{i}{\exor{\exor{u}{e_{1}}{\vec{w_{1}}} \dots}{e_{n}}{\vec{w_{n}}}} = \weight{i}{u} \cupdot \set{\weightvar{i}{u}(\vec{w_{1}}), \dots , \weightvar{i}{u}(\vec{w_{n}})}$
\newline
where $\weightvar{i}{u}(\vec{w}) = \weightvar{i}{u}(w_{1}) + \dots + \weightvar{i}{u}(w_{n})$ and $\vec{w} = \set{w_{1}, \dots, w_{n}}$
\newline
\newline
Lifting and Compound
$$\share{\share{u}{\vec{w}}{y}}{\vec{x} \cdot y}{t} \rightsquigarrow_{C} \share{u}{\vec{x} \cdot \vec{w}}{t}$$
$\weight{i}{\share{\share{u}{\vec{w}}{y}}{\vec{x} \cdot y}{t}} = \weight{i}{\share{u}{\vec{w}}{y}} \cupdot \weight{j}{t}$
\newline
where $j = \weightvar{i}{\share{u}{\vec{w}}{y}}(\vec{x}) + \weightvar{i}{\share{u}{\vec{w}}{y}}(y) = \weightvar{i}{\share{u}{\vec{w}}{y}}(\vec{x}) + \weightvar{i}{u}(\vec{w})$
\newline
$= \weight{i}{u} \cupdot \weight{j}{t} = \weight{i}{\share{u}{\vec{x} \cdot \vec{w}}{t}}$
\newline
\newline
$$\share{u}{x}{t} \rightsquigarrow_{C} \sub{u}{t}{x} $$
$\weight{i}{\share{u}{x}{t}} = \weight{i}{u} \cupdot \weight{j}{t}$
\newline
where $j = \weightvar{i}{u}(x)$
\newline
$\weight{i}{ \sub{u}{t}{x}} = \weight{i}{u} \cupdot \weight{\weightvar{i}{u}(x)}{t}$
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newline
\newline
For the other lifting rules, we show that $\weightvar{i}{u[\Gamma]}$ outputs the same integers before and after lifting for each variable bounded by $[\Gamma]$. Then we can know it produces some multiset $M$.

$$\app{(s[\Gamma])}{t} \rightsquigarrow_{L} (\app{s}{t})[\Gamma]$$
$\weight{i}{\app{(s[\Gamma])}{t}} = \weight{i}{s[\Gamma]} \cupdot \weight{i}{t} = \weight{i}{s} \cupdot \weight{i}{t} \cupdot M_{1}$
\newline
$\weight{i}{ (\app{s}{t})[\Gamma]} = \weight{i}{\app{s}{t}} \cupdot M_{2} = \weight{i}{s} \cupdot \weight{i}{t} \cupdot M_{2}$
\newline
$M_{1} = M_{2}$ since $\weightvar{i}{s}(x) = \weightvar{i}{\app{s}{t}}(x)$ for $x \in \fv{s}$ and $[\Gamma]$ only binds variables in $s$.
\newline
$$\app{s}{t[\Gamma]} \rightsquigarrow_{L} (\app{s}{t})[\Gamma]$$
This case is very similar to the one above and we omit it.
\newline
$$\fake{d}{\vec{x}}{t[\Gamma]} \rightsquigarrow_{L} (\fake{d}{\vec{x}}{t})[\Gamma] \text{ iff all $\vec{x} \in \fv{t}$}$$
Case 1:
\newline
$\weight{i}{\fake{d}{d}{(t[\Gamma])}} = \weight{i}{t[\Gamma]} \cupdot \set{i, \weightvar{i}{t[\Gamma]}(d)} = \weight{i}{t} \cupdot M_{1} \cupdot \set{i, \weightvar{i}{t}(d)}$
\newline
$\weight{i}{(\fake{d}{d}{t})[\Gamma]} = \weight{i}{\fake{d}{d}{t}} \cupdot M_{2} =  \weight{i}{t} \cupdot M_{2} \cupdot \set{i, \weightvar{i}{t}(d)}$
\newline
$M_{1} = M_{2}$ since $\weightvar{i}{t}(x) = \weight{i}{\fake{d}{d}{t}}(x)$ where $x \neq d$ and $d$ is not bound by $[\Gamma]$
\newline
Case 2:
\newline
$\weight{i}{\fake{d}{\vec{x}}{(t[\sigma])}} = \weight{i}{t[\sigma]} \cupdot \set{i} = \weight{i}{t} \cupdot M_{1} \cupdot \set{i}$
\newline
$\weight{i}{(\fake{d}{\vec{x}}{t})[\sigma]} = \weight{i}{\fake{d}{\vec{x}}{t}} \cupdot M_{2} =  \weight{i}{t} \cupdot M_{2} \cupdot \set{i}$
\newline
$M_{1} = M_{2}$ since $\weightvar{i}{t}(x) = \weight{i}{\fake{d}{\vec{x}}{t}}(x)$ where $x \neq d$ and $d$ is not bound by $[\Gamma]$
\newline
$$\share{u}{\vec{x}}{t[\Gamma]} \rightsquigarrow_{L} \share{u}{\vec{x}}{t}[\Gamma]$$
Case 1:
\newline
$\weight{i}{\share{u}{\vec{x}}{t[\Gamma]}} = \weight{i}{u} \cupdot \weight{j}{t[\Gamma]} = \weight{i}{u} \cupdot \weight{j}{t} \cupdot M_{1}$
\newline
where $j = \weightvar{i}{u}(x_{1}) + \dots +  \weightvar{i}{u}(x_{n})$
\newline
$\weight{i}{\share{u}{\vec{x}}{t}[\Gamma]} = \weight{i}{\share{u}{\vec{x}}{t}} \cupdot M_{2} = \weight{i}{u} \cupdot \weight{j}{t} \cupdot M_{2}$
\newline
$M_{1} = M_{2}$ since $\weightvar{j}{t}(x) = \weightvar{i}{\share{u}{\vec{x}}{t}}(x)$ for $x \in \fv{t}$ and $[\Gamma]$ only binds variables in $t$
\newline
Case 2:
\newline
$\weight{i}{\share{u}{}{t[\Gamma]}} = \weight{i}{u} \cupdot \weight{1}{t[\Gamma]} = \weight{i}{u} \cupdot \weight{1}{t} \cupdot M_{1}$
\newline
$\weight{i}{\share{u}{}{t}[\Gamma]} = \weight{i}{\share{u}{}{t}} \cupdot M_{2} = \weight{i}{u} \cupdot \weight{1}{t} \cupdot M_{2}$
\newline
$M_{1} = M_{2}$ since $\weightvar{1}{t}(x) = \weightvar{i}{\share{u}{}{t}}(x)$ for $x \in \fv{t}$ and  $[\Gamma]$ only binds variables in $t$
\newline
$$\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}} \dots \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]} \share{}{\vec{y}}{t}}{c}{\vec{x}} \rightsquigarrow_{L}$$
$$\dist{\psub{ \psub{u}{(\vec{w_{1}} / \vec{y})}{e_{1}} \dots}{(\vec{w_{n}} / \vec{y})}{e_{n}}}{\fakedist{e_{1}}{\vec{w_{1}} / \vec{y}} \dots \fakedist{e_{n}}{\vec{w_{n}} / \vec{y}}}{\overline{[\Gamma]}}{c}{\vec{x}} \share{}{\vec{y}}{t}$$
\newline
$$\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}} \dots \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]} \dist{}{\vecdist{f}{\vec{z}}}{\overline{[\Gamma']}}
{d}{\vec{a}}}{c}{\vec{x}} \rightsquigarrow_{L}$$
$$\dist{\psub{ \psub{u}{(\vec{w_{1}} / \vec{z})}{e_{1}} \dots}{(\vec{w_{n}} / \vec{z})}{e_{n}}}{\fakedist{e_{1}}{\vec{w_{1}} / \vec{z}} \dots \fakedist{e_{n}}{\vec{w_{n}} / \vec{z}}}{\overline{[\Gamma]}}{c}{\vec{x}}  \dist{}{\vecdist{f}{\vec{z}}}{\overline{[\Gamma']}}{d}{\vec{a}}$$
Since book-keeping operations do not affect the weight of a term (Proposition \ref{prop:bkweight}), we simplify these two rules into one, where $u'$ is $u$ with some book-keepings applied.
\newline
\emph{Note}: Proposition \ref{prop:bkweight} is relevant here since the book-keepings produced by this rule cannot be of the form $\psub{}{e}{e}$ without breaking linearity.
$$\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}} \dots \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]} [\Gamma]}{c}{\vec{x}} \rightsquigarrow_{L}\dist{u'}{\fakedist{e_{1}}{\vec{z_{1}}} \dots \fakedist{e_{n}}{\vec{z_{1}}}}{\overline{[\Gamma]}}{c}{\vec{x}}[\Gamma]$$
Case 1:
\newline
$\weight{i}{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}} \dots \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]} [\Gamma]}{c}{c}} = \weight{i}{u \overline{[\Gamma]}[\Gamma]} \cupdot \set{\weightvar{i}{u\overline{[\Gamma]}[\Gamma](c)}}$
\newline
$= \weight{i}{u\overline{[\Gamma]}} \cupdot M_{1} \cupdot  \set{\weightvar{i}{u\overline{[\Gamma]}[\Gamma](c)}}$
\newline
$\weight{i}{\dist{u'}{\fakedist{e_{1}}{\vec{z_{1}}} \dots \fakedist{e_{n}}{\vec{z_{1}}}}{\overline{[\Gamma]}}{c}{c}[\Gamma]} = \weight{i}{\dist{u'}{\fakedist{e_{1}}{\vec{z_{1}}} \dots \fakedist{e_{n}}{\vec{z_{1}}}}{\overline{[\Gamma]}}{c}{c}} \cupdot M_{2}$
\newline
$= \weight{i}{u'[\Gamma]} \cupdot M_{2} \cupdot \set{\weightvar{i}{u[\Gamma]}(c)}$
\newline
$M_{1} = M_{2}$ since $\weightvar{i}{u \overline{[\Gamma]}}(x) = \weightvar{i}{\dist{u'}{\fakedist{e_{1}}{\vec{z_{1}}} \dots \fakedist{e_{n}}{\vec{z_{1}}}}{\overline{[\Gamma]}}{c}{c}}(x)$
\newline
for $x \in \fv{u \overline{[\Gamma]} / \set{c, e_{1}, \dots, e_{n}}}$ and the variables $c, e_{1}, \dots, e_{n}$ are not bound by $[\Gamma]$
\newline
$\set{\weightvar{i}{u\overline{[\Gamma]}[\Gamma]}(c)} =  \set{\weightvar{i}{u\overline{[\Gamma]}}(c)}$ since $c \in \fv{\overline{[\Gamma]}}$ and $\weightvar{i}{u\overline{[\Gamma]}[\Gamma]} = \weightvar{i}{u\overline{[\Gamma]}} \cupdot \weightvar{j}{[\Gamma]}$.
\newline
Case 2:
\newline
$\weight{i}{\dist{u}{\fakedist{e_{1}}{\vec{w_{1}}} \dots \fakedist{e_{n}}{\vec{w_{n}}}}{\overline{[\Gamma]} [\Gamma]}{c}{\vec{x}}} = \weight{i}{u\overline{[\Gamma]}[\Gamma]} = \weight{i}{u\overline{[\Gamma]}} \cupdot M_{1}$
\newline
$\weight{i}{\dist{u'}{\fakedist{e_{1}}{\vec{z_{1}}} \dots \fakedist{e_{n}}{\vec{z_{1}}}}{\overline{[\Gamma]}}{c}{\vec{x}}[\Gamma]} = \weight{i}{\dist{u'}{\fakedist{e_{1}}{\vec{z_{1}}} \dots \fakedist{e_{n}}{\vec{z_{1}}}}{\overline{[\Gamma]}}{c}{\vec{x}}} \cupdot M_{2}$
\newline
$= \weight{i}{u'\overline{[\Gamma]}} \cupdot M_{2}$
\newline
$M_{1} = M_{2}$ since $\weightvar{i}{u \overline{[\Gamma]}}(x) = \weightvar{i}{\dist{u'}{\fakedist{e_{1}}{\vec{z_{1}}} \dots \fakedist{e_{n}}{\vec{z_{1}}}}{ \overline{[\Gamma]}}{c}{c}}(x)$
\newline
for $x \in \fv{u \overline{[\Gamma]} / \set{c, e_{1}, \dots, e_{n}}}$ and the variables $c, e_{1}, \dots, e_{n}$ are not bound by $[\Gamma]$
\end{proof}

\end{document}
